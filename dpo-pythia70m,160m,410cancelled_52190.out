WARNING: eval_every must be divisible by batch_size
Setting eval_every to 11968
no FSDP port specified; using open port for FSDP: 37725
seed: 0
exp_name: pythia70m_dpo_seed0
batch_size: 64
eval_batch_size: 16
debug: false
fsdp_port: 37725
datasets:
- hh_static
wandb:
  enabled: true
  entity: lauraomahony999
  project: pythia-dpo
local_dirs:
- /scr-ssd
- /scr
- .cache
sample_during_eval: false
n_eval_model_samples: 16
do_first_eval: true
local_run_dir: .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994
lr: 1.0e-06
gradient_accumulation_steps: 1
max_grad_norm: 10.0
max_length: 512
max_prompt_length: 256
n_epochs: 1
n_examples: null
n_eval_examples: 256
trainer: FSDPTrainer
optimizer: RMSprop
warmup_steps: 150
activation_checkpointing: false
eval_every: 11968
minimum_log_interval_secs: 1.0
model:
  name_or_path: lomahony/pythia-70m-helpful-sft
  tokenizer_name_or_path: null
  archive: null
  block_name: GPTNeoXLayer
  policy_dtype: float32
  fsdp_policy_mp: null
  reference_dtype: float16
loss:
  name: dpo
  beta: 0.1
  label_smoothing: 0
  reference_free: false

================================================================================
Writing to ip-10-0-222-166:.cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994
================================================================================
building policy
Some weights of GPTNeoXForCausalLM were not initialized from the model checkpoint at lomahony/pythia-70m-helpful-sft and are newly initialized: ['gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.1.attention.bias', 'gpt_neox.layers.4.attention.masked_bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.5.attention.bias', 'gpt_neox.layers.5.attention.masked_bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
building reference model
Some weights of GPTNeoXForCausalLM were not initialized from the model checkpoint at lomahony/pythia-70m-helpful-sft and are newly initialized: ['gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.1.attention.bias', 'gpt_neox.layers.4.attention.masked_bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.5.attention.bias', 'gpt_neox.layers.5.attention.masked_bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
starting 8 processes for FSDP training
setting RLIMIT_NOFILE soft limit to 131072 from 8192
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
wandb: Currently logged in as: lauraomahony999. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in .cache/laura/wandb/run-20240112_144227-wc2q2vp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pythia70m_dpo_seed0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lauraomahony999/pythia-dpo
wandb: üöÄ View run at https://wandb.ai/lauraomahony999/pythia-dpo/runs/wc2q2vp1
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
0 initializing distributed
Creating trainer on process 0 with world size 8
Loading tokenizer lomahony/pythia-70m-helpful-sft
Loaded train data iterator
Loading HH static dataset (test split) from Huggingface...
done
Processing HH static:   0%|          | 0/5103 [00:00<?, ?it/s]Processing HH static:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2833/5103 [00:00<00:00, 28311.19it/s]Processing HH static: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5103/5103 [00:00<00:00, 28181.34it/s]
FINISHED 256 EXAMPLES on test split
Loaded 16 eval batches of size 16
Sharding policy...
Sharding reference model...
Loaded model on rank 0
Using RMSprop optimizer
Loading HH static dataset (train split) from Huggingface...
done
Processing HH static:   0%|          | 0/96256 [00:00<?, ?it/s]Processing HH static:   3%|‚ñé         | 2908/96256 [00:00<00:03, 29067.00it/s]Processing HH static:   6%|‚ñå         | 5815/96256 [00:00<00:03, 28942.12it/s]Processing HH static:   9%|‚ñâ         | 8710/96256 [00:00<00:03, 28707.82it/s]Processing HH static:  12%|‚ñà‚ñè        | 11581/96256 [00:00<00:05, 15409.15it/s]Processing HH static:  15%|‚ñà‚ñç        | 14381/96256 [00:00<00:04, 18319.22it/s]Processing HH static:  18%|‚ñà‚ñä        | 17108/96256 [00:00<00:03, 20540.15it/s]Processing HH static:  21%|‚ñà‚ñà        | 19918/96256 [00:00<00:03, 22517.38it/s]Processing HH static:  24%|‚ñà‚ñà‚ñé       | 22698/96256 [00:01<00:03, 23953.84it/s]Processing HH static:  27%|‚ñà‚ñà‚ñã       | 25510/96256 [00:01<00:02, 25117.65it/s]Processing HH static:  29%|‚ñà‚ñà‚ñâ       | 28311/96256 [00:01<00:02, 25943.00it/s]Processing HH static:  32%|‚ñà‚ñà‚ñà‚ñè      | 31139/96256 [00:01<00:02, 26618.99it/s]Processing HH static:  35%|‚ñà‚ñà‚ñà‚ñå      | 33931/96256 [00:01<00:02, 26998.41it/s]Processing HH static:  38%|‚ñà‚ñà‚ñà‚ñä      | 36701/96256 [00:01<00:02, 27154.82it/s]Processing HH static:  41%|‚ñà‚ñà‚ñà‚ñà      | 39466/96256 [00:01<00:02, 27045.08it/s]Processing HH static:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 42234/96256 [00:01<00:01, 27231.97it/s]Processing HH static:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 44982/96256 [00:01<00:02, 18702.10it/s]Processing HH static:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 47665/96256 [00:02<00:02, 20528.83it/s]Processing HH static:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 50327/96256 [00:02<00:02, 22009.83it/s]Processing HH static:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 53011/96256 [00:02<00:01, 23254.86it/s]Processing HH static:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 55699/96256 [00:02<00:01, 24229.60it/s]Processing HH static:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 58276/96256 [00:02<00:01, 24613.70it/s]Processing HH static:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 60868/96256 [00:02<00:01, 24982.73it/s]Processing HH static:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 63565/96256 [00:02<00:01, 25554.66it/s]Processing HH static:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 66249/96256 [00:02<00:01, 25927.81it/s]Processing HH static:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 68919/96256 [00:02<00:01, 26154.46it/s]Processing HH static:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 71588/96256 [00:02<00:00, 26310.57it/s]Processing HH static:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 74257/96256 [00:03<00:00, 26422.17it/s]Processing HH static:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 76914/96256 [00:03<00:00, 26378.71it/s]Processing HH static:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 79578/96256 [00:03<00:00, 26455.89it/s]Processing HH static:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 82231/96256 [00:03<00:00, 25700.12it/s]Processing HH static:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 84811/96256 [00:03<00:00, 16394.95it/s]Processing HH static:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 87470/96256 [00:03<00:00, 18539.84it/s]Processing HH static:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 90030/96256 [00:03<00:00, 20170.14it/s]Processing HH static:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 92652/96256 [00:03<00:00, 21671.11it/s]Processing HH static:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 95125/96256 [00:04<00:00, 22471.42it/s]Processing HH static: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96256/96256 [00:04<00:00, 23299.71it/s]
Running evaluation after 0 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:   6%|‚ñã         | 1/16 [00:01<00:21,  1.42s/it]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:01<00:03,  3.37it/s]Computing eval metrics:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:01<00:01,  6.41it/s]Computing eval metrics:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:01<00:00, 10.73it/s]Computing eval metrics:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [00:01<00:00, 14.73it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:01<00:00,  8.35it/s]
eval after 0: {'rewards_eval/chosen': '0.13774', 'rewards_eval/rejected': '0.11633', 'rewards_eval/accuracies': '0.51562', 'rewards_eval/margins': '0.021412', 'logps_eval/rejected': '-186.19', 'logps_eval/chosen': '-222.17', 'loss/eval': '0.69642'}
train stats after 64 examples: {'rewards_train/chosen': '0.11799', 'rewards_train/rejected': '0.10566', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.012328', 'logps_train/rejected': '-212.74', 'logps_train/chosen': '-219.17', 'loss/train': '0.70125', 'examples_per_second': '355.51', 'grad_norm': '66.37', 'counters/examples': 64, 'counters/updates': 1}
skipping logging after 128 examples to avoid logging too frequently
skipping logging after 192 examples to avoid logging too frequently
skipping logging after 256 examples to avoid logging too frequently
skipping logging after 320 examples to avoid logging too frequently
skipping logging after 384 examples to avoid logging too frequently
train stats after 448 examples: {'rewards_train/chosen': '0.20001', 'rewards_train/rejected': '0.091491', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.10852', 'logps_train/rejected': '-184.07', 'logps_train/chosen': '-246.31', 'loss/train': '0.65296', 'examples_per_second': '567.8', 'grad_norm': '53.22', 'counters/examples': 448, 'counters/updates': 7}
skipping logging after 512 examples to avoid logging too frequently
skipping logging after 576 examples to avoid logging too frequently
skipping logging after 640 examples to avoid logging too frequently
skipping logging after 704 examples to avoid logging too frequently
skipping logging after 768 examples to avoid logging too frequently
train stats after 832 examples: {'rewards_train/chosen': '0.20005', 'rewards_train/rejected': '0.10716', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.092893', 'logps_train/rejected': '-184.22', 'logps_train/chosen': '-258.45', 'loss/train': '0.66337', 'examples_per_second': '550.55', 'grad_norm': '61.397', 'counters/examples': 832, 'counters/updates': 13}
skipping logging after 896 examples to avoid logging too frequently
skipping logging after 960 examples to avoid logging too frequently
skipping logging after 1024 examples to avoid logging too frequently
skipping logging after 1088 examples to avoid logging too frequently
skipping logging after 1152 examples to avoid logging too frequently
train stats after 1216 examples: {'rewards_train/chosen': '0.14513', 'rewards_train/rejected': '0.16976', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '-0.024627', 'logps_train/rejected': '-223.41', 'logps_train/chosen': '-246.01', 'loss/train': '0.72315', 'examples_per_second': '531.26', 'grad_norm': '71.116', 'counters/examples': 1216, 'counters/updates': 19}
skipping logging after 1280 examples to avoid logging too frequently
skipping logging after 1344 examples to avoid logging too frequently
skipping logging after 1408 examples to avoid logging too frequently
skipping logging after 1472 examples to avoid logging too frequently
skipping logging after 1536 examples to avoid logging too frequently
train stats after 1600 examples: {'rewards_train/chosen': '0.25807', 'rewards_train/rejected': '0.17401', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.084063', 'logps_train/rejected': '-231.17', 'logps_train/chosen': '-245.92', 'loss/train': '0.67168', 'examples_per_second': '545.61', 'grad_norm': '64.594', 'counters/examples': 1600, 'counters/updates': 25}
skipping logging after 1664 examples to avoid logging too frequently
skipping logging after 1728 examples to avoid logging too frequently
skipping logging after 1792 examples to avoid logging too frequently
skipping logging after 1856 examples to avoid logging too frequently
skipping logging after 1920 examples to avoid logging too frequently
train stats after 1984 examples: {'rewards_train/chosen': '0.12645', 'rewards_train/rejected': '0.12678', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.0003324', 'logps_train/rejected': '-176.29', 'logps_train/chosen': '-214.43', 'loss/train': '0.70565', 'examples_per_second': '550.09', 'grad_norm': '66.511', 'counters/examples': 1984, 'counters/updates': 31}
skipping logging after 2048 examples to avoid logging too frequently
skipping logging after 2112 examples to avoid logging too frequently
skipping logging after 2176 examples to avoid logging too frequently
skipping logging after 2240 examples to avoid logging too frequently
skipping logging after 2304 examples to avoid logging too frequently
train stats after 2368 examples: {'rewards_train/chosen': '0.1449', 'rewards_train/rejected': '0.11281', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.032096', 'logps_train/rejected': '-175.86', 'logps_train/chosen': '-203.64', 'loss/train': '0.68536', 'examples_per_second': '538.42', 'grad_norm': '60.924', 'counters/examples': 2368, 'counters/updates': 37}
skipping logging after 2432 examples to avoid logging too frequently
skipping logging after 2496 examples to avoid logging too frequently
skipping logging after 2560 examples to avoid logging too frequently
skipping logging after 2624 examples to avoid logging too frequently
skipping logging after 2688 examples to avoid logging too frequently
train stats after 2752 examples: {'rewards_train/chosen': '0.20977', 'rewards_train/rejected': '0.1117', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.098068', 'logps_train/rejected': '-188.74', 'logps_train/chosen': '-233.89', 'loss/train': '0.66111', 'examples_per_second': '568.99', 'grad_norm': '62.344', 'counters/examples': 2752, 'counters/updates': 43}
skipping logging after 2816 examples to avoid logging too frequently
skipping logging after 2880 examples to avoid logging too frequently
skipping logging after 2944 examples to avoid logging too frequently
skipping logging after 3008 examples to avoid logging too frequently
skipping logging after 3072 examples to avoid logging too frequently
train stats after 3136 examples: {'rewards_train/chosen': '0.20809', 'rewards_train/rejected': '0.12217', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.085914', 'logps_train/rejected': '-170.81', 'logps_train/chosen': '-203.49', 'loss/train': '0.66588', 'examples_per_second': '593.52', 'grad_norm': '51.262', 'counters/examples': 3136, 'counters/updates': 49}
skipping logging after 3200 examples to avoid logging too frequently
skipping logging after 3264 examples to avoid logging too frequently
skipping logging after 3328 examples to avoid logging too frequently
skipping logging after 3392 examples to avoid logging too frequently
skipping logging after 3456 examples to avoid logging too frequently
train stats after 3520 examples: {'rewards_train/chosen': '0.25671', 'rewards_train/rejected': '0.20201', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.054693', 'logps_train/rejected': '-214.52', 'logps_train/chosen': '-240.57', 'loss/train': '0.68291', 'examples_per_second': '551.23', 'grad_norm': '61.89', 'counters/examples': 3520, 'counters/updates': 55}
skipping logging after 3584 examples to avoid logging too frequently
skipping logging after 3648 examples to avoid logging too frequently
skipping logging after 3712 examples to avoid logging too frequently
skipping logging after 3776 examples to avoid logging too frequently
skipping logging after 3840 examples to avoid logging too frequently
train stats after 3904 examples: {'rewards_train/chosen': '0.27736', 'rewards_train/rejected': '0.20049', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.076867', 'logps_train/rejected': '-187.98', 'logps_train/chosen': '-224.95', 'loss/train': '0.68098', 'examples_per_second': '552.52', 'grad_norm': '55.401', 'counters/examples': 3904, 'counters/updates': 61}
skipping logging after 3968 examples to avoid logging too frequently
skipping logging after 4032 examples to avoid logging too frequently
skipping logging after 4096 examples to avoid logging too frequently
skipping logging after 4160 examples to avoid logging too frequently
skipping logging after 4224 examples to avoid logging too frequently
train stats after 4288 examples: {'rewards_train/chosen': '0.2243', 'rewards_train/rejected': '0.21174', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.01256', 'logps_train/rejected': '-201.89', 'logps_train/chosen': '-199.77', 'loss/train': '0.70051', 'examples_per_second': '550.79', 'grad_norm': '69.371', 'counters/examples': 4288, 'counters/updates': 67}
skipping logging after 4352 examples to avoid logging too frequently
skipping logging after 4416 examples to avoid logging too frequently
skipping logging after 4480 examples to avoid logging too frequently
skipping logging after 4544 examples to avoid logging too frequently
skipping logging after 4608 examples to avoid logging too frequently
train stats after 4672 examples: {'rewards_train/chosen': '0.2893', 'rewards_train/rejected': '0.23761', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.051692', 'logps_train/rejected': '-188.97', 'logps_train/chosen': '-204.2', 'loss/train': '0.68491', 'examples_per_second': '554.33', 'grad_norm': '62.163', 'counters/examples': 4672, 'counters/updates': 73}
skipping logging after 4736 examples to avoid logging too frequently
skipping logging after 4800 examples to avoid logging too frequently
skipping logging after 4864 examples to avoid logging too frequently
skipping logging after 4928 examples to avoid logging too frequently
skipping logging after 4992 examples to avoid logging too frequently
train stats after 5056 examples: {'rewards_train/chosen': '0.24197', 'rewards_train/rejected': '0.26478', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '-0.022807', 'logps_train/rejected': '-213.26', 'logps_train/chosen': '-199.21', 'loss/train': '0.73045', 'examples_per_second': '563.77', 'grad_norm': '69.281', 'counters/examples': 5056, 'counters/updates': 79}
skipping logging after 5120 examples to avoid logging too frequently
skipping logging after 5184 examples to avoid logging too frequently
skipping logging after 5248 examples to avoid logging too frequently
skipping logging after 5312 examples to avoid logging too frequently
skipping logging after 5376 examples to avoid logging too frequently
train stats after 5440 examples: {'rewards_train/chosen': '0.28364', 'rewards_train/rejected': '0.22762', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.056017', 'logps_train/rejected': '-195.14', 'logps_train/chosen': '-195.69', 'loss/train': '0.68944', 'examples_per_second': '575.24', 'grad_norm': '63.39', 'counters/examples': 5440, 'counters/updates': 85}
skipping logging after 5504 examples to avoid logging too frequently
skipping logging after 5568 examples to avoid logging too frequently
skipping logging after 5632 examples to avoid logging too frequently
skipping logging after 5696 examples to avoid logging too frequently
skipping logging after 5760 examples to avoid logging too frequently
train stats after 5824 examples: {'rewards_train/chosen': '0.37422', 'rewards_train/rejected': '0.24464', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.12959', 'logps_train/rejected': '-219.29', 'logps_train/chosen': '-258.25', 'loss/train': '0.6601', 'examples_per_second': '565.73', 'grad_norm': '58.983', 'counters/examples': 5824, 'counters/updates': 91}
skipping logging after 5888 examples to avoid logging too frequently
skipping logging after 5952 examples to avoid logging too frequently
skipping logging after 6016 examples to avoid logging too frequently
skipping logging after 6080 examples to avoid logging too frequently
skipping logging after 6144 examples to avoid logging too frequently
train stats after 6208 examples: {'rewards_train/chosen': '0.23557', 'rewards_train/rejected': '0.14667', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.088908', 'logps_train/rejected': '-198.55', 'logps_train/chosen': '-230.88', 'loss/train': '0.66612', 'examples_per_second': '596.31', 'grad_norm': '63.461', 'counters/examples': 6208, 'counters/updates': 97}
skipping logging after 6272 examples to avoid logging too frequently
skipping logging after 6336 examples to avoid logging too frequently
skipping logging after 6400 examples to avoid logging too frequently
skipping logging after 6464 examples to avoid logging too frequently
skipping logging after 6528 examples to avoid logging too frequently
train stats after 6592 examples: {'rewards_train/chosen': '0.34281', 'rewards_train/rejected': '0.29931', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.043502', 'logps_train/rejected': '-234.51', 'logps_train/chosen': '-213.15', 'loss/train': '0.70673', 'examples_per_second': '558.99', 'grad_norm': '71.208', 'counters/examples': 6592, 'counters/updates': 103}
skipping logging after 6656 examples to avoid logging too frequently
skipping logging after 6720 examples to avoid logging too frequently
skipping logging after 6784 examples to avoid logging too frequently
skipping logging after 6848 examples to avoid logging too frequently
skipping logging after 6912 examples to avoid logging too frequently
train stats after 6976 examples: {'rewards_train/chosen': '0.30542', 'rewards_train/rejected': '0.16081', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14461', 'logps_train/rejected': '-203', 'logps_train/chosen': '-259.16', 'loss/train': '0.65291', 'examples_per_second': '562.21', 'grad_norm': '53.757', 'counters/examples': 6976, 'counters/updates': 109}
skipping logging after 7040 examples to avoid logging too frequently
skipping logging after 7104 examples to avoid logging too frequently
skipping logging after 7168 examples to avoid logging too frequently
skipping logging after 7232 examples to avoid logging too frequently
skipping logging after 7296 examples to avoid logging too frequently
train stats after 7360 examples: {'rewards_train/chosen': '0.34993', 'rewards_train/rejected': '0.14843', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.20149', 'logps_train/rejected': '-173.33', 'logps_train/chosen': '-216.91', 'loss/train': '0.62562', 'examples_per_second': '584.51', 'grad_norm': '52.927', 'counters/examples': 7360, 'counters/updates': 115}
skipping logging after 7424 examples to avoid logging too frequently
skipping logging after 7488 examples to avoid logging too frequently
skipping logging after 7552 examples to avoid logging too frequently
skipping logging after 7616 examples to avoid logging too frequently
skipping logging after 7680 examples to avoid logging too frequently
train stats after 7744 examples: {'rewards_train/chosen': '0.45376', 'rewards_train/rejected': '0.22662', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.22714', 'logps_train/rejected': '-162.67', 'logps_train/chosen': '-239.72', 'loss/train': '0.61555', 'examples_per_second': '564.86', 'grad_norm': '54.035', 'counters/examples': 7744, 'counters/updates': 121}
skipping logging after 7808 examples to avoid logging too frequently
skipping logging after 7872 examples to avoid logging too frequently
skipping logging after 7936 examples to avoid logging too frequently
skipping logging after 8000 examples to avoid logging too frequently
skipping logging after 8064 examples to avoid logging too frequently
train stats after 8128 examples: {'rewards_train/chosen': '0.45712', 'rewards_train/rejected': '0.38596', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.071163', 'logps_train/rejected': '-221.93', 'logps_train/chosen': '-236.51', 'loss/train': '0.70711', 'examples_per_second': '543.98', 'grad_norm': '74.696', 'counters/examples': 8128, 'counters/updates': 127}
skipping logging after 8192 examples to avoid logging too frequently
skipping logging after 8256 examples to avoid logging too frequently
skipping logging after 8320 examples to avoid logging too frequently
skipping logging after 8384 examples to avoid logging too frequently
skipping logging after 8448 examples to avoid logging too frequently
train stats after 8512 examples: {'rewards_train/chosen': '0.49996', 'rewards_train/rejected': '0.2902', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20976', 'logps_train/rejected': '-185.29', 'logps_train/chosen': '-229.01', 'loss/train': '0.64548', 'examples_per_second': '565.56', 'grad_norm': '53.927', 'counters/examples': 8512, 'counters/updates': 133}
skipping logging after 8576 examples to avoid logging too frequently
skipping logging after 8640 examples to avoid logging too frequently
skipping logging after 8704 examples to avoid logging too frequently
skipping logging after 8768 examples to avoid logging too frequently
skipping logging after 8832 examples to avoid logging too frequently
train stats after 8896 examples: {'rewards_train/chosen': '0.31731', 'rewards_train/rejected': '0.12571', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.1916', 'logps_train/rejected': '-167.57', 'logps_train/chosen': '-220.36', 'loss/train': '0.63178', 'examples_per_second': '560.43', 'grad_norm': '46.766', 'counters/examples': 8896, 'counters/updates': 139}
skipping logging after 8960 examples to avoid logging too frequently
skipping logging after 9024 examples to avoid logging too frequently
skipping logging after 9088 examples to avoid logging too frequently
skipping logging after 9152 examples to avoid logging too frequently
train stats after 9216 examples: {'rewards_train/chosen': '0.38289', 'rewards_train/rejected': '0.29011', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.092777', 'logps_train/rejected': '-210.79', 'logps_train/chosen': '-239.55', 'loss/train': '0.67974', 'examples_per_second': '150.02', 'grad_norm': '61.359', 'counters/examples': 9216, 'counters/updates': 144}
skipping logging after 9280 examples to avoid logging too frequently
skipping logging after 9344 examples to avoid logging too frequently
skipping logging after 9408 examples to avoid logging too frequently
skipping logging after 9472 examples to avoid logging too frequently
skipping logging after 9536 examples to avoid logging too frequently
train stats after 9600 examples: {'rewards_train/chosen': '0.34257', 'rewards_train/rejected': '0.25012', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.092446', 'logps_train/rejected': '-190.05', 'logps_train/chosen': '-221.31', 'loss/train': '0.67787', 'examples_per_second': '572.95', 'grad_norm': '54.133', 'counters/examples': 9600, 'counters/updates': 150}
skipping logging after 9664 examples to avoid logging too frequently
skipping logging after 9728 examples to avoid logging too frequently
skipping logging after 9792 examples to avoid logging too frequently
skipping logging after 9856 examples to avoid logging too frequently
skipping logging after 9920 examples to avoid logging too frequently
train stats after 9984 examples: {'rewards_train/chosen': '0.41503', 'rewards_train/rejected': '0.14364', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.27139', 'logps_train/rejected': '-190.51', 'logps_train/chosen': '-218.58', 'loss/train': '0.61143', 'examples_per_second': '164.88', 'grad_norm': '62.713', 'counters/examples': 9984, 'counters/updates': 156}
skipping logging after 10048 examples to avoid logging too frequently
skipping logging after 10112 examples to avoid logging too frequently
skipping logging after 10176 examples to avoid logging too frequently
skipping logging after 10240 examples to avoid logging too frequently
skipping logging after 10304 examples to avoid logging too frequently
train stats after 10368 examples: {'rewards_train/chosen': '0.36375', 'rewards_train/rejected': '0.16669', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.19706', 'logps_train/rejected': '-166.75', 'logps_train/chosen': '-230.84', 'loss/train': '0.64399', 'examples_per_second': '567.27', 'grad_norm': '58.479', 'counters/examples': 10368, 'counters/updates': 162}
skipping logging after 10432 examples to avoid logging too frequently
skipping logging after 10496 examples to avoid logging too frequently
skipping logging after 10560 examples to avoid logging too frequently
skipping logging after 10624 examples to avoid logging too frequently
skipping logging after 10688 examples to avoid logging too frequently
train stats after 10752 examples: {'rewards_train/chosen': '0.3591', 'rewards_train/rejected': '0.15762', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.20148', 'logps_train/rejected': '-201.23', 'logps_train/chosen': '-229.89', 'loss/train': '0.63297', 'examples_per_second': '552.65', 'grad_norm': '54.678', 'counters/examples': 10752, 'counters/updates': 168}
skipping logging after 10816 examples to avoid logging too frequently
skipping logging after 10880 examples to avoid logging too frequently
skipping logging after 10944 examples to avoid logging too frequently
skipping logging after 11008 examples to avoid logging too frequently
skipping logging after 11072 examples to avoid logging too frequently
train stats after 11136 examples: {'rewards_train/chosen': '0.40909', 'rewards_train/rejected': '0.30663', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10246', 'logps_train/rejected': '-232.65', 'logps_train/chosen': '-257.3', 'loss/train': '0.69574', 'examples_per_second': '570.73', 'grad_norm': '71.37', 'counters/examples': 11136, 'counters/updates': 174}
skipping logging after 11200 examples to avoid logging too frequently
skipping logging after 11264 examples to avoid logging too frequently
skipping logging after 11328 examples to avoid logging too frequently
skipping logging after 11392 examples to avoid logging too frequently
skipping logging after 11456 examples to avoid logging too frequently
train stats after 11520 examples: {'rewards_train/chosen': '0.35642', 'rewards_train/rejected': '0.094029', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.26239', 'logps_train/rejected': '-179.5', 'logps_train/chosen': '-247.94', 'loss/train': '0.61551', 'examples_per_second': '576.92', 'grad_norm': '52.036', 'counters/examples': 11520, 'counters/updates': 180}
skipping logging after 11584 examples to avoid logging too frequently
skipping logging after 11648 examples to avoid logging too frequently
skipping logging after 11712 examples to avoid logging too frequently
skipping logging after 11776 examples to avoid logging too frequently
skipping logging after 11840 examples to avoid logging too frequently
train stats after 11904 examples: {'rewards_train/chosen': '0.21891', 'rewards_train/rejected': '0.1418', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.077113', 'logps_train/rejected': '-244.84', 'logps_train/chosen': '-231.71', 'loss/train': '0.70178', 'examples_per_second': '568.47', 'grad_norm': '77.78', 'counters/examples': 11904, 'counters/updates': 186}
skipping logging after 11968 examples to avoid logging too frequently
Running evaluation after 11968 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 30.83it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 31.05it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 31.00it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.18it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.08it/s]
eval after 11968: {'rewards_eval/chosen': '0.30847', 'rewards_eval/rejected': '0.10837', 'rewards_eval/accuracies': '0.61719', 'rewards_eval/margins': '0.2001', 'logps_eval/rejected': '-186.27', 'logps_eval/chosen': '-220.46', 'loss/eval': '0.64978'}
creating checkpoint to write to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-11968...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-11968/policy.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-11968/optimizer.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-11968/scheduler.pt...
train stats after 12032 examples: {'rewards_train/chosen': '0.31921', 'rewards_train/rejected': '0.12523', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.19399', 'logps_train/rejected': '-165.45', 'logps_train/chosen': '-228.59', 'loss/train': '0.64404', 'examples_per_second': '508.8', 'grad_norm': '62.535', 'counters/examples': 12032, 'counters/updates': 188}
skipping logging after 12096 examples to avoid logging too frequently
skipping logging after 12160 examples to avoid logging too frequently
skipping logging after 12224 examples to avoid logging too frequently
skipping logging after 12288 examples to avoid logging too frequently
skipping logging after 12352 examples to avoid logging too frequently
train stats after 12416 examples: {'rewards_train/chosen': '0.32932', 'rewards_train/rejected': '0.15544', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.17388', 'logps_train/rejected': '-176.51', 'logps_train/chosen': '-180.32', 'loss/train': '0.64416', 'examples_per_second': '567.95', 'grad_norm': '53.7', 'counters/examples': 12416, 'counters/updates': 194}
skipping logging after 12480 examples to avoid logging too frequently
skipping logging after 12544 examples to avoid logging too frequently
skipping logging after 12608 examples to avoid logging too frequently
skipping logging after 12672 examples to avoid logging too frequently
skipping logging after 12736 examples to avoid logging too frequently
train stats after 12800 examples: {'rewards_train/chosen': '0.33142', 'rewards_train/rejected': '0.046134', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.28528', 'logps_train/rejected': '-184.24', 'logps_train/chosen': '-218.79', 'loss/train': '0.60437', 'examples_per_second': '569.27', 'grad_norm': '59.911', 'counters/examples': 12800, 'counters/updates': 200}
skipping logging after 12864 examples to avoid logging too frequently
skipping logging after 12928 examples to avoid logging too frequently
skipping logging after 12992 examples to avoid logging too frequently
skipping logging after 13056 examples to avoid logging too frequently
skipping logging after 13120 examples to avoid logging too frequently
train stats after 13184 examples: {'rewards_train/chosen': '0.26869', 'rewards_train/rejected': '0.15228', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.11641', 'logps_train/rejected': '-187.91', 'logps_train/chosen': '-221.04', 'loss/train': '0.67492', 'examples_per_second': '561.52', 'grad_norm': '63.319', 'counters/examples': 13184, 'counters/updates': 206}
skipping logging after 13248 examples to avoid logging too frequently
skipping logging after 13312 examples to avoid logging too frequently
skipping logging after 13376 examples to avoid logging too frequently
skipping logging after 13440 examples to avoid logging too frequently
skipping logging after 13504 examples to avoid logging too frequently
train stats after 13568 examples: {'rewards_train/chosen': '0.36022', 'rewards_train/rejected': '0.044218', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.31601', 'logps_train/rejected': '-207.07', 'logps_train/chosen': '-222.85', 'loss/train': '0.61852', 'examples_per_second': '570.7', 'grad_norm': '53.324', 'counters/examples': 13568, 'counters/updates': 212}
skipping logging after 13632 examples to avoid logging too frequently
skipping logging after 13696 examples to avoid logging too frequently
skipping logging after 13760 examples to avoid logging too frequently
skipping logging after 13824 examples to avoid logging too frequently
skipping logging after 13888 examples to avoid logging too frequently
train stats after 13952 examples: {'rewards_train/chosen': '0.30885', 'rewards_train/rejected': '0.20263', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10622', 'logps_train/rejected': '-183.67', 'logps_train/chosen': '-216', 'loss/train': '0.68448', 'examples_per_second': '609.59', 'grad_norm': '56.158', 'counters/examples': 13952, 'counters/updates': 218}
skipping logging after 14016 examples to avoid logging too frequently
skipping logging after 14080 examples to avoid logging too frequently
skipping logging after 14144 examples to avoid logging too frequently
skipping logging after 14208 examples to avoid logging too frequently
skipping logging after 14272 examples to avoid logging too frequently
train stats after 14336 examples: {'rewards_train/chosen': '0.31847', 'rewards_train/rejected': '0.16567', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.1528', 'logps_train/rejected': '-223.13', 'logps_train/chosen': '-226.83', 'loss/train': '0.65829', 'examples_per_second': '566.68', 'grad_norm': '64.993', 'counters/examples': 14336, 'counters/updates': 224}
skipping logging after 14400 examples to avoid logging too frequently
skipping logging after 14464 examples to avoid logging too frequently
skipping logging after 14528 examples to avoid logging too frequently
skipping logging after 14592 examples to avoid logging too frequently
skipping logging after 14656 examples to avoid logging too frequently
train stats after 14720 examples: {'rewards_train/chosen': '0.19903', 'rewards_train/rejected': '0.16526', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.033776', 'logps_train/rejected': '-213.57', 'logps_train/chosen': '-234.13', 'loss/train': '0.72096', 'examples_per_second': '580.91', 'grad_norm': '66.64', 'counters/examples': 14720, 'counters/updates': 230}
skipping logging after 14784 examples to avoid logging too frequently
skipping logging after 14848 examples to avoid logging too frequently
skipping logging after 14912 examples to avoid logging too frequently
skipping logging after 14976 examples to avoid logging too frequently
skipping logging after 15040 examples to avoid logging too frequently
train stats after 15104 examples: {'rewards_train/chosen': '0.14538', 'rewards_train/rejected': '0.073717', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.071667', 'logps_train/rejected': '-195.07', 'logps_train/chosen': '-218.85', 'loss/train': '0.69793', 'examples_per_second': '558.94', 'grad_norm': '66.298', 'counters/examples': 15104, 'counters/updates': 236}
skipping logging after 15168 examples to avoid logging too frequently
skipping logging after 15232 examples to avoid logging too frequently
skipping logging after 15296 examples to avoid logging too frequently
skipping logging after 15360 examples to avoid logging too frequently
skipping logging after 15424 examples to avoid logging too frequently
train stats after 15488 examples: {'rewards_train/chosen': '0.15438', 'rewards_train/rejected': '0.082261', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.072114', 'logps_train/rejected': '-160.38', 'logps_train/chosen': '-193.09', 'loss/train': '0.69816', 'examples_per_second': '566.78', 'grad_norm': '63.976', 'counters/examples': 15488, 'counters/updates': 242}
skipping logging after 15552 examples to avoid logging too frequently
skipping logging after 15616 examples to avoid logging too frequently
skipping logging after 15680 examples to avoid logging too frequently
skipping logging after 15744 examples to avoid logging too frequently
skipping logging after 15808 examples to avoid logging too frequently
train stats after 15872 examples: {'rewards_train/chosen': '0.14603', 'rewards_train/rejected': '-0.023129', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16916', 'logps_train/rejected': '-219.27', 'logps_train/chosen': '-208.9', 'loss/train': '0.65985', 'examples_per_second': '562.64', 'grad_norm': '63.899', 'counters/examples': 15872, 'counters/updates': 248}
skipping logging after 15936 examples to avoid logging too frequently
skipping logging after 16000 examples to avoid logging too frequently
skipping logging after 16064 examples to avoid logging too frequently
skipping logging after 16128 examples to avoid logging too frequently
skipping logging after 16192 examples to avoid logging too frequently
train stats after 16256 examples: {'rewards_train/chosen': '0.14534', 'rewards_train/rejected': '0.083554', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.061783', 'logps_train/rejected': '-197.38', 'logps_train/chosen': '-212.84', 'loss/train': '0.69214', 'examples_per_second': '580.21', 'grad_norm': '67.028', 'counters/examples': 16256, 'counters/updates': 254}
skipping logging after 16320 examples to avoid logging too frequently
skipping logging after 16384 examples to avoid logging too frequently
skipping logging after 16448 examples to avoid logging too frequently
skipping logging after 16512 examples to avoid logging too frequently
skipping logging after 16576 examples to avoid logging too frequently
train stats after 16640 examples: {'rewards_train/chosen': '0.15466', 'rewards_train/rejected': '0.071036', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.083621', 'logps_train/rejected': '-197.45', 'logps_train/chosen': '-220.57', 'loss/train': '0.70139', 'examples_per_second': '550.09', 'grad_norm': '71.897', 'counters/examples': 16640, 'counters/updates': 260}
skipping logging after 16704 examples to avoid logging too frequently
skipping logging after 16768 examples to avoid logging too frequently
skipping logging after 16832 examples to avoid logging too frequently
skipping logging after 16896 examples to avoid logging too frequently
skipping logging after 16960 examples to avoid logging too frequently
train stats after 17024 examples: {'rewards_train/chosen': '0.014847', 'rewards_train/rejected': '-0.09657', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11142', 'logps_train/rejected': '-246.93', 'logps_train/chosen': '-213.89', 'loss/train': '0.68565', 'examples_per_second': '565.21', 'grad_norm': '59.541', 'counters/examples': 17024, 'counters/updates': 266}
skipping logging after 17088 examples to avoid logging too frequently
skipping logging after 17152 examples to avoid logging too frequently
skipping logging after 17216 examples to avoid logging too frequently
skipping logging after 17280 examples to avoid logging too frequently
skipping logging after 17344 examples to avoid logging too frequently
train stats after 17408 examples: {'rewards_train/chosen': '0.22948', 'rewards_train/rejected': '0.029667', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.19981', 'logps_train/rejected': '-210.21', 'logps_train/chosen': '-240.73', 'loss/train': '0.64659', 'examples_per_second': '544.84', 'grad_norm': '60.09', 'counters/examples': 17408, 'counters/updates': 272}
skipping logging after 17472 examples to avoid logging too frequently
skipping logging after 17536 examples to avoid logging too frequently
skipping logging after 17600 examples to avoid logging too frequently
skipping logging after 17664 examples to avoid logging too frequently
skipping logging after 17728 examples to avoid logging too frequently
train stats after 17792 examples: {'rewards_train/chosen': '0.097349', 'rewards_train/rejected': '-0.093321', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.19067', 'logps_train/rejected': '-162.37', 'logps_train/chosen': '-166.22', 'loss/train': '0.65301', 'examples_per_second': '586.95', 'grad_norm': '54.884', 'counters/examples': 17792, 'counters/updates': 278}
skipping logging after 17856 examples to avoid logging too frequently
skipping logging after 17920 examples to avoid logging too frequently
skipping logging after 17984 examples to avoid logging too frequently
skipping logging after 18048 examples to avoid logging too frequently
skipping logging after 18112 examples to avoid logging too frequently
train stats after 18176 examples: {'rewards_train/chosen': '0.14915', 'rewards_train/rejected': '-0.1411', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.29026', 'logps_train/rejected': '-170.46', 'logps_train/chosen': '-221.26', 'loss/train': '0.60957', 'examples_per_second': '552.48', 'grad_norm': '57.347', 'counters/examples': 18176, 'counters/updates': 284}
skipping logging after 18240 examples to avoid logging too frequently
skipping logging after 18304 examples to avoid logging too frequently
skipping logging after 18368 examples to avoid logging too frequently
skipping logging after 18432 examples to avoid logging too frequently
skipping logging after 18496 examples to avoid logging too frequently
train stats after 18560 examples: {'rewards_train/chosen': '0.11413', 'rewards_train/rejected': '-0.0017339', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11587', 'logps_train/rejected': '-188.18', 'logps_train/chosen': '-259.86', 'loss/train': '0.70026', 'examples_per_second': '569.29', 'grad_norm': '66.742', 'counters/examples': 18560, 'counters/updates': 290}
skipping logging after 18624 examples to avoid logging too frequently
skipping logging after 18688 examples to avoid logging too frequently
skipping logging after 18752 examples to avoid logging too frequently
skipping logging after 18816 examples to avoid logging too frequently
skipping logging after 18880 examples to avoid logging too frequently
train stats after 18944 examples: {'rewards_train/chosen': '0.16416', 'rewards_train/rejected': '0.10608', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.058078', 'logps_train/rejected': '-187.2', 'logps_train/chosen': '-213.28', 'loss/train': '0.72263', 'examples_per_second': '570.85', 'grad_norm': '69.933', 'counters/examples': 18944, 'counters/updates': 296}
skipping logging after 19008 examples to avoid logging too frequently
skipping logging after 19072 examples to avoid logging too frequently
skipping logging after 19136 examples to avoid logging too frequently
skipping logging after 19200 examples to avoid logging too frequently
skipping logging after 19264 examples to avoid logging too frequently
train stats after 19328 examples: {'rewards_train/chosen': '0.40846', 'rewards_train/rejected': '0.23847', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16999', 'logps_train/rejected': '-193.07', 'logps_train/chosen': '-244.59', 'loss/train': '0.65778', 'examples_per_second': '561.4', 'grad_norm': '73.226', 'counters/examples': 19328, 'counters/updates': 302}
skipping logging after 19392 examples to avoid logging too frequently
skipping logging after 19456 examples to avoid logging too frequently
skipping logging after 19520 examples to avoid logging too frequently
skipping logging after 19584 examples to avoid logging too frequently
skipping logging after 19648 examples to avoid logging too frequently
train stats after 19712 examples: {'rewards_train/chosen': '0.49581', 'rewards_train/rejected': '0.13484', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.36097', 'logps_train/rejected': '-204.47', 'logps_train/chosen': '-222.04', 'loss/train': '0.6015', 'examples_per_second': '543.52', 'grad_norm': '64.531', 'counters/examples': 19712, 'counters/updates': 308}
skipping logging after 19776 examples to avoid logging too frequently
skipping logging after 19840 examples to avoid logging too frequently
skipping logging after 19904 examples to avoid logging too frequently
skipping logging after 19968 examples to avoid logging too frequently
skipping logging after 20032 examples to avoid logging too frequently
train stats after 20096 examples: {'rewards_train/chosen': '0.43352', 'rewards_train/rejected': '0.23298', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.20054', 'logps_train/rejected': '-213.34', 'logps_train/chosen': '-240.89', 'loss/train': '0.66789', 'examples_per_second': '640.18', 'grad_norm': '54.443', 'counters/examples': 20096, 'counters/updates': 314}
skipping logging after 20160 examples to avoid logging too frequently
skipping logging after 20224 examples to avoid logging too frequently
skipping logging after 20288 examples to avoid logging too frequently
skipping logging after 20352 examples to avoid logging too frequently
skipping logging after 20416 examples to avoid logging too frequently
train stats after 20480 examples: {'rewards_train/chosen': '0.40418', 'rewards_train/rejected': '0.1693', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.23488', 'logps_train/rejected': '-249.83', 'logps_train/chosen': '-227.64', 'loss/train': '0.65455', 'examples_per_second': '568.62', 'grad_norm': '56.361', 'counters/examples': 20480, 'counters/updates': 320}
skipping logging after 20544 examples to avoid logging too frequently
skipping logging after 20608 examples to avoid logging too frequently
skipping logging after 20672 examples to avoid logging too frequently
skipping logging after 20736 examples to avoid logging too frequently
skipping logging after 20800 examples to avoid logging too frequently
train stats after 20864 examples: {'rewards_train/chosen': '0.25544', 'rewards_train/rejected': '0.053781', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.20166', 'logps_train/rejected': '-174.84', 'logps_train/chosen': '-218.8', 'loss/train': '0.64259', 'examples_per_second': '540.56', 'grad_norm': '56.209', 'counters/examples': 20864, 'counters/updates': 326}
skipping logging after 20928 examples to avoid logging too frequently
skipping logging after 20992 examples to avoid logging too frequently
skipping logging after 21056 examples to avoid logging too frequently
skipping logging after 21120 examples to avoid logging too frequently
skipping logging after 21184 examples to avoid logging too frequently
train stats after 21248 examples: {'rewards_train/chosen': '0.38892', 'rewards_train/rejected': '0.2275', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16142', 'logps_train/rejected': '-176.53', 'logps_train/chosen': '-188.46', 'loss/train': '0.67064', 'examples_per_second': '582.32', 'grad_norm': '55.157', 'counters/examples': 21248, 'counters/updates': 332}
skipping logging after 21312 examples to avoid logging too frequently
skipping logging after 21376 examples to avoid logging too frequently
skipping logging after 21440 examples to avoid logging too frequently
skipping logging after 21504 examples to avoid logging too frequently
skipping logging after 21568 examples to avoid logging too frequently
train stats after 21632 examples: {'rewards_train/chosen': '0.33202', 'rewards_train/rejected': '0.1658', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.16622', 'logps_train/rejected': '-176.7', 'logps_train/chosen': '-210.4', 'loss/train': '0.66321', 'examples_per_second': '566.95', 'grad_norm': '55.028', 'counters/examples': 21632, 'counters/updates': 338}
skipping logging after 21696 examples to avoid logging too frequently
skipping logging after 21760 examples to avoid logging too frequently
skipping logging after 21824 examples to avoid logging too frequently
skipping logging after 21888 examples to avoid logging too frequently
skipping logging after 21952 examples to avoid logging too frequently
train stats after 22016 examples: {'rewards_train/chosen': '0.36632', 'rewards_train/rejected': '0.1557', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.21061', 'logps_train/rejected': '-231.33', 'logps_train/chosen': '-209.16', 'loss/train': '0.68821', 'examples_per_second': '562.56', 'grad_norm': '73.036', 'counters/examples': 22016, 'counters/updates': 344}
skipping logging after 22080 examples to avoid logging too frequently
skipping logging after 22144 examples to avoid logging too frequently
skipping logging after 22208 examples to avoid logging too frequently
skipping logging after 22272 examples to avoid logging too frequently
skipping logging after 22336 examples to avoid logging too frequently
train stats after 22400 examples: {'rewards_train/chosen': '0.32659', 'rewards_train/rejected': '0.089717', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.23687', 'logps_train/rejected': '-173.52', 'logps_train/chosen': '-241.71', 'loss/train': '0.64342', 'examples_per_second': '567.34', 'grad_norm': '61.41', 'counters/examples': 22400, 'counters/updates': 350}
skipping logging after 22464 examples to avoid logging too frequently
skipping logging after 22528 examples to avoid logging too frequently
skipping logging after 22592 examples to avoid logging too frequently
skipping logging after 22656 examples to avoid logging too frequently
skipping logging after 22720 examples to avoid logging too frequently
train stats after 22784 examples: {'rewards_train/chosen': '0.21313', 'rewards_train/rejected': '0.048416', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16472', 'logps_train/rejected': '-194.28', 'logps_train/chosen': '-217.32', 'loss/train': '0.67085', 'examples_per_second': '599.76', 'grad_norm': '61.831', 'counters/examples': 22784, 'counters/updates': 356}
skipping logging after 22848 examples to avoid logging too frequently
skipping logging after 22912 examples to avoid logging too frequently
skipping logging after 22976 examples to avoid logging too frequently
skipping logging after 23040 examples to avoid logging too frequently
skipping logging after 23104 examples to avoid logging too frequently
train stats after 23168 examples: {'rewards_train/chosen': '0.29481', 'rewards_train/rejected': '0.055239', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.23958', 'logps_train/rejected': '-202.11', 'logps_train/chosen': '-250.21', 'loss/train': '0.62486', 'examples_per_second': '567.15', 'grad_norm': '62.255', 'counters/examples': 23168, 'counters/updates': 362}
skipping logging after 23232 examples to avoid logging too frequently
skipping logging after 23296 examples to avoid logging too frequently
skipping logging after 23360 examples to avoid logging too frequently
skipping logging after 23424 examples to avoid logging too frequently
skipping logging after 23488 examples to avoid logging too frequently
train stats after 23552 examples: {'rewards_train/chosen': '0.29077', 'rewards_train/rejected': '-0.050289', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.34106', 'logps_train/rejected': '-203.49', 'logps_train/chosen': '-207.7', 'loss/train': '0.63607', 'examples_per_second': '570.65', 'grad_norm': '58.592', 'counters/examples': 23552, 'counters/updates': 368}
skipping logging after 23616 examples to avoid logging too frequently
skipping logging after 23680 examples to avoid logging too frequently
skipping logging after 23744 examples to avoid logging too frequently
skipping logging after 23808 examples to avoid logging too frequently
skipping logging after 23872 examples to avoid logging too frequently
train stats after 23936 examples: {'rewards_train/chosen': '0.14752', 'rewards_train/rejected': '0.058496', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.089024', 'logps_train/rejected': '-183.76', 'logps_train/chosen': '-200.92', 'loss/train': '0.68761', 'examples_per_second': '572.28', 'grad_norm': '56.213', 'counters/examples': 23936, 'counters/updates': 374}
Running evaluation after 23936 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 31.80it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 31.65it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 31.83it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.83it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.78it/s]
eval after 23936: {'rewards_eval/chosen': '0.28388', 'rewards_eval/rejected': '0.1034', 'rewards_eval/accuracies': '0.60156', 'rewards_eval/margins': '0.18048', 'logps_eval/rejected': '-186.32', 'logps_eval/chosen': '-220.71', 'loss/eval': '0.66836'}
creating checkpoint to write to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-23936...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-23936/policy.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-23936/optimizer.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-23936/scheduler.pt...
train stats after 24000 examples: {'rewards_train/chosen': '0.1294', 'rewards_train/rejected': '0.076433', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.052972', 'logps_train/rejected': '-176.26', 'logps_train/chosen': '-212.35', 'loss/train': '0.72977', 'examples_per_second': '502.04', 'grad_norm': '63.852', 'counters/examples': 24000, 'counters/updates': 375}
skipping logging after 24064 examples to avoid logging too frequently
skipping logging after 24128 examples to avoid logging too frequently
skipping logging after 24192 examples to avoid logging too frequently
skipping logging after 24256 examples to avoid logging too frequently
skipping logging after 24320 examples to avoid logging too frequently
train stats after 24384 examples: {'rewards_train/chosen': '0.32475', 'rewards_train/rejected': '0.085522', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.23923', 'logps_train/rejected': '-197.4', 'logps_train/chosen': '-226.44', 'loss/train': '0.62831', 'examples_per_second': '563.91', 'grad_norm': '51.393', 'counters/examples': 24384, 'counters/updates': 381}
skipping logging after 24448 examples to avoid logging too frequently
skipping logging after 24512 examples to avoid logging too frequently
skipping logging after 24576 examples to avoid logging too frequently
skipping logging after 24640 examples to avoid logging too frequently
skipping logging after 24704 examples to avoid logging too frequently
train stats after 24768 examples: {'rewards_train/chosen': '0.35328', 'rewards_train/rejected': '0.18654', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16674', 'logps_train/rejected': '-214.53', 'logps_train/chosen': '-215.9', 'loss/train': '0.69079', 'examples_per_second': '588.77', 'grad_norm': '65.334', 'counters/examples': 24768, 'counters/updates': 387}
skipping logging after 24832 examples to avoid logging too frequently
skipping logging after 24896 examples to avoid logging too frequently
skipping logging after 24960 examples to avoid logging too frequently
skipping logging after 25024 examples to avoid logging too frequently
skipping logging after 25088 examples to avoid logging too frequently
train stats after 25152 examples: {'rewards_train/chosen': '0.35399', 'rewards_train/rejected': '0.080057', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.27393', 'logps_train/rejected': '-195.49', 'logps_train/chosen': '-200.28', 'loss/train': '0.63253', 'examples_per_second': '568.66', 'grad_norm': '54.128', 'counters/examples': 25152, 'counters/updates': 393}
skipping logging after 25216 examples to avoid logging too frequently
skipping logging after 25280 examples to avoid logging too frequently
skipping logging after 25344 examples to avoid logging too frequently
skipping logging after 25408 examples to avoid logging too frequently
skipping logging after 25472 examples to avoid logging too frequently
train stats after 25536 examples: {'rewards_train/chosen': '0.18473', 'rewards_train/rejected': '0.019001', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.16573', 'logps_train/rejected': '-171.91', 'logps_train/chosen': '-217.77', 'loss/train': '0.68285', 'examples_per_second': '555.4', 'grad_norm': '61.073', 'counters/examples': 25536, 'counters/updates': 399}
skipping logging after 25600 examples to avoid logging too frequently
skipping logging after 25664 examples to avoid logging too frequently
skipping logging after 25728 examples to avoid logging too frequently
skipping logging after 25792 examples to avoid logging too frequently
skipping logging after 25856 examples to avoid logging too frequently
train stats after 25920 examples: {'rewards_train/chosen': '0.47484', 'rewards_train/rejected': '0.13693', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.33791', 'logps_train/rejected': '-200.84', 'logps_train/chosen': '-250.28', 'loss/train': '0.6031', 'examples_per_second': '561.06', 'grad_norm': '61.376', 'counters/examples': 25920, 'counters/updates': 405}
skipping logging after 25984 examples to avoid logging too frequently
skipping logging after 26048 examples to avoid logging too frequently
skipping logging after 26112 examples to avoid logging too frequently
skipping logging after 26176 examples to avoid logging too frequently
skipping logging after 26240 examples to avoid logging too frequently
train stats after 26304 examples: {'rewards_train/chosen': '0.40177', 'rewards_train/rejected': '0.095275', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.3065', 'logps_train/rejected': '-174.39', 'logps_train/chosen': '-242.92', 'loss/train': '0.61927', 'examples_per_second': '592.65', 'grad_norm': '49.95', 'counters/examples': 26304, 'counters/updates': 411}
skipping logging after 26368 examples to avoid logging too frequently
skipping logging after 26432 examples to avoid logging too frequently
skipping logging after 26496 examples to avoid logging too frequently
skipping logging after 26560 examples to avoid logging too frequently
skipping logging after 26624 examples to avoid logging too frequently
train stats after 26688 examples: {'rewards_train/chosen': '0.56363', 'rewards_train/rejected': '0.20277', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.36086', 'logps_train/rejected': '-227.73', 'logps_train/chosen': '-263.94', 'loss/train': '0.58099', 'examples_per_second': '560.73', 'grad_norm': '52.301', 'counters/examples': 26688, 'counters/updates': 417}
skipping logging after 26752 examples to avoid logging too frequently
skipping logging after 26816 examples to avoid logging too frequently
skipping logging after 26880 examples to avoid logging too frequently
skipping logging after 26944 examples to avoid logging too frequently
skipping logging after 27008 examples to avoid logging too frequently
train stats after 27072 examples: {'rewards_train/chosen': '0.3179', 'rewards_train/rejected': '0.11478', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.20312', 'logps_train/rejected': '-169.77', 'logps_train/chosen': '-224.24', 'loss/train': '0.64844', 'examples_per_second': '557.33', 'grad_norm': '52.987', 'counters/examples': 27072, 'counters/updates': 423}
skipping logging after 27136 examples to avoid logging too frequently
skipping logging after 27200 examples to avoid logging too frequently
skipping logging after 27264 examples to avoid logging too frequently
skipping logging after 27328 examples to avoid logging too frequently
skipping logging after 27392 examples to avoid logging too frequently
train stats after 27456 examples: {'rewards_train/chosen': '0.48838', 'rewards_train/rejected': '0.29393', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.19445', 'logps_train/rejected': '-240.76', 'logps_train/chosen': '-290.85', 'loss/train': '0.70862', 'examples_per_second': '534.62', 'grad_norm': '83.758', 'counters/examples': 27456, 'counters/updates': 429}
skipping logging after 27520 examples to avoid logging too frequently
skipping logging after 27584 examples to avoid logging too frequently
skipping logging after 27648 examples to avoid logging too frequently
skipping logging after 27712 examples to avoid logging too frequently
skipping logging after 27776 examples to avoid logging too frequently
train stats after 27840 examples: {'rewards_train/chosen': '0.30597', 'rewards_train/rejected': '-0.0088545', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.31483', 'logps_train/rejected': '-182.83', 'logps_train/chosen': '-209.6', 'loss/train': '0.60023', 'examples_per_second': '548.65', 'grad_norm': '57.284', 'counters/examples': 27840, 'counters/updates': 435}
skipping logging after 27904 examples to avoid logging too frequently
skipping logging after 27968 examples to avoid logging too frequently
skipping logging after 28032 examples to avoid logging too frequently
skipping logging after 28096 examples to avoid logging too frequently
skipping logging after 28160 examples to avoid logging too frequently
train stats after 28224 examples: {'rewards_train/chosen': '0.27521', 'rewards_train/rejected': '-0.035043', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.31026', 'logps_train/rejected': '-170.81', 'logps_train/chosen': '-221.02', 'loss/train': '0.60469', 'examples_per_second': '536.32', 'grad_norm': '53.18', 'counters/examples': 28224, 'counters/updates': 441}
skipping logging after 28288 examples to avoid logging too frequently
skipping logging after 28352 examples to avoid logging too frequently
skipping logging after 28416 examples to avoid logging too frequently
skipping logging after 28480 examples to avoid logging too frequently
skipping logging after 28544 examples to avoid logging too frequently
train stats after 28608 examples: {'rewards_train/chosen': '0.42748', 'rewards_train/rejected': '0.072891', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.35459', 'logps_train/rejected': '-186.94', 'logps_train/chosen': '-255.86', 'loss/train': '0.6265', 'examples_per_second': '592.81', 'grad_norm': '61.057', 'counters/examples': 28608, 'counters/updates': 447}
skipping logging after 28672 examples to avoid logging too frequently
skipping logging after 28736 examples to avoid logging too frequently
skipping logging after 28800 examples to avoid logging too frequently
skipping logging after 28864 examples to avoid logging too frequently
skipping logging after 28928 examples to avoid logging too frequently
train stats after 28992 examples: {'rewards_train/chosen': '0.31965', 'rewards_train/rejected': '-0.10096', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.42061', 'logps_train/rejected': '-163.95', 'logps_train/chosen': '-194.95', 'loss/train': '0.58393', 'examples_per_second': '580.13', 'grad_norm': '53.051', 'counters/examples': 28992, 'counters/updates': 453}
skipping logging after 29056 examples to avoid logging too frequently
skipping logging after 29120 examples to avoid logging too frequently
skipping logging after 29184 examples to avoid logging too frequently
skipping logging after 29248 examples to avoid logging too frequently
skipping logging after 29312 examples to avoid logging too frequently
train stats after 29376 examples: {'rewards_train/chosen': '0.29997', 'rewards_train/rejected': '-0.020914', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.32089', 'logps_train/rejected': '-178.2', 'logps_train/chosen': '-236.46', 'loss/train': '0.61583', 'examples_per_second': '552.33', 'grad_norm': '56.974', 'counters/examples': 29376, 'counters/updates': 459}
skipping logging after 29440 examples to avoid logging too frequently
skipping logging after 29504 examples to avoid logging too frequently
skipping logging after 29568 examples to avoid logging too frequently
skipping logging after 29632 examples to avoid logging too frequently
skipping logging after 29696 examples to avoid logging too frequently
train stats after 29760 examples: {'rewards_train/chosen': '0.49864', 'rewards_train/rejected': '0.21184', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.28679', 'logps_train/rejected': '-226.66', 'logps_train/chosen': '-216.2', 'loss/train': '0.651', 'examples_per_second': '550.69', 'grad_norm': '72.767', 'counters/examples': 29760, 'counters/updates': 465}
skipping logging after 29824 examples to avoid logging too frequently
skipping logging after 29888 examples to avoid logging too frequently
skipping logging after 29952 examples to avoid logging too frequently
skipping logging after 30016 examples to avoid logging too frequently
skipping logging after 30080 examples to avoid logging too frequently
train stats after 30144 examples: {'rewards_train/chosen': '0.12676', 'rewards_train/rejected': '-0.077396', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.20416', 'logps_train/rejected': '-198.11', 'logps_train/chosen': '-205.73', 'loss/train': '0.66558', 'examples_per_second': '565.51', 'grad_norm': '55.694', 'counters/examples': 30144, 'counters/updates': 471}
skipping logging after 30208 examples to avoid logging too frequently
skipping logging after 30272 examples to avoid logging too frequently
skipping logging after 30336 examples to avoid logging too frequently
skipping logging after 30400 examples to avoid logging too frequently
skipping logging after 30464 examples to avoid logging too frequently
train stats after 30528 examples: {'rewards_train/chosen': '0.50327', 'rewards_train/rejected': '0.12762', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.37565', 'logps_train/rejected': '-194.03', 'logps_train/chosen': '-206.91', 'loss/train': '0.60073', 'examples_per_second': '559.75', 'grad_norm': '64.471', 'counters/examples': 30528, 'counters/updates': 477}
skipping logging after 30592 examples to avoid logging too frequently
skipping logging after 30656 examples to avoid logging too frequently
skipping logging after 30720 examples to avoid logging too frequently
skipping logging after 30784 examples to avoid logging too frequently
skipping logging after 30848 examples to avoid logging too frequently
train stats after 30912 examples: {'rewards_train/chosen': '0.504', 'rewards_train/rejected': '0.11325', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.39075', 'logps_train/rejected': '-182.97', 'logps_train/chosen': '-241.74', 'loss/train': '0.60813', 'examples_per_second': '569.7', 'grad_norm': '51.632', 'counters/examples': 30912, 'counters/updates': 483}
skipping logging after 30976 examples to avoid logging too frequently
skipping logging after 31040 examples to avoid logging too frequently
skipping logging after 31104 examples to avoid logging too frequently
skipping logging after 31168 examples to avoid logging too frequently
skipping logging after 31232 examples to avoid logging too frequently
train stats after 31296 examples: {'rewards_train/chosen': '0.45776', 'rewards_train/rejected': '0.13841', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.31934', 'logps_train/rejected': '-181.77', 'logps_train/chosen': '-231.05', 'loss/train': '0.6182', 'examples_per_second': '563.94', 'grad_norm': '62.414', 'counters/examples': 31296, 'counters/updates': 489}
skipping logging after 31360 examples to avoid logging too frequently
skipping logging after 31424 examples to avoid logging too frequently
skipping logging after 31488 examples to avoid logging too frequently
skipping logging after 31552 examples to avoid logging too frequently
skipping logging after 31616 examples to avoid logging too frequently
train stats after 31680 examples: {'rewards_train/chosen': '0.33165', 'rewards_train/rejected': '0.27475', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.056903', 'logps_train/rejected': '-199.24', 'logps_train/chosen': '-240.11', 'loss/train': '0.76084', 'examples_per_second': '570.81', 'grad_norm': '80.848', 'counters/examples': 31680, 'counters/updates': 495}
skipping logging after 31744 examples to avoid logging too frequently
skipping logging after 31808 examples to avoid logging too frequently
skipping logging after 31872 examples to avoid logging too frequently
skipping logging after 31936 examples to avoid logging too frequently
skipping logging after 32000 examples to avoid logging too frequently
train stats after 32064 examples: {'rewards_train/chosen': '0.45965', 'rewards_train/rejected': '0.27352', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.18613', 'logps_train/rejected': '-204.17', 'logps_train/chosen': '-235.11', 'loss/train': '0.69882', 'examples_per_second': '570.08', 'grad_norm': '66.3', 'counters/examples': 32064, 'counters/updates': 501}
skipping logging after 32128 examples to avoid logging too frequently
skipping logging after 32192 examples to avoid logging too frequently
skipping logging after 32256 examples to avoid logging too frequently
skipping logging after 32320 examples to avoid logging too frequently
skipping logging after 32384 examples to avoid logging too frequently
train stats after 32448 examples: {'rewards_train/chosen': '0.45208', 'rewards_train/rejected': '0.10069', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.35139', 'logps_train/rejected': '-208.54', 'logps_train/chosen': '-232.89', 'loss/train': '0.60169', 'examples_per_second': '570.85', 'grad_norm': '73.579', 'counters/examples': 32448, 'counters/updates': 507}
skipping logging after 32512 examples to avoid logging too frequently
skipping logging after 32576 examples to avoid logging too frequently
skipping logging after 32640 examples to avoid logging too frequently
skipping logging after 32704 examples to avoid logging too frequently
skipping logging after 32768 examples to avoid logging too frequently
train stats after 32832 examples: {'rewards_train/chosen': '0.32243', 'rewards_train/rejected': '0.04441', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.27802', 'logps_train/rejected': '-196.42', 'logps_train/chosen': '-207.7', 'loss/train': '0.63322', 'examples_per_second': '570.89', 'grad_norm': '64.431', 'counters/examples': 32832, 'counters/updates': 513}
skipping logging after 32896 examples to avoid logging too frequently
skipping logging after 32960 examples to avoid logging too frequently
skipping logging after 33024 examples to avoid logging too frequently
skipping logging after 33088 examples to avoid logging too frequently
skipping logging after 33152 examples to avoid logging too frequently
train stats after 33216 examples: {'rewards_train/chosen': '0.30618', 'rewards_train/rejected': '0.082988', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.22319', 'logps_train/rejected': '-206.19', 'logps_train/chosen': '-215.93', 'loss/train': '0.66807', 'examples_per_second': '567.95', 'grad_norm': '60.934', 'counters/examples': 33216, 'counters/updates': 519}
skipping logging after 33280 examples to avoid logging too frequently
skipping logging after 33344 examples to avoid logging too frequently
skipping logging after 33408 examples to avoid logging too frequently
skipping logging after 33472 examples to avoid logging too frequently
skipping logging after 33536 examples to avoid logging too frequently
train stats after 33600 examples: {'rewards_train/chosen': '0.42066', 'rewards_train/rejected': '0.21488', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.20577', 'logps_train/rejected': '-172.66', 'logps_train/chosen': '-243.78', 'loss/train': '0.66755', 'examples_per_second': '566.03', 'grad_norm': '67.094', 'counters/examples': 33600, 'counters/updates': 525}
skipping logging after 33664 examples to avoid logging too frequently
skipping logging after 33728 examples to avoid logging too frequently
skipping logging after 33792 examples to avoid logging too frequently
skipping logging after 33856 examples to avoid logging too frequently
skipping logging after 33920 examples to avoid logging too frequently
train stats after 33984 examples: {'rewards_train/chosen': '0.38614', 'rewards_train/rejected': '0.10401', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.28213', 'logps_train/rejected': '-174.57', 'logps_train/chosen': '-232.42', 'loss/train': '0.61401', 'examples_per_second': '569.78', 'grad_norm': '61.168', 'counters/examples': 33984, 'counters/updates': 531}
skipping logging after 34048 examples to avoid logging too frequently
skipping logging after 34112 examples to avoid logging too frequently
skipping logging after 34176 examples to avoid logging too frequently
skipping logging after 34240 examples to avoid logging too frequently
skipping logging after 34304 examples to avoid logging too frequently
train stats after 34368 examples: {'rewards_train/chosen': '0.22912', 'rewards_train/rejected': '-0.017215', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.24634', 'logps_train/rejected': '-186.32', 'logps_train/chosen': '-201.1', 'loss/train': '0.65431', 'examples_per_second': '568.82', 'grad_norm': '52.211', 'counters/examples': 34368, 'counters/updates': 537}
skipping logging after 34432 examples to avoid logging too frequently
skipping logging after 34496 examples to avoid logging too frequently
skipping logging after 34560 examples to avoid logging too frequently
skipping logging after 34624 examples to avoid logging too frequently
skipping logging after 34688 examples to avoid logging too frequently
train stats after 34752 examples: {'rewards_train/chosen': '0.4543', 'rewards_train/rejected': '0.14361', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.31069', 'logps_train/rejected': '-175.66', 'logps_train/chosen': '-196.67', 'loss/train': '0.61057', 'examples_per_second': '582.68', 'grad_norm': '51.627', 'counters/examples': 34752, 'counters/updates': 543}
skipping logging after 34816 examples to avoid logging too frequently
skipping logging after 34880 examples to avoid logging too frequently
skipping logging after 34944 examples to avoid logging too frequently
skipping logging after 35008 examples to avoid logging too frequently
skipping logging after 35072 examples to avoid logging too frequently
train stats after 35136 examples: {'rewards_train/chosen': '0.28202', 'rewards_train/rejected': '0.066483', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21553', 'logps_train/rejected': '-181.78', 'logps_train/chosen': '-208.37', 'loss/train': '0.65564', 'examples_per_second': '574.9', 'grad_norm': '56.356', 'counters/examples': 35136, 'counters/updates': 549}
skipping logging after 35200 examples to avoid logging too frequently
skipping logging after 35264 examples to avoid logging too frequently
skipping logging after 35328 examples to avoid logging too frequently
skipping logging after 35392 examples to avoid logging too frequently
skipping logging after 35456 examples to avoid logging too frequently
train stats after 35520 examples: {'rewards_train/chosen': '0.39532', 'rewards_train/rejected': '-0.11602', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.51134', 'logps_train/rejected': '-179.34', 'logps_train/chosen': '-235.45', 'loss/train': '0.54254', 'examples_per_second': '567.71', 'grad_norm': '50.579', 'counters/examples': 35520, 'counters/updates': 555}
skipping logging after 35584 examples to avoid logging too frequently
skipping logging after 35648 examples to avoid logging too frequently
skipping logging after 35712 examples to avoid logging too frequently
skipping logging after 35776 examples to avoid logging too frequently
skipping logging after 35840 examples to avoid logging too frequently
train stats after 35904 examples: {'rewards_train/chosen': '0.39696', 'rewards_train/rejected': '-0.076552', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.47351', 'logps_train/rejected': '-194.22', 'logps_train/chosen': '-229.92', 'loss/train': '0.57688', 'examples_per_second': '604.08', 'grad_norm': '48.978', 'counters/examples': 35904, 'counters/updates': 561}
Running evaluation after 35904 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 31.35it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 31.20it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 31.52it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.56it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.47it/s]
eval after 35904: {'rewards_eval/chosen': '0.2888', 'rewards_eval/rejected': '0.099756', 'rewards_eval/accuracies': '0.59375', 'rewards_eval/margins': '0.18904', 'logps_eval/rejected': '-186.36', 'logps_eval/chosen': '-220.66', 'loss/eval': '0.67201'}
creating checkpoint to write to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-35904...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-35904/policy.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-35904/optimizer.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-35904/scheduler.pt...
train stats after 35968 examples: {'rewards_train/chosen': '0.28368', 'rewards_train/rejected': '-0.065956', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.34963', 'logps_train/rejected': '-163.82', 'logps_train/chosen': '-190.56', 'loss/train': '0.57503', 'examples_per_second': '488.72', 'grad_norm': '45.596', 'counters/examples': 35968, 'counters/updates': 562}
skipping logging after 36032 examples to avoid logging too frequently
skipping logging after 36096 examples to avoid logging too frequently
skipping logging after 36160 examples to avoid logging too frequently
skipping logging after 36224 examples to avoid logging too frequently
skipping logging after 36288 examples to avoid logging too frequently
train stats after 36352 examples: {'rewards_train/chosen': '0.31367', 'rewards_train/rejected': '-0.0074452', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.32112', 'logps_train/rejected': '-192.44', 'logps_train/chosen': '-237.97', 'loss/train': '0.63123', 'examples_per_second': '588.61', 'grad_norm': '65.808', 'counters/examples': 36352, 'counters/updates': 568}
skipping logging after 36416 examples to avoid logging too frequently
skipping logging after 36480 examples to avoid logging too frequently
skipping logging after 36544 examples to avoid logging too frequently
skipping logging after 36608 examples to avoid logging too frequently
skipping logging after 36672 examples to avoid logging too frequently
train stats after 36736 examples: {'rewards_train/chosen': '0.22343', 'rewards_train/rejected': '0.025804', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19762', 'logps_train/rejected': '-153.69', 'logps_train/chosen': '-230.29', 'loss/train': '0.67613', 'examples_per_second': '563.26', 'grad_norm': '59.879', 'counters/examples': 36736, 'counters/updates': 574}
skipping logging after 36800 examples to avoid logging too frequently
skipping logging after 36864 examples to avoid logging too frequently
skipping logging after 36928 examples to avoid logging too frequently
skipping logging after 36992 examples to avoid logging too frequently
skipping logging after 37056 examples to avoid logging too frequently
train stats after 37120 examples: {'rewards_train/chosen': '0.2946', 'rewards_train/rejected': '-0.046608', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.34121', 'logps_train/rejected': '-190.91', 'logps_train/chosen': '-242.1', 'loss/train': '0.60973', 'examples_per_second': '622.69', 'grad_norm': '61.424', 'counters/examples': 37120, 'counters/updates': 580}
skipping logging after 37184 examples to avoid logging too frequently
skipping logging after 37248 examples to avoid logging too frequently
skipping logging after 37312 examples to avoid logging too frequently
skipping logging after 37376 examples to avoid logging too frequently
skipping logging after 37440 examples to avoid logging too frequently
train stats after 37504 examples: {'rewards_train/chosen': '0.30802', 'rewards_train/rejected': '0.09336', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.21466', 'logps_train/rejected': '-193.33', 'logps_train/chosen': '-208.52', 'loss/train': '0.64241', 'examples_per_second': '554.8', 'grad_norm': '59.36', 'counters/examples': 37504, 'counters/updates': 586}
skipping logging after 37568 examples to avoid logging too frequently
skipping logging after 37632 examples to avoid logging too frequently
skipping logging after 37696 examples to avoid logging too frequently
skipping logging after 37760 examples to avoid logging too frequently
skipping logging after 37824 examples to avoid logging too frequently
train stats after 37888 examples: {'rewards_train/chosen': '0.42594', 'rewards_train/rejected': '0.16858', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25737', 'logps_train/rejected': '-167.42', 'logps_train/chosen': '-231.69', 'loss/train': '0.65686', 'examples_per_second': '553.15', 'grad_norm': '55.114', 'counters/examples': 37888, 'counters/updates': 592}
skipping logging after 37952 examples to avoid logging too frequently
skipping logging after 38016 examples to avoid logging too frequently
skipping logging after 38080 examples to avoid logging too frequently
skipping logging after 38144 examples to avoid logging too frequently
skipping logging after 38208 examples to avoid logging too frequently
train stats after 38272 examples: {'rewards_train/chosen': '0.47604', 'rewards_train/rejected': '0.25383', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.22221', 'logps_train/rejected': '-184.76', 'logps_train/chosen': '-224.21', 'loss/train': '0.66175', 'examples_per_second': '554.39', 'grad_norm': '55.508', 'counters/examples': 38272, 'counters/updates': 598}
skipping logging after 38336 examples to avoid logging too frequently
skipping logging after 38400 examples to avoid logging too frequently
skipping logging after 38464 examples to avoid logging too frequently
skipping logging after 38528 examples to avoid logging too frequently
skipping logging after 38592 examples to avoid logging too frequently
train stats after 38656 examples: {'rewards_train/chosen': '0.39319', 'rewards_train/rejected': '0.23362', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.15958', 'logps_train/rejected': '-192.35', 'logps_train/chosen': '-227.94', 'loss/train': '0.70492', 'examples_per_second': '554.07', 'grad_norm': '68.413', 'counters/examples': 38656, 'counters/updates': 604}
skipping logging after 38720 examples to avoid logging too frequently
skipping logging after 38784 examples to avoid logging too frequently
skipping logging after 38848 examples to avoid logging too frequently
skipping logging after 38912 examples to avoid logging too frequently
skipping logging after 38976 examples to avoid logging too frequently
train stats after 39040 examples: {'rewards_train/chosen': '0.41045', 'rewards_train/rejected': '0.077629', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.33282', 'logps_train/rejected': '-208.03', 'logps_train/chosen': '-209.73', 'loss/train': '0.63972', 'examples_per_second': '564.22', 'grad_norm': '69.182', 'counters/examples': 39040, 'counters/updates': 610}
skipping logging after 39104 examples to avoid logging too frequently
skipping logging after 39168 examples to avoid logging too frequently
skipping logging after 39232 examples to avoid logging too frequently
skipping logging after 39296 examples to avoid logging too frequently
skipping logging after 39360 examples to avoid logging too frequently
train stats after 39424 examples: {'rewards_train/chosen': '0.36238', 'rewards_train/rejected': '0.11541', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.24697', 'logps_train/rejected': '-174.43', 'logps_train/chosen': '-204.66', 'loss/train': '0.64603', 'examples_per_second': '563.3', 'grad_norm': '65.292', 'counters/examples': 39424, 'counters/updates': 616}
skipping logging after 39488 examples to avoid logging too frequently
skipping logging after 39552 examples to avoid logging too frequently
skipping logging after 39616 examples to avoid logging too frequently
skipping logging after 39680 examples to avoid logging too frequently
skipping logging after 39744 examples to avoid logging too frequently
train stats after 39808 examples: {'rewards_train/chosen': '0.32466', 'rewards_train/rejected': '0.16822', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15644', 'logps_train/rejected': '-201.29', 'logps_train/chosen': '-217.95', 'loss/train': '0.70397', 'examples_per_second': '584.56', 'grad_norm': '68.31', 'counters/examples': 39808, 'counters/updates': 622}
skipping logging after 39872 examples to avoid logging too frequently
skipping logging after 39936 examples to avoid logging too frequently
skipping logging after 40000 examples to avoid logging too frequently
skipping logging after 40064 examples to avoid logging too frequently
skipping logging after 40128 examples to avoid logging too frequently
train stats after 40192 examples: {'rewards_train/chosen': '0.33927', 'rewards_train/rejected': '0.095549', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.24372', 'logps_train/rejected': '-180.73', 'logps_train/chosen': '-226.64', 'loss/train': '0.63421', 'examples_per_second': '595.11', 'grad_norm': '56.466', 'counters/examples': 40192, 'counters/updates': 628}
skipping logging after 40256 examples to avoid logging too frequently
skipping logging after 40320 examples to avoid logging too frequently
skipping logging after 40384 examples to avoid logging too frequently
skipping logging after 40448 examples to avoid logging too frequently
skipping logging after 40512 examples to avoid logging too frequently
train stats after 40576 examples: {'rewards_train/chosen': '0.2857', 'rewards_train/rejected': '0.10969', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.17601', 'logps_train/rejected': '-196.16', 'logps_train/chosen': '-232.33', 'loss/train': '0.68831', 'examples_per_second': '566.58', 'grad_norm': '57.382', 'counters/examples': 40576, 'counters/updates': 634}
skipping logging after 40640 examples to avoid logging too frequently
skipping logging after 40704 examples to avoid logging too frequently
skipping logging after 40768 examples to avoid logging too frequently
skipping logging after 40832 examples to avoid logging too frequently
skipping logging after 40896 examples to avoid logging too frequently
train stats after 40960 examples: {'rewards_train/chosen': '0.39018', 'rewards_train/rejected': '0.099806', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.29037', 'logps_train/rejected': '-201.34', 'logps_train/chosen': '-197.36', 'loss/train': '0.6206', 'examples_per_second': '584.62', 'grad_norm': '51.253', 'counters/examples': 40960, 'counters/updates': 640}
skipping logging after 41024 examples to avoid logging too frequently
skipping logging after 41088 examples to avoid logging too frequently
skipping logging after 41152 examples to avoid logging too frequently
skipping logging after 41216 examples to avoid logging too frequently
skipping logging after 41280 examples to avoid logging too frequently
train stats after 41344 examples: {'rewards_train/chosen': '0.27933', 'rewards_train/rejected': '0.13857', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.14076', 'logps_train/rejected': '-167.29', 'logps_train/chosen': '-195.2', 'loss/train': '0.70995', 'examples_per_second': '590.42', 'grad_norm': '58.036', 'counters/examples': 41344, 'counters/updates': 646}
skipping logging after 41408 examples to avoid logging too frequently
skipping logging after 41472 examples to avoid logging too frequently
skipping logging after 41536 examples to avoid logging too frequently
skipping logging after 41600 examples to avoid logging too frequently
skipping logging after 41664 examples to avoid logging too frequently
train stats after 41728 examples: {'rewards_train/chosen': '0.28234', 'rewards_train/rejected': '0.14562', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.13672', 'logps_train/rejected': '-186.32', 'logps_train/chosen': '-223.33', 'loss/train': '0.69914', 'examples_per_second': '566.29', 'grad_norm': '74.638', 'counters/examples': 41728, 'counters/updates': 652}
skipping logging after 41792 examples to avoid logging too frequently
skipping logging after 41856 examples to avoid logging too frequently
skipping logging after 41920 examples to avoid logging too frequently
skipping logging after 41984 examples to avoid logging too frequently
skipping logging after 42048 examples to avoid logging too frequently
train stats after 42112 examples: {'rewards_train/chosen': '0.36816', 'rewards_train/rejected': '-0.03254', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.4007', 'logps_train/rejected': '-201.15', 'logps_train/chosen': '-191.34', 'loss/train': '0.59751', 'examples_per_second': '566.55', 'grad_norm': '62.5', 'counters/examples': 42112, 'counters/updates': 658}
skipping logging after 42176 examples to avoid logging too frequently
skipping logging after 42240 examples to avoid logging too frequently
skipping logging after 42304 examples to avoid logging too frequently
skipping logging after 42368 examples to avoid logging too frequently
skipping logging after 42432 examples to avoid logging too frequently
train stats after 42496 examples: {'rewards_train/chosen': '0.11242', 'rewards_train/rejected': '0.011708', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10071', 'logps_train/rejected': '-163.4', 'logps_train/chosen': '-211.91', 'loss/train': '0.73523', 'examples_per_second': '570.6', 'grad_norm': '65.194', 'counters/examples': 42496, 'counters/updates': 664}
skipping logging after 42560 examples to avoid logging too frequently
skipping logging after 42624 examples to avoid logging too frequently
skipping logging after 42688 examples to avoid logging too frequently
skipping logging after 42752 examples to avoid logging too frequently
skipping logging after 42816 examples to avoid logging too frequently
train stats after 42880 examples: {'rewards_train/chosen': '0.29809', 'rewards_train/rejected': '0.021147', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.27694', 'logps_train/rejected': '-195.54', 'logps_train/chosen': '-176.84', 'loss/train': '0.62021', 'examples_per_second': '588.72', 'grad_norm': '49.833', 'counters/examples': 42880, 'counters/updates': 670}
skipping logging after 42944 examples to avoid logging too frequently
skipping logging after 43008 examples to avoid logging too frequently
skipping logging after 43072 examples to avoid logging too frequently
skipping logging after 43136 examples to avoid logging too frequently
skipping logging after 43200 examples to avoid logging too frequently
train stats after 43264 examples: {'rewards_train/chosen': '0.20619', 'rewards_train/rejected': '-0.10516', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.31135', 'logps_train/rejected': '-189.49', 'logps_train/chosen': '-232.88', 'loss/train': '0.62019', 'examples_per_second': '529.97', 'grad_norm': '66.79', 'counters/examples': 43264, 'counters/updates': 676}
skipping logging after 43328 examples to avoid logging too frequently
skipping logging after 43392 examples to avoid logging too frequently
skipping logging after 43456 examples to avoid logging too frequently
skipping logging after 43520 examples to avoid logging too frequently
skipping logging after 43584 examples to avoid logging too frequently
train stats after 43648 examples: {'rewards_train/chosen': '0.1941', 'rewards_train/rejected': '-0.16838', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.36248', 'logps_train/rejected': '-135.3', 'logps_train/chosen': '-205.27', 'loss/train': '0.59389', 'examples_per_second': '547.65', 'grad_norm': '47.479', 'counters/examples': 43648, 'counters/updates': 682}
skipping logging after 43712 examples to avoid logging too frequently
skipping logging after 43776 examples to avoid logging too frequently
skipping logging after 43840 examples to avoid logging too frequently
skipping logging after 43904 examples to avoid logging too frequently
skipping logging after 43968 examples to avoid logging too frequently
train stats after 44032 examples: {'rewards_train/chosen': '0.23538', 'rewards_train/rejected': '-0.0071638', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.24254', 'logps_train/rejected': '-211.05', 'logps_train/chosen': '-233.85', 'loss/train': '0.67243', 'examples_per_second': '577.34', 'grad_norm': '58.661', 'counters/examples': 44032, 'counters/updates': 688}
skipping logging after 44096 examples to avoid logging too frequently
skipping logging after 44160 examples to avoid logging too frequently
skipping logging after 44224 examples to avoid logging too frequently
skipping logging after 44288 examples to avoid logging too frequently
skipping logging after 44352 examples to avoid logging too frequently
train stats after 44416 examples: {'rewards_train/chosen': '0.43957', 'rewards_train/rejected': '0.10361', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.33596', 'logps_train/rejected': '-180.66', 'logps_train/chosen': '-216.83', 'loss/train': '0.62172', 'examples_per_second': '567.72', 'grad_norm': '54.214', 'counters/examples': 44416, 'counters/updates': 694}
skipping logging after 44480 examples to avoid logging too frequently
skipping logging after 44544 examples to avoid logging too frequently
skipping logging after 44608 examples to avoid logging too frequently
skipping logging after 44672 examples to avoid logging too frequently
skipping logging after 44736 examples to avoid logging too frequently
train stats after 44800 examples: {'rewards_train/chosen': '0.31082', 'rewards_train/rejected': '-0.015991', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.32681', 'logps_train/rejected': '-214.39', 'logps_train/chosen': '-251.49', 'loss/train': '0.63453', 'examples_per_second': '563.91', 'grad_norm': '62.945', 'counters/examples': 44800, 'counters/updates': 700}
skipping logging after 44864 examples to avoid logging too frequently
skipping logging after 44928 examples to avoid logging too frequently
skipping logging after 44992 examples to avoid logging too frequently
skipping logging after 45056 examples to avoid logging too frequently
skipping logging after 45120 examples to avoid logging too frequently
train stats after 45184 examples: {'rewards_train/chosen': '0.24255', 'rewards_train/rejected': '-0.047556', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.29011', 'logps_train/rejected': '-163.09', 'logps_train/chosen': '-200.62', 'loss/train': '0.62185', 'examples_per_second': '558.47', 'grad_norm': '51.738', 'counters/examples': 45184, 'counters/updates': 706}
skipping logging after 45248 examples to avoid logging too frequently
skipping logging after 45312 examples to avoid logging too frequently
skipping logging after 45376 examples to avoid logging too frequently
skipping logging after 45440 examples to avoid logging too frequently
skipping logging after 45504 examples to avoid logging too frequently
train stats after 45568 examples: {'rewards_train/chosen': '0.20963', 'rewards_train/rejected': '0.056962', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15267', 'logps_train/rejected': '-159.18', 'logps_train/chosen': '-190.1', 'loss/train': '0.71014', 'examples_per_second': '603.57', 'grad_norm': '58.833', 'counters/examples': 45568, 'counters/updates': 712}
skipping logging after 45632 examples to avoid logging too frequently
skipping logging after 45696 examples to avoid logging too frequently
skipping logging after 45760 examples to avoid logging too frequently
skipping logging after 45824 examples to avoid logging too frequently
skipping logging after 45888 examples to avoid logging too frequently
train stats after 45952 examples: {'rewards_train/chosen': '0.40258', 'rewards_train/rejected': '0.17703', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.22554', 'logps_train/rejected': '-172.3', 'logps_train/chosen': '-222.04', 'loss/train': '0.65839', 'examples_per_second': '572.24', 'grad_norm': '54.03', 'counters/examples': 45952, 'counters/updates': 718}
skipping logging after 46016 examples to avoid logging too frequently
skipping logging after 46080 examples to avoid logging too frequently
skipping logging after 46144 examples to avoid logging too frequently
skipping logging after 46208 examples to avoid logging too frequently
skipping logging after 46272 examples to avoid logging too frequently
train stats after 46336 examples: {'rewards_train/chosen': '0.37125', 'rewards_train/rejected': '0.051944', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.3193', 'logps_train/rejected': '-194.97', 'logps_train/chosen': '-223', 'loss/train': '0.6857', 'examples_per_second': '575.91', 'grad_norm': '57.057', 'counters/examples': 46336, 'counters/updates': 724}
skipping logging after 46400 examples to avoid logging too frequently
skipping logging after 46464 examples to avoid logging too frequently
skipping logging after 46528 examples to avoid logging too frequently
skipping logging after 46592 examples to avoid logging too frequently
skipping logging after 46656 examples to avoid logging too frequently
train stats after 46720 examples: {'rewards_train/chosen': '0.34188', 'rewards_train/rejected': '0.14432', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.19756', 'logps_train/rejected': '-215.49', 'logps_train/chosen': '-252.06', 'loss/train': '0.66365', 'examples_per_second': '561.62', 'grad_norm': '55.539', 'counters/examples': 46720, 'counters/updates': 730}
skipping logging after 46784 examples to avoid logging too frequently
skipping logging after 46848 examples to avoid logging too frequently
skipping logging after 46912 examples to avoid logging too frequently
skipping logging after 46976 examples to avoid logging too frequently
skipping logging after 47040 examples to avoid logging too frequently
train stats after 47104 examples: {'rewards_train/chosen': '0.56506', 'rewards_train/rejected': '0.26911', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.29595', 'logps_train/rejected': '-191.12', 'logps_train/chosen': '-233.91', 'loss/train': '0.63455', 'examples_per_second': '578.61', 'grad_norm': '63.766', 'counters/examples': 47104, 'counters/updates': 736}
skipping logging after 47168 examples to avoid logging too frequently
skipping logging after 47232 examples to avoid logging too frequently
skipping logging after 47296 examples to avoid logging too frequently
skipping logging after 47360 examples to avoid logging too frequently
skipping logging after 47424 examples to avoid logging too frequently
train stats after 47488 examples: {'rewards_train/chosen': '0.29727', 'rewards_train/rejected': '0.011159', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.28611', 'logps_train/rejected': '-204.77', 'logps_train/chosen': '-240.93', 'loss/train': '0.64722', 'examples_per_second': '565.35', 'grad_norm': '74.596', 'counters/examples': 47488, 'counters/updates': 742}
skipping logging after 47552 examples to avoid logging too frequently
skipping logging after 47616 examples to avoid logging too frequently
skipping logging after 47680 examples to avoid logging too frequently
skipping logging after 47744 examples to avoid logging too frequently
skipping logging after 47808 examples to avoid logging too frequently
train stats after 47872 examples: {'rewards_train/chosen': '0.23108', 'rewards_train/rejected': '0.099303', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.13178', 'logps_train/rejected': '-189.8', 'logps_train/chosen': '-186.74', 'loss/train': '0.67224', 'examples_per_second': '553.16', 'grad_norm': '54.846', 'counters/examples': 47872, 'counters/updates': 748}
Running evaluation after 47872 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 31.48it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 31.76it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 31.66it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.67it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.64it/s]
eval after 47872: {'rewards_eval/chosen': '0.33526', 'rewards_eval/rejected': '0.13343', 'rewards_eval/accuracies': '0.58984', 'rewards_eval/margins': '0.20183', 'logps_eval/rejected': '-186.02', 'logps_eval/chosen': '-220.19', 'loss/eval': '0.67844'}
creating checkpoint to write to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-47872...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-47872/policy.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-47872/optimizer.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-47872/scheduler.pt...
train stats after 47936 examples: {'rewards_train/chosen': '0.33814', 'rewards_train/rejected': '0.15653', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.18162', 'logps_train/rejected': '-199.22', 'logps_train/chosen': '-235', 'loss/train': '0.68969', 'examples_per_second': '488.4', 'grad_norm': '71.754', 'counters/examples': 47936, 'counters/updates': 749}
skipping logging after 48000 examples to avoid logging too frequently
skipping logging after 48064 examples to avoid logging too frequently
skipping logging after 48128 examples to avoid logging too frequently
skipping logging after 48192 examples to avoid logging too frequently
skipping logging after 48256 examples to avoid logging too frequently
train stats after 48320 examples: {'rewards_train/chosen': '0.1982', 'rewards_train/rejected': '0.042908', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1553', 'logps_train/rejected': '-198.42', 'logps_train/chosen': '-200.77', 'loss/train': '0.68675', 'examples_per_second': '562.65', 'grad_norm': '74.033', 'counters/examples': 48320, 'counters/updates': 755}
skipping logging after 48384 examples to avoid logging too frequently
skipping logging after 48448 examples to avoid logging too frequently
skipping logging after 48512 examples to avoid logging too frequently
skipping logging after 48576 examples to avoid logging too frequently
skipping logging after 48640 examples to avoid logging too frequently
train stats after 48704 examples: {'rewards_train/chosen': '0.274', 'rewards_train/rejected': '-0.084903', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.3589', 'logps_train/rejected': '-177.5', 'logps_train/chosen': '-212.98', 'loss/train': '0.59656', 'examples_per_second': '566.94', 'grad_norm': '57.649', 'counters/examples': 48704, 'counters/updates': 761}
skipping logging after 48768 examples to avoid logging too frequently
skipping logging after 48832 examples to avoid logging too frequently
skipping logging after 48896 examples to avoid logging too frequently
skipping logging after 48960 examples to avoid logging too frequently
skipping logging after 49024 examples to avoid logging too frequently
train stats after 49088 examples: {'rewards_train/chosen': '0.27976', 'rewards_train/rejected': '0.129', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15076', 'logps_train/rejected': '-170.12', 'logps_train/chosen': '-191.23', 'loss/train': '0.68965', 'examples_per_second': '566.16', 'grad_norm': '57.19', 'counters/examples': 49088, 'counters/updates': 767}
skipping logging after 49152 examples to avoid logging too frequently
skipping logging after 49216 examples to avoid logging too frequently
skipping logging after 49280 examples to avoid logging too frequently
skipping logging after 49344 examples to avoid logging too frequently
skipping logging after 49408 examples to avoid logging too frequently
train stats after 49472 examples: {'rewards_train/chosen': '0.28742', 'rewards_train/rejected': '-0.0019545', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.28938', 'logps_train/rejected': '-179.68', 'logps_train/chosen': '-238.96', 'loss/train': '0.63306', 'examples_per_second': '595.76', 'grad_norm': '60.338', 'counters/examples': 49472, 'counters/updates': 773}
skipping logging after 49536 examples to avoid logging too frequently
skipping logging after 49600 examples to avoid logging too frequently
skipping logging after 49664 examples to avoid logging too frequently
skipping logging after 49728 examples to avoid logging too frequently
skipping logging after 49792 examples to avoid logging too frequently
train stats after 49856 examples: {'rewards_train/chosen': '0.30811', 'rewards_train/rejected': '0.14254', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.16557', 'logps_train/rejected': '-187.69', 'logps_train/chosen': '-204.61', 'loss/train': '0.71243', 'examples_per_second': '547.38', 'grad_norm': '58.254', 'counters/examples': 49856, 'counters/updates': 779}
skipping logging after 49920 examples to avoid logging too frequently
skipping logging after 49984 examples to avoid logging too frequently
skipping logging after 50048 examples to avoid logging too frequently
skipping logging after 50112 examples to avoid logging too frequently
skipping logging after 50176 examples to avoid logging too frequently
train stats after 50240 examples: {'rewards_train/chosen': '0.095035', 'rewards_train/rejected': '-0.059279', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15431', 'logps_train/rejected': '-191.31', 'logps_train/chosen': '-206.91', 'loss/train': '0.66532', 'examples_per_second': '590.92', 'grad_norm': '61.854', 'counters/examples': 50240, 'counters/updates': 785}
skipping logging after 50304 examples to avoid logging too frequently
skipping logging after 50368 examples to avoid logging too frequently
skipping logging after 50432 examples to avoid logging too frequently
skipping logging after 50496 examples to avoid logging too frequently
skipping logging after 50560 examples to avoid logging too frequently
train stats after 50624 examples: {'rewards_train/chosen': '0.20507', 'rewards_train/rejected': '-0.09243', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.2975', 'logps_train/rejected': '-176.45', 'logps_train/chosen': '-191.7', 'loss/train': '0.65422', 'examples_per_second': '601.33', 'grad_norm': '61.773', 'counters/examples': 50624, 'counters/updates': 791}
skipping logging after 50688 examples to avoid logging too frequently
skipping logging after 50752 examples to avoid logging too frequently
skipping logging after 50816 examples to avoid logging too frequently
skipping logging after 50880 examples to avoid logging too frequently
skipping logging after 50944 examples to avoid logging too frequently
train stats after 51008 examples: {'rewards_train/chosen': '0.16037', 'rewards_train/rejected': '-0.016383', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17675', 'logps_train/rejected': '-202.84', 'logps_train/chosen': '-238.44', 'loss/train': '0.67256', 'examples_per_second': '585.11', 'grad_norm': '63.317', 'counters/examples': 51008, 'counters/updates': 797}
skipping logging after 51072 examples to avoid logging too frequently
skipping logging after 51136 examples to avoid logging too frequently
skipping logging after 51200 examples to avoid logging too frequently
skipping logging after 51264 examples to avoid logging too frequently
skipping logging after 51328 examples to avoid logging too frequently
train stats after 51392 examples: {'rewards_train/chosen': '0.34977', 'rewards_train/rejected': '-0.13973', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.4895', 'logps_train/rejected': '-182.9', 'logps_train/chosen': '-234.95', 'loss/train': '0.56043', 'examples_per_second': '527.46', 'grad_norm': '51.227', 'counters/examples': 51392, 'counters/updates': 803}
skipping logging after 51456 examples to avoid logging too frequently
skipping logging after 51520 examples to avoid logging too frequently
skipping logging after 51584 examples to avoid logging too frequently
skipping logging after 51648 examples to avoid logging too frequently
skipping logging after 51712 examples to avoid logging too frequently
train stats after 51776 examples: {'rewards_train/chosen': '0.35106', 'rewards_train/rejected': '0.1801', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.17096', 'logps_train/rejected': '-203.04', 'logps_train/chosen': '-199.57', 'loss/train': '0.6909', 'examples_per_second': '564.67', 'grad_norm': '63.821', 'counters/examples': 51776, 'counters/updates': 809}
skipping logging after 51840 examples to avoid logging too frequently
skipping logging after 51904 examples to avoid logging too frequently
skipping logging after 51968 examples to avoid logging too frequently
skipping logging after 52032 examples to avoid logging too frequently
skipping logging after 52096 examples to avoid logging too frequently
train stats after 52160 examples: {'rewards_train/chosen': '0.33218', 'rewards_train/rejected': '0.12926', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.20292', 'logps_train/rejected': '-217.14', 'logps_train/chosen': '-221.43', 'loss/train': '0.68538', 'examples_per_second': '565.06', 'grad_norm': '56.853', 'counters/examples': 52160, 'counters/updates': 815}
skipping logging after 52224 examples to avoid logging too frequently
skipping logging after 52288 examples to avoid logging too frequently
skipping logging after 52352 examples to avoid logging too frequently
skipping logging after 52416 examples to avoid logging too frequently
skipping logging after 52480 examples to avoid logging too frequently
train stats after 52544 examples: {'rewards_train/chosen': '0.35437', 'rewards_train/rejected': '-0.056838', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.41121', 'logps_train/rejected': '-186.96', 'logps_train/chosen': '-193.67', 'loss/train': '0.58713', 'examples_per_second': '555.85', 'grad_norm': '55.06', 'counters/examples': 52544, 'counters/updates': 821}
skipping logging after 52608 examples to avoid logging too frequently
skipping logging after 52672 examples to avoid logging too frequently
skipping logging after 52736 examples to avoid logging too frequently
skipping logging after 52800 examples to avoid logging too frequently
skipping logging after 52864 examples to avoid logging too frequently
train stats after 52928 examples: {'rewards_train/chosen': '0.40579', 'rewards_train/rejected': '0.013462', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.39233', 'logps_train/rejected': '-230.35', 'logps_train/chosen': '-253.92', 'loss/train': '0.62728', 'examples_per_second': '545.42', 'grad_norm': '68.745', 'counters/examples': 52928, 'counters/updates': 827}
skipping logging after 52992 examples to avoid logging too frequently
skipping logging after 53056 examples to avoid logging too frequently
skipping logging after 53120 examples to avoid logging too frequently
skipping logging after 53184 examples to avoid logging too frequently
skipping logging after 53248 examples to avoid logging too frequently
train stats after 53312 examples: {'rewards_train/chosen': '0.11077', 'rewards_train/rejected': '-0.13609', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.24686', 'logps_train/rejected': '-206.49', 'logps_train/chosen': '-223.94', 'loss/train': '0.68288', 'examples_per_second': '566.47', 'grad_norm': '62.058', 'counters/examples': 53312, 'counters/updates': 833}
skipping logging after 53376 examples to avoid logging too frequently
skipping logging after 53440 examples to avoid logging too frequently
skipping logging after 53504 examples to avoid logging too frequently
skipping logging after 53568 examples to avoid logging too frequently
skipping logging after 53632 examples to avoid logging too frequently
train stats after 53696 examples: {'rewards_train/chosen': '0.20142', 'rewards_train/rejected': '-0.035597', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.23702', 'logps_train/rejected': '-183.25', 'logps_train/chosen': '-230.75', 'loss/train': '0.67287', 'examples_per_second': '568.84', 'grad_norm': '75.666', 'counters/examples': 53696, 'counters/updates': 839}
skipping logging after 53760 examples to avoid logging too frequently
skipping logging after 53824 examples to avoid logging too frequently
skipping logging after 53888 examples to avoid logging too frequently
skipping logging after 53952 examples to avoid logging too frequently
skipping logging after 54016 examples to avoid logging too frequently
train stats after 54080 examples: {'rewards_train/chosen': '0.25089', 'rewards_train/rejected': '0.22692', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.02397', 'logps_train/rejected': '-220.93', 'logps_train/chosen': '-231.91', 'loss/train': '0.76207', 'examples_per_second': '564.61', 'grad_norm': '73.828', 'counters/examples': 54080, 'counters/updates': 845}
skipping logging after 54144 examples to avoid logging too frequently
skipping logging after 54208 examples to avoid logging too frequently
skipping logging after 54272 examples to avoid logging too frequently
skipping logging after 54336 examples to avoid logging too frequently
skipping logging after 54400 examples to avoid logging too frequently
train stats after 54464 examples: {'rewards_train/chosen': '0.42331', 'rewards_train/rejected': '0.20975', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21355', 'logps_train/rejected': '-180.35', 'logps_train/chosen': '-274.63', 'loss/train': '0.67051', 'examples_per_second': '564.93', 'grad_norm': '81.785', 'counters/examples': 54464, 'counters/updates': 851}
skipping logging after 54528 examples to avoid logging too frequently
skipping logging after 54592 examples to avoid logging too frequently
skipping logging after 54656 examples to avoid logging too frequently
skipping logging after 54720 examples to avoid logging too frequently
skipping logging after 54784 examples to avoid logging too frequently
train stats after 54848 examples: {'rewards_train/chosen': '0.37429', 'rewards_train/rejected': '0.12021', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.25408', 'logps_train/rejected': '-231.04', 'logps_train/chosen': '-225.74', 'loss/train': '0.67592', 'examples_per_second': '562.45', 'grad_norm': '68.21', 'counters/examples': 54848, 'counters/updates': 857}
skipping logging after 54912 examples to avoid logging too frequently
skipping logging after 54976 examples to avoid logging too frequently
skipping logging after 55040 examples to avoid logging too frequently
skipping logging after 55104 examples to avoid logging too frequently
skipping logging after 55168 examples to avoid logging too frequently
train stats after 55232 examples: {'rewards_train/chosen': '0.41818', 'rewards_train/rejected': '0.084457', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.33372', 'logps_train/rejected': '-195.91', 'logps_train/chosen': '-264.53', 'loss/train': '0.61026', 'examples_per_second': '567.06', 'grad_norm': '52.449', 'counters/examples': 55232, 'counters/updates': 863}
skipping logging after 55296 examples to avoid logging too frequently
skipping logging after 55360 examples to avoid logging too frequently
skipping logging after 55424 examples to avoid logging too frequently
skipping logging after 55488 examples to avoid logging too frequently
skipping logging after 55552 examples to avoid logging too frequently
train stats after 55616 examples: {'rewards_train/chosen': '0.39001', 'rewards_train/rejected': '0.073893', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.31611', 'logps_train/rejected': '-204.89', 'logps_train/chosen': '-233.67', 'loss/train': '0.61632', 'examples_per_second': '553.02', 'grad_norm': '56.49', 'counters/examples': 55616, 'counters/updates': 869}
skipping logging after 55680 examples to avoid logging too frequently
skipping logging after 55744 examples to avoid logging too frequently
skipping logging after 55808 examples to avoid logging too frequently
skipping logging after 55872 examples to avoid logging too frequently
skipping logging after 55936 examples to avoid logging too frequently
train stats after 56000 examples: {'rewards_train/chosen': '0.35503', 'rewards_train/rejected': '0.044171', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.31086', 'logps_train/rejected': '-181.24', 'logps_train/chosen': '-238.36', 'loss/train': '0.63843', 'examples_per_second': '570.14', 'grad_norm': '53.237', 'counters/examples': 56000, 'counters/updates': 875}
skipping logging after 56064 examples to avoid logging too frequently
skipping logging after 56128 examples to avoid logging too frequently
skipping logging after 56192 examples to avoid logging too frequently
skipping logging after 56256 examples to avoid logging too frequently
skipping logging after 56320 examples to avoid logging too frequently
train stats after 56384 examples: {'rewards_train/chosen': '0.40127', 'rewards_train/rejected': '0.17866', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.22262', 'logps_train/rejected': '-193.48', 'logps_train/chosen': '-245.57', 'loss/train': '0.65016', 'examples_per_second': '567.95', 'grad_norm': '63.913', 'counters/examples': 56384, 'counters/updates': 881}
skipping logging after 56448 examples to avoid logging too frequently
skipping logging after 56512 examples to avoid logging too frequently
skipping logging after 56576 examples to avoid logging too frequently
skipping logging after 56640 examples to avoid logging too frequently
skipping logging after 56704 examples to avoid logging too frequently
train stats after 56768 examples: {'rewards_train/chosen': '0.42545', 'rewards_train/rejected': '0.027624', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.39782', 'logps_train/rejected': '-185.36', 'logps_train/chosen': '-224.88', 'loss/train': '0.61464', 'examples_per_second': '567.13', 'grad_norm': '52.437', 'counters/examples': 56768, 'counters/updates': 887}
skipping logging after 56832 examples to avoid logging too frequently
skipping logging after 56896 examples to avoid logging too frequently
skipping logging after 56960 examples to avoid logging too frequently
skipping logging after 57024 examples to avoid logging too frequently
skipping logging after 57088 examples to avoid logging too frequently
train stats after 57152 examples: {'rewards_train/chosen': '0.35422', 'rewards_train/rejected': '0.02398', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.33024', 'logps_train/rejected': '-221.75', 'logps_train/chosen': '-199.12', 'loss/train': '0.6292', 'examples_per_second': '563.34', 'grad_norm': '61.055', 'counters/examples': 57152, 'counters/updates': 893}
skipping logging after 57216 examples to avoid logging too frequently
skipping logging after 57280 examples to avoid logging too frequently
skipping logging after 57344 examples to avoid logging too frequently
skipping logging after 57408 examples to avoid logging too frequently
skipping logging after 57472 examples to avoid logging too frequently
train stats after 57536 examples: {'rewards_train/chosen': '0.31431', 'rewards_train/rejected': '-0.0060968', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.3204', 'logps_train/rejected': '-204.54', 'logps_train/chosen': '-222.72', 'loss/train': '0.61859', 'examples_per_second': '573.6', 'grad_norm': '60.983', 'counters/examples': 57536, 'counters/updates': 899}
skipping logging after 57600 examples to avoid logging too frequently
skipping logging after 57664 examples to avoid logging too frequently
skipping logging after 57728 examples to avoid logging too frequently
skipping logging after 57792 examples to avoid logging too frequently
skipping logging after 57856 examples to avoid logging too frequently
train stats after 57920 examples: {'rewards_train/chosen': '0.4636', 'rewards_train/rejected': '0.032407', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.4312', 'logps_train/rejected': '-167.71', 'logps_train/chosen': '-203.82', 'loss/train': '0.5756', 'examples_per_second': '575.38', 'grad_norm': '50.837', 'counters/examples': 57920, 'counters/updates': 905}
skipping logging after 57984 examples to avoid logging too frequently
skipping logging after 58048 examples to avoid logging too frequently
skipping logging after 58112 examples to avoid logging too frequently
skipping logging after 58176 examples to avoid logging too frequently
skipping logging after 58240 examples to avoid logging too frequently
train stats after 58304 examples: {'rewards_train/chosen': '0.46616', 'rewards_train/rejected': '0.17576', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.2904', 'logps_train/rejected': '-198.09', 'logps_train/chosen': '-229.1', 'loss/train': '0.64657', 'examples_per_second': '569.53', 'grad_norm': '57.707', 'counters/examples': 58304, 'counters/updates': 911}
skipping logging after 58368 examples to avoid logging too frequently
skipping logging after 58432 examples to avoid logging too frequently
skipping logging after 58496 examples to avoid logging too frequently
skipping logging after 58560 examples to avoid logging too frequently
skipping logging after 58624 examples to avoid logging too frequently
train stats after 58688 examples: {'rewards_train/chosen': '0.27038', 'rewards_train/rejected': '0.034973', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.2354', 'logps_train/rejected': '-215.73', 'logps_train/chosen': '-200.54', 'loss/train': '0.65905', 'examples_per_second': '549.81', 'grad_norm': '61.209', 'counters/examples': 58688, 'counters/updates': 917}
skipping logging after 58752 examples to avoid logging too frequently
skipping logging after 58816 examples to avoid logging too frequently
skipping logging after 58880 examples to avoid logging too frequently
skipping logging after 58944 examples to avoid logging too frequently
skipping logging after 59008 examples to avoid logging too frequently
train stats after 59072 examples: {'rewards_train/chosen': '0.32121', 'rewards_train/rejected': '-0.033932', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.35514', 'logps_train/rejected': '-214.48', 'logps_train/chosen': '-204.34', 'loss/train': '0.62322', 'examples_per_second': '561.01', 'grad_norm': '75.061', 'counters/examples': 59072, 'counters/updates': 923}
skipping logging after 59136 examples to avoid logging too frequently
skipping logging after 59200 examples to avoid logging too frequently
skipping logging after 59264 examples to avoid logging too frequently
skipping logging after 59328 examples to avoid logging too frequently
skipping logging after 59392 examples to avoid logging too frequently
train stats after 59456 examples: {'rewards_train/chosen': '0.23429', 'rewards_train/rejected': '0.070965', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.16333', 'logps_train/rejected': '-215.29', 'logps_train/chosen': '-238.95', 'loss/train': '0.6932', 'examples_per_second': '566.66', 'grad_norm': '68.125', 'counters/examples': 59456, 'counters/updates': 929}
skipping logging after 59520 examples to avoid logging too frequently
skipping logging after 59584 examples to avoid logging too frequently
skipping logging after 59648 examples to avoid logging too frequently
skipping logging after 59712 examples to avoid logging too frequently
skipping logging after 59776 examples to avoid logging too frequently
train stats after 59840 examples: {'rewards_train/chosen': '0.22278', 'rewards_train/rejected': '0.17258', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.050194', 'logps_train/rejected': '-189.41', 'logps_train/chosen': '-213.22', 'loss/train': '0.75688', 'examples_per_second': '589.11', 'grad_norm': '59.732', 'counters/examples': 59840, 'counters/updates': 935}
Running evaluation after 59840 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 31.22it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 31.45it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 31.48it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.52it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.45it/s]
eval after 59840: {'rewards_eval/chosen': '0.33104', 'rewards_eval/rejected': '0.098875', 'rewards_eval/accuracies': '0.5625', 'rewards_eval/margins': '0.23217', 'logps_eval/rejected': '-186.37', 'logps_eval/chosen': '-220.23', 'loss/eval': '0.67'}
creating checkpoint to write to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-59840...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-59840/policy.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-59840/optimizer.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-59840/scheduler.pt...
train stats after 59904 examples: {'rewards_train/chosen': '0.23583', 'rewards_train/rejected': '-0.084793', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.32062', 'logps_train/rejected': '-181.29', 'logps_train/chosen': '-202.97', 'loss/train': '0.64059', 'examples_per_second': '454.79', 'grad_norm': '55.623', 'counters/examples': 59904, 'counters/updates': 936}
skipping logging after 59968 examples to avoid logging too frequently
skipping logging after 60032 examples to avoid logging too frequently
skipping logging after 60096 examples to avoid logging too frequently
skipping logging after 60160 examples to avoid logging too frequently
skipping logging after 60224 examples to avoid logging too frequently
train stats after 60288 examples: {'rewards_train/chosen': '0.42835', 'rewards_train/rejected': '0.14183', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.28651', 'logps_train/rejected': '-174.66', 'logps_train/chosen': '-199.45', 'loss/train': '0.64523', 'examples_per_second': '549.25', 'grad_norm': '57.638', 'counters/examples': 60288, 'counters/updates': 942}
skipping logging after 60352 examples to avoid logging too frequently
skipping logging after 60416 examples to avoid logging too frequently
skipping logging after 60480 examples to avoid logging too frequently
skipping logging after 60544 examples to avoid logging too frequently
skipping logging after 60608 examples to avoid logging too frequently
train stats after 60672 examples: {'rewards_train/chosen': '0.31828', 'rewards_train/rejected': '0.033234', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.28505', 'logps_train/rejected': '-157.09', 'logps_train/chosen': '-218.27', 'loss/train': '0.61266', 'examples_per_second': '557.21', 'grad_norm': '49.85', 'counters/examples': 60672, 'counters/updates': 948}
skipping logging after 60736 examples to avoid logging too frequently
skipping logging after 60800 examples to avoid logging too frequently
skipping logging after 60864 examples to avoid logging too frequently
skipping logging after 60928 examples to avoid logging too frequently
skipping logging after 60992 examples to avoid logging too frequently
train stats after 61056 examples: {'rewards_train/chosen': '0.22985', 'rewards_train/rejected': '-0.034277', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.26413', 'logps_train/rejected': '-179.45', 'logps_train/chosen': '-215.44', 'loss/train': '0.64077', 'examples_per_second': '643.49', 'grad_norm': '57.288', 'counters/examples': 61056, 'counters/updates': 954}
skipping logging after 61120 examples to avoid logging too frequently
skipping logging after 61184 examples to avoid logging too frequently
skipping logging after 61248 examples to avoid logging too frequently
skipping logging after 61312 examples to avoid logging too frequently
skipping logging after 61376 examples to avoid logging too frequently
train stats after 61440 examples: {'rewards_train/chosen': '0.23764', 'rewards_train/rejected': '0.091624', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.14601', 'logps_train/rejected': '-197.26', 'logps_train/chosen': '-202.65', 'loss/train': '0.69608', 'examples_per_second': '566.85', 'grad_norm': '63.567', 'counters/examples': 61440, 'counters/updates': 960}
skipping logging after 61504 examples to avoid logging too frequently
skipping logging after 61568 examples to avoid logging too frequently
skipping logging after 61632 examples to avoid logging too frequently
skipping logging after 61696 examples to avoid logging too frequently
skipping logging after 61760 examples to avoid logging too frequently
train stats after 61824 examples: {'rewards_train/chosen': '0.42334', 'rewards_train/rejected': '-0.043314', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.46665', 'logps_train/rejected': '-169.37', 'logps_train/chosen': '-232.34', 'loss/train': '0.55021', 'examples_per_second': '568.62', 'grad_norm': '49.45', 'counters/examples': 61824, 'counters/updates': 966}
skipping logging after 61888 examples to avoid logging too frequently
skipping logging after 61952 examples to avoid logging too frequently
skipping logging after 62016 examples to avoid logging too frequently
skipping logging after 62080 examples to avoid logging too frequently
skipping logging after 62144 examples to avoid logging too frequently
train stats after 62208 examples: {'rewards_train/chosen': '0.40285', 'rewards_train/rejected': '0.2873', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11555', 'logps_train/rejected': '-213.25', 'logps_train/chosen': '-221.82', 'loss/train': '0.72193', 'examples_per_second': '549.6', 'grad_norm': '76.481', 'counters/examples': 62208, 'counters/updates': 972}
skipping logging after 62272 examples to avoid logging too frequently
skipping logging after 62336 examples to avoid logging too frequently
skipping logging after 62400 examples to avoid logging too frequently
skipping logging after 62464 examples to avoid logging too frequently
skipping logging after 62528 examples to avoid logging too frequently
train stats after 62592 examples: {'rewards_train/chosen': '0.43137', 'rewards_train/rejected': '0.17738', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.25399', 'logps_train/rejected': '-188.01', 'logps_train/chosen': '-243.06', 'loss/train': '0.62844', 'examples_per_second': '551.5', 'grad_norm': '58.322', 'counters/examples': 62592, 'counters/updates': 978}
skipping logging after 62656 examples to avoid logging too frequently
skipping logging after 62720 examples to avoid logging too frequently
skipping logging after 62784 examples to avoid logging too frequently
skipping logging after 62848 examples to avoid logging too frequently
skipping logging after 62912 examples to avoid logging too frequently
train stats after 62976 examples: {'rewards_train/chosen': '0.2515', 'rewards_train/rejected': '-0.076359', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.32786', 'logps_train/rejected': '-205.62', 'logps_train/chosen': '-239.94', 'loss/train': '0.63041', 'examples_per_second': '567.96', 'grad_norm': '60.018', 'counters/examples': 62976, 'counters/updates': 984}
skipping logging after 63040 examples to avoid logging too frequently
skipping logging after 63104 examples to avoid logging too frequently
skipping logging after 63168 examples to avoid logging too frequently
skipping logging after 63232 examples to avoid logging too frequently
skipping logging after 63296 examples to avoid logging too frequently
train stats after 63360 examples: {'rewards_train/chosen': '0.32613', 'rewards_train/rejected': '-0.10347', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.4296', 'logps_train/rejected': '-210.48', 'logps_train/chosen': '-204.5', 'loss/train': '0.60941', 'examples_per_second': '577.09', 'grad_norm': '63.413', 'counters/examples': 63360, 'counters/updates': 990}
skipping logging after 63424 examples to avoid logging too frequently
skipping logging after 63488 examples to avoid logging too frequently
skipping logging after 63552 examples to avoid logging too frequently
skipping logging after 63616 examples to avoid logging too frequently
skipping logging after 63680 examples to avoid logging too frequently
train stats after 63744 examples: {'rewards_train/chosen': '0.46265', 'rewards_train/rejected': '-0.030139', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.49279', 'logps_train/rejected': '-191.83', 'logps_train/chosen': '-269.69', 'loss/train': '0.54209', 'examples_per_second': '604.3', 'grad_norm': '55.943', 'counters/examples': 63744, 'counters/updates': 996}
skipping logging after 63808 examples to avoid logging too frequently
skipping logging after 63872 examples to avoid logging too frequently
skipping logging after 63936 examples to avoid logging too frequently
skipping logging after 64000 examples to avoid logging too frequently
skipping logging after 64064 examples to avoid logging too frequently
train stats after 64128 examples: {'rewards_train/chosen': '0.27235', 'rewards_train/rejected': '-0.022258', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.2946', 'logps_train/rejected': '-197.12', 'logps_train/chosen': '-219.9', 'loss/train': '0.66355', 'examples_per_second': '558.82', 'grad_norm': '73.186', 'counters/examples': 64128, 'counters/updates': 1002}
skipping logging after 64192 examples to avoid logging too frequently
skipping logging after 64256 examples to avoid logging too frequently
skipping logging after 64320 examples to avoid logging too frequently
skipping logging after 64384 examples to avoid logging too frequently
skipping logging after 64448 examples to avoid logging too frequently
train stats after 64512 examples: {'rewards_train/chosen': '0.30989', 'rewards_train/rejected': '-0.0089233', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.31881', 'logps_train/rejected': '-160.13', 'logps_train/chosen': '-181.04', 'loss/train': '0.59888', 'examples_per_second': '566.59', 'grad_norm': '49.475', 'counters/examples': 64512, 'counters/updates': 1008}
skipping logging after 64576 examples to avoid logging too frequently
skipping logging after 64640 examples to avoid logging too frequently
skipping logging after 64704 examples to avoid logging too frequently
skipping logging after 64768 examples to avoid logging too frequently
skipping logging after 64832 examples to avoid logging too frequently
train stats after 64896 examples: {'rewards_train/chosen': '0.36853', 'rewards_train/rejected': '0.095661', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.27287', 'logps_train/rejected': '-245.3', 'logps_train/chosen': '-264.61', 'loss/train': '0.66493', 'examples_per_second': '561.03', 'grad_norm': '63.008', 'counters/examples': 64896, 'counters/updates': 1014}
skipping logging after 64960 examples to avoid logging too frequently
skipping logging after 65024 examples to avoid logging too frequently
skipping logging after 65088 examples to avoid logging too frequently
skipping logging after 65152 examples to avoid logging too frequently
skipping logging after 65216 examples to avoid logging too frequently
train stats after 65280 examples: {'rewards_train/chosen': '0.43857', 'rewards_train/rejected': '-0.11763', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.5562', 'logps_train/rejected': '-176.06', 'logps_train/chosen': '-225.66', 'loss/train': '0.5478', 'examples_per_second': '568.34', 'grad_norm': '48.209', 'counters/examples': 65280, 'counters/updates': 1020}
skipping logging after 65344 examples to avoid logging too frequently
skipping logging after 65408 examples to avoid logging too frequently
skipping logging after 65472 examples to avoid logging too frequently
skipping logging after 65536 examples to avoid logging too frequently
skipping logging after 65600 examples to avoid logging too frequently
train stats after 65664 examples: {'rewards_train/chosen': '0.44548', 'rewards_train/rejected': '-0.079907', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.52539', 'logps_train/rejected': '-178', 'logps_train/chosen': '-247.12', 'loss/train': '0.56932', 'examples_per_second': '567.44', 'grad_norm': '46.717', 'counters/examples': 65664, 'counters/updates': 1026}
skipping logging after 65728 examples to avoid logging too frequently
skipping logging after 65792 examples to avoid logging too frequently
skipping logging after 65856 examples to avoid logging too frequently
skipping logging after 65920 examples to avoid logging too frequently
skipping logging after 65984 examples to avoid logging too frequently
train stats after 66048 examples: {'rewards_train/chosen': '0.4719', 'rewards_train/rejected': '0.085325', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.38658', 'logps_train/rejected': '-194.79', 'logps_train/chosen': '-242.38', 'loss/train': '0.61453', 'examples_per_second': '564.47', 'grad_norm': '59.173', 'counters/examples': 66048, 'counters/updates': 1032}
skipping logging after 66112 examples to avoid logging too frequently
skipping logging after 66176 examples to avoid logging too frequently
skipping logging after 66240 examples to avoid logging too frequently
skipping logging after 66304 examples to avoid logging too frequently
skipping logging after 66368 examples to avoid logging too frequently
train stats after 66432 examples: {'rewards_train/chosen': '0.46436', 'rewards_train/rejected': '0.30255', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16181', 'logps_train/rejected': '-212.99', 'logps_train/chosen': '-217.49', 'loss/train': '0.70276', 'examples_per_second': '551.1', 'grad_norm': '63.79', 'counters/examples': 66432, 'counters/updates': 1038}
skipping logging after 66496 examples to avoid logging too frequently
skipping logging after 66560 examples to avoid logging too frequently
skipping logging after 66624 examples to avoid logging too frequently
skipping logging after 66688 examples to avoid logging too frequently
skipping logging after 66752 examples to avoid logging too frequently
train stats after 66816 examples: {'rewards_train/chosen': '0.53218', 'rewards_train/rejected': '0.15278', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.3794', 'logps_train/rejected': '-255.97', 'logps_train/chosen': '-226.14', 'loss/train': '0.63692', 'examples_per_second': '573.11', 'grad_norm': '71.333', 'counters/examples': 66816, 'counters/updates': 1044}
skipping logging after 66880 examples to avoid logging too frequently
skipping logging after 66944 examples to avoid logging too frequently
skipping logging after 67008 examples to avoid logging too frequently
skipping logging after 67072 examples to avoid logging too frequently
skipping logging after 67136 examples to avoid logging too frequently
train stats after 67200 examples: {'rewards_train/chosen': '0.30022', 'rewards_train/rejected': '-0.02222', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.32244', 'logps_train/rejected': '-183.58', 'logps_train/chosen': '-181.33', 'loss/train': '0.61966', 'examples_per_second': '556.41', 'grad_norm': '54.748', 'counters/examples': 67200, 'counters/updates': 1050}
skipping logging after 67264 examples to avoid logging too frequently
skipping logging after 67328 examples to avoid logging too frequently
skipping logging after 67392 examples to avoid logging too frequently
skipping logging after 67456 examples to avoid logging too frequently
skipping logging after 67520 examples to avoid logging too frequently
train stats after 67584 examples: {'rewards_train/chosen': '0.41364', 'rewards_train/rejected': '0.25893', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.15471', 'logps_train/rejected': '-168.48', 'logps_train/chosen': '-212.88', 'loss/train': '0.70137', 'examples_per_second': '538.92', 'grad_norm': '57.786', 'counters/examples': 67584, 'counters/updates': 1056}
skipping logging after 67648 examples to avoid logging too frequently
skipping logging after 67712 examples to avoid logging too frequently
skipping logging after 67776 examples to avoid logging too frequently
skipping logging after 67840 examples to avoid logging too frequently
skipping logging after 67904 examples to avoid logging too frequently
train stats after 67968 examples: {'rewards_train/chosen': '0.46431', 'rewards_train/rejected': '0.21409', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25023', 'logps_train/rejected': '-176.7', 'logps_train/chosen': '-273.58', 'loss/train': '0.67223', 'examples_per_second': '576.85', 'grad_norm': '55.701', 'counters/examples': 67968, 'counters/updates': 1062}
skipping logging after 68032 examples to avoid logging too frequently
skipping logging after 68096 examples to avoid logging too frequently
skipping logging after 68160 examples to avoid logging too frequently
skipping logging after 68224 examples to avoid logging too frequently
skipping logging after 68288 examples to avoid logging too frequently
train stats after 68352 examples: {'rewards_train/chosen': '0.49927', 'rewards_train/rejected': '0.2252', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.27407', 'logps_train/rejected': '-235.68', 'logps_train/chosen': '-240.44', 'loss/train': '0.68642', 'examples_per_second': '568.21', 'grad_norm': '56.582', 'counters/examples': 68352, 'counters/updates': 1068}
skipping logging after 68416 examples to avoid logging too frequently
skipping logging after 68480 examples to avoid logging too frequently
skipping logging after 68544 examples to avoid logging too frequently
skipping logging after 68608 examples to avoid logging too frequently
skipping logging after 68672 examples to avoid logging too frequently
train stats after 68736 examples: {'rewards_train/chosen': '0.25441', 'rewards_train/rejected': '0.045537', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20887', 'logps_train/rejected': '-203.57', 'logps_train/chosen': '-234.95', 'loss/train': '0.66393', 'examples_per_second': '570.38', 'grad_norm': '69.682', 'counters/examples': 68736, 'counters/updates': 1074}
skipping logging after 68800 examples to avoid logging too frequently
skipping logging after 68864 examples to avoid logging too frequently
skipping logging after 68928 examples to avoid logging too frequently
skipping logging after 68992 examples to avoid logging too frequently
skipping logging after 69056 examples to avoid logging too frequently
train stats after 69120 examples: {'rewards_train/chosen': '0.36836', 'rewards_train/rejected': '-0.025317', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.39368', 'logps_train/rejected': '-218.22', 'logps_train/chosen': '-209.42', 'loss/train': '0.61218', 'examples_per_second': '548.34', 'grad_norm': '69.846', 'counters/examples': 69120, 'counters/updates': 1080}
skipping logging after 69184 examples to avoid logging too frequently
skipping logging after 69248 examples to avoid logging too frequently
skipping logging after 69312 examples to avoid logging too frequently
skipping logging after 69376 examples to avoid logging too frequently
skipping logging after 69440 examples to avoid logging too frequently
train stats after 69504 examples: {'rewards_train/chosen': '0.52871', 'rewards_train/rejected': '0.13516', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.39355', 'logps_train/rejected': '-201.94', 'logps_train/chosen': '-239.89', 'loss/train': '0.59286', 'examples_per_second': '561.77', 'grad_norm': '53.049', 'counters/examples': 69504, 'counters/updates': 1086}
skipping logging after 69568 examples to avoid logging too frequently
skipping logging after 69632 examples to avoid logging too frequently
skipping logging after 69696 examples to avoid logging too frequently
skipping logging after 69760 examples to avoid logging too frequently
skipping logging after 69824 examples to avoid logging too frequently
train stats after 69888 examples: {'rewards_train/chosen': '0.42677', 'rewards_train/rejected': '-0.046409', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '0.47318', 'logps_train/rejected': '-209.12', 'logps_train/chosen': '-218.82', 'loss/train': '0.54847', 'examples_per_second': '520.45', 'grad_norm': '52.194', 'counters/examples': 69888, 'counters/updates': 1092}
skipping logging after 69952 examples to avoid logging too frequently
skipping logging after 70016 examples to avoid logging too frequently
skipping logging after 70080 examples to avoid logging too frequently
skipping logging after 70144 examples to avoid logging too frequently
skipping logging after 70208 examples to avoid logging too frequently
train stats after 70272 examples: {'rewards_train/chosen': '0.42776', 'rewards_train/rejected': '0.22865', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.19911', 'logps_train/rejected': '-185.23', 'logps_train/chosen': '-210.08', 'loss/train': '0.65111', 'examples_per_second': '514.64', 'grad_norm': '52.673', 'counters/examples': 70272, 'counters/updates': 1098}
skipping logging after 70336 examples to avoid logging too frequently
skipping logging after 70400 examples to avoid logging too frequently
skipping logging after 70464 examples to avoid logging too frequently
skipping logging after 70528 examples to avoid logging too frequently
skipping logging after 70592 examples to avoid logging too frequently
train stats after 70656 examples: {'rewards_train/chosen': '0.28279', 'rewards_train/rejected': '0.060255', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.22254', 'logps_train/rejected': '-200.54', 'logps_train/chosen': '-250.15', 'loss/train': '0.67873', 'examples_per_second': '565.44', 'grad_norm': '78.801', 'counters/examples': 70656, 'counters/updates': 1104}
skipping logging after 70720 examples to avoid logging too frequently
skipping logging after 70784 examples to avoid logging too frequently
skipping logging after 70848 examples to avoid logging too frequently
skipping logging after 70912 examples to avoid logging too frequently
skipping logging after 70976 examples to avoid logging too frequently
train stats after 71040 examples: {'rewards_train/chosen': '0.38639', 'rewards_train/rejected': '-0.049891', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.43628', 'logps_train/rejected': '-171.58', 'logps_train/chosen': '-241.88', 'loss/train': '0.57152', 'examples_per_second': '564.2', 'grad_norm': '59.705', 'counters/examples': 71040, 'counters/updates': 1110}
skipping logging after 71104 examples to avoid logging too frequently
skipping logging after 71168 examples to avoid logging too frequently
skipping logging after 71232 examples to avoid logging too frequently
skipping logging after 71296 examples to avoid logging too frequently
skipping logging after 71360 examples to avoid logging too frequently
train stats after 71424 examples: {'rewards_train/chosen': '0.38321', 'rewards_train/rejected': '0.20732', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.17589', 'logps_train/rejected': '-213.65', 'logps_train/chosen': '-186.5', 'loss/train': '0.70199', 'examples_per_second': '551.06', 'grad_norm': '61.894', 'counters/examples': 71424, 'counters/updates': 1116}
skipping logging after 71488 examples to avoid logging too frequently
skipping logging after 71552 examples to avoid logging too frequently
skipping logging after 71616 examples to avoid logging too frequently
skipping logging after 71680 examples to avoid logging too frequently
skipping logging after 71744 examples to avoid logging too frequently
train stats after 71808 examples: {'rewards_train/chosen': '0.47997', 'rewards_train/rejected': '0.085421', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.39455', 'logps_train/rejected': '-156.9', 'logps_train/chosen': '-220.01', 'loss/train': '0.59719', 'examples_per_second': '553.78', 'grad_norm': '50.782', 'counters/examples': 71808, 'counters/updates': 1122}
Running evaluation after 71808 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 31.49it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 31.71it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 31.70it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.68it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.65it/s]
eval after 71808: {'rewards_eval/chosen': '0.34785', 'rewards_eval/rejected': '0.085353', 'rewards_eval/accuracies': '0.59375', 'rewards_eval/margins': '0.2625', 'logps_eval/rejected': '-186.5', 'logps_eval/chosen': '-220.07', 'loss/eval': '0.6693'}
creating checkpoint to write to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-71808...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-71808/policy.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-71808/optimizer.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-71808/scheduler.pt...
train stats after 71872 examples: {'rewards_train/chosen': '0.39099', 'rewards_train/rejected': '-0.030681', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.42167', 'logps_train/rejected': '-176.67', 'logps_train/chosen': '-278.22', 'loss/train': '0.58506', 'examples_per_second': '480.34', 'grad_norm': '63.994', 'counters/examples': 71872, 'counters/updates': 1123}
skipping logging after 71936 examples to avoid logging too frequently
skipping logging after 72000 examples to avoid logging too frequently
skipping logging after 72064 examples to avoid logging too frequently
skipping logging after 72128 examples to avoid logging too frequently
skipping logging after 72192 examples to avoid logging too frequently
train stats after 72256 examples: {'rewards_train/chosen': '0.33745', 'rewards_train/rejected': '-0.11136', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.44881', 'logps_train/rejected': '-148.25', 'logps_train/chosen': '-217.18', 'loss/train': '0.57385', 'examples_per_second': '569.11', 'grad_norm': '55.259', 'counters/examples': 72256, 'counters/updates': 1129}
skipping logging after 72320 examples to avoid logging too frequently
skipping logging after 72384 examples to avoid logging too frequently
skipping logging after 72448 examples to avoid logging too frequently
skipping logging after 72512 examples to avoid logging too frequently
skipping logging after 72576 examples to avoid logging too frequently
train stats after 72640 examples: {'rewards_train/chosen': '0.40187', 'rewards_train/rejected': '0.047407', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.35446', 'logps_train/rejected': '-191.83', 'logps_train/chosen': '-204.4', 'loss/train': '0.60274', 'examples_per_second': '588.21', 'grad_norm': '60.754', 'counters/examples': 72640, 'counters/updates': 1135}
skipping logging after 72704 examples to avoid logging too frequently
skipping logging after 72768 examples to avoid logging too frequently
skipping logging after 72832 examples to avoid logging too frequently
skipping logging after 72896 examples to avoid logging too frequently
skipping logging after 72960 examples to avoid logging too frequently
train stats after 73024 examples: {'rewards_train/chosen': '0.35669', 'rewards_train/rejected': '0.090472', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.26622', 'logps_train/rejected': '-230.98', 'logps_train/chosen': '-222.48', 'loss/train': '0.63178', 'examples_per_second': '567.32', 'grad_norm': '67.416', 'counters/examples': 73024, 'counters/updates': 1141}
skipping logging after 73088 examples to avoid logging too frequently
skipping logging after 73152 examples to avoid logging too frequently
skipping logging after 73216 examples to avoid logging too frequently
skipping logging after 73280 examples to avoid logging too frequently
skipping logging after 73344 examples to avoid logging too frequently
train stats after 73408 examples: {'rewards_train/chosen': '0.32771', 'rewards_train/rejected': '-0.050518', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.37823', 'logps_train/rejected': '-199.27', 'logps_train/chosen': '-218.63', 'loss/train': '0.58122', 'examples_per_second': '564.5', 'grad_norm': '56.02', 'counters/examples': 73408, 'counters/updates': 1147}
skipping logging after 73472 examples to avoid logging too frequently
skipping logging after 73536 examples to avoid logging too frequently
skipping logging after 73600 examples to avoid logging too frequently
skipping logging after 73664 examples to avoid logging too frequently
skipping logging after 73728 examples to avoid logging too frequently
train stats after 73792 examples: {'rewards_train/chosen': '0.39171', 'rewards_train/rejected': '0.045309', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.3464', 'logps_train/rejected': '-204.34', 'logps_train/chosen': '-206.6', 'loss/train': '0.62253', 'examples_per_second': '564.8', 'grad_norm': '56.948', 'counters/examples': 73792, 'counters/updates': 1153}
skipping logging after 73856 examples to avoid logging too frequently
skipping logging after 73920 examples to avoid logging too frequently
skipping logging after 73984 examples to avoid logging too frequently
skipping logging after 74048 examples to avoid logging too frequently
skipping logging after 74112 examples to avoid logging too frequently
train stats after 74176 examples: {'rewards_train/chosen': '0.28373', 'rewards_train/rejected': '-0.041852', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.32559', 'logps_train/rejected': '-155.93', 'logps_train/chosen': '-210.66', 'loss/train': '0.63548', 'examples_per_second': '561.24', 'grad_norm': '61.236', 'counters/examples': 74176, 'counters/updates': 1159}
skipping logging after 74240 examples to avoid logging too frequently
skipping logging after 74304 examples to avoid logging too frequently
skipping logging after 74368 examples to avoid logging too frequently
skipping logging after 74432 examples to avoid logging too frequently
skipping logging after 74496 examples to avoid logging too frequently
train stats after 74560 examples: {'rewards_train/chosen': '0.26998', 'rewards_train/rejected': '-0.020449', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.29043', 'logps_train/rejected': '-161.77', 'logps_train/chosen': '-183.03', 'loss/train': '0.6267', 'examples_per_second': '556.52', 'grad_norm': '57.788', 'counters/examples': 74560, 'counters/updates': 1165}
skipping logging after 74624 examples to avoid logging too frequently
skipping logging after 74688 examples to avoid logging too frequently
skipping logging after 74752 examples to avoid logging too frequently
skipping logging after 74816 examples to avoid logging too frequently
skipping logging after 74880 examples to avoid logging too frequently
train stats after 74944 examples: {'rewards_train/chosen': '0.29698', 'rewards_train/rejected': '0.079264', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.21771', 'logps_train/rejected': '-232.56', 'logps_train/chosen': '-209.51', 'loss/train': '0.69693', 'examples_per_second': '560.82', 'grad_norm': '75.119', 'counters/examples': 74944, 'counters/updates': 1171}
skipping logging after 75008 examples to avoid logging too frequently
skipping logging after 75072 examples to avoid logging too frequently
skipping logging after 75136 examples to avoid logging too frequently
skipping logging after 75200 examples to avoid logging too frequently
skipping logging after 75264 examples to avoid logging too frequently
train stats after 75328 examples: {'rewards_train/chosen': '0.27151', 'rewards_train/rejected': '0.026934', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.24458', 'logps_train/rejected': '-181.43', 'logps_train/chosen': '-209.5', 'loss/train': '0.63594', 'examples_per_second': '552.74', 'grad_norm': '60.418', 'counters/examples': 75328, 'counters/updates': 1177}
skipping logging after 75392 examples to avoid logging too frequently
skipping logging after 75456 examples to avoid logging too frequently
skipping logging after 75520 examples to avoid logging too frequently
skipping logging after 75584 examples to avoid logging too frequently
skipping logging after 75648 examples to avoid logging too frequently
train stats after 75712 examples: {'rewards_train/chosen': '0.081977', 'rewards_train/rejected': '-0.13597', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.21794', 'logps_train/rejected': '-180.13', 'logps_train/chosen': '-176.41', 'loss/train': '0.69369', 'examples_per_second': '567.09', 'grad_norm': '56.452', 'counters/examples': 75712, 'counters/updates': 1183}
skipping logging after 75776 examples to avoid logging too frequently
skipping logging after 75840 examples to avoid logging too frequently
skipping logging after 75904 examples to avoid logging too frequently
skipping logging after 75968 examples to avoid logging too frequently
skipping logging after 76032 examples to avoid logging too frequently
train stats after 76096 examples: {'rewards_train/chosen': '0.23426', 'rewards_train/rejected': '0.10569', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12857', 'logps_train/rejected': '-204.4', 'logps_train/chosen': '-215.36', 'loss/train': '0.71574', 'examples_per_second': '556', 'grad_norm': '90.474', 'counters/examples': 76096, 'counters/updates': 1189}
skipping logging after 76160 examples to avoid logging too frequently
skipping logging after 76224 examples to avoid logging too frequently
skipping logging after 76288 examples to avoid logging too frequently
skipping logging after 76352 examples to avoid logging too frequently
skipping logging after 76416 examples to avoid logging too frequently
train stats after 76480 examples: {'rewards_train/chosen': '0.2847', 'rewards_train/rejected': '0.064089', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.22061', 'logps_train/rejected': '-194.48', 'logps_train/chosen': '-220.92', 'loss/train': '0.66502', 'examples_per_second': '550.57', 'grad_norm': '70.858', 'counters/examples': 76480, 'counters/updates': 1195}
skipping logging after 76544 examples to avoid logging too frequently
skipping logging after 76608 examples to avoid logging too frequently
skipping logging after 76672 examples to avoid logging too frequently
skipping logging after 76736 examples to avoid logging too frequently
skipping logging after 76800 examples to avoid logging too frequently
train stats after 76864 examples: {'rewards_train/chosen': '0.32231', 'rewards_train/rejected': '-0.017894', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.3402', 'logps_train/rejected': '-178.03', 'logps_train/chosen': '-193.41', 'loss/train': '0.621', 'examples_per_second': '574.72', 'grad_norm': '58.08', 'counters/examples': 76864, 'counters/updates': 1201}
skipping logging after 76928 examples to avoid logging too frequently
skipping logging after 76992 examples to avoid logging too frequently
skipping logging after 77056 examples to avoid logging too frequently
skipping logging after 77120 examples to avoid logging too frequently
skipping logging after 77184 examples to avoid logging too frequently
train stats after 77248 examples: {'rewards_train/chosen': '0.51914', 'rewards_train/rejected': '-0.051696', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.57083', 'logps_train/rejected': '-207.5', 'logps_train/chosen': '-243.72', 'loss/train': '0.5277', 'examples_per_second': '542.39', 'grad_norm': '50.126', 'counters/examples': 77248, 'counters/updates': 1207}
skipping logging after 77312 examples to avoid logging too frequently
skipping logging after 77376 examples to avoid logging too frequently
skipping logging after 77440 examples to avoid logging too frequently
skipping logging after 77504 examples to avoid logging too frequently
skipping logging after 77568 examples to avoid logging too frequently
train stats after 77632 examples: {'rewards_train/chosen': '0.35345', 'rewards_train/rejected': '-0.20374', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.55719', 'logps_train/rejected': '-196.49', 'logps_train/chosen': '-220.27', 'loss/train': '0.54546', 'examples_per_second': '555.27', 'grad_norm': '47.06', 'counters/examples': 77632, 'counters/updates': 1213}
skipping logging after 77696 examples to avoid logging too frequently
skipping logging after 77760 examples to avoid logging too frequently
skipping logging after 77824 examples to avoid logging too frequently
skipping logging after 77888 examples to avoid logging too frequently
skipping logging after 77952 examples to avoid logging too frequently
train stats after 78016 examples: {'rewards_train/chosen': '0.15416', 'rewards_train/rejected': '-0.24649', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.40065', 'logps_train/rejected': '-182.07', 'logps_train/chosen': '-214.42', 'loss/train': '0.58453', 'examples_per_second': '552.06', 'grad_norm': '60.633', 'counters/examples': 78016, 'counters/updates': 1219}
skipping logging after 78080 examples to avoid logging too frequently
skipping logging after 78144 examples to avoid logging too frequently
skipping logging after 78208 examples to avoid logging too frequently
skipping logging after 78272 examples to avoid logging too frequently
skipping logging after 78336 examples to avoid logging too frequently
train stats after 78400 examples: {'rewards_train/chosen': '0.20968', 'rewards_train/rejected': '-0.050727', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.26041', 'logps_train/rejected': '-212.24', 'logps_train/chosen': '-205.62', 'loss/train': '0.67145', 'examples_per_second': '551.62', 'grad_norm': '49.7', 'counters/examples': 78400, 'counters/updates': 1225}
skipping logging after 78464 examples to avoid logging too frequently
skipping logging after 78528 examples to avoid logging too frequently
skipping logging after 78592 examples to avoid logging too frequently
skipping logging after 78656 examples to avoid logging too frequently
skipping logging after 78720 examples to avoid logging too frequently
train stats after 78784 examples: {'rewards_train/chosen': '0.25647', 'rewards_train/rejected': '-0.27206', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.52853', 'logps_train/rejected': '-169.97', 'logps_train/chosen': '-237.01', 'loss/train': '0.55228', 'examples_per_second': '562.24', 'grad_norm': '55.913', 'counters/examples': 78784, 'counters/updates': 1231}
skipping logging after 78848 examples to avoid logging too frequently
skipping logging after 78912 examples to avoid logging too frequently
skipping logging after 78976 examples to avoid logging too frequently
skipping logging after 79040 examples to avoid logging too frequently
skipping logging after 79104 examples to avoid logging too frequently
train stats after 79168 examples: {'rewards_train/chosen': '0.27855', 'rewards_train/rejected': '-0.24516', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.52371', 'logps_train/rejected': '-173.44', 'logps_train/chosen': '-232.1', 'loss/train': '0.5816', 'examples_per_second': '577.56', 'grad_norm': '49.846', 'counters/examples': 79168, 'counters/updates': 1237}
skipping logging after 79232 examples to avoid logging too frequently
skipping logging after 79296 examples to avoid logging too frequently
skipping logging after 79360 examples to avoid logging too frequently
skipping logging after 79424 examples to avoid logging too frequently
skipping logging after 79488 examples to avoid logging too frequently
train stats after 79552 examples: {'rewards_train/chosen': '0.25043', 'rewards_train/rejected': '0.070606', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17983', 'logps_train/rejected': '-211.66', 'logps_train/chosen': '-182.26', 'loss/train': '0.68422', 'examples_per_second': '566.91', 'grad_norm': '66.729', 'counters/examples': 79552, 'counters/updates': 1243}
skipping logging after 79616 examples to avoid logging too frequently
skipping logging after 79680 examples to avoid logging too frequently
skipping logging after 79744 examples to avoid logging too frequently
skipping logging after 79808 examples to avoid logging too frequently
skipping logging after 79872 examples to avoid logging too frequently
train stats after 79936 examples: {'rewards_train/chosen': '0.48252', 'rewards_train/rejected': '-0.079725', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.56225', 'logps_train/rejected': '-214.1', 'logps_train/chosen': '-241.58', 'loss/train': '0.56551', 'examples_per_second': '568.27', 'grad_norm': '53.292', 'counters/examples': 79936, 'counters/updates': 1249}
skipping logging after 80000 examples to avoid logging too frequently
skipping logging after 80064 examples to avoid logging too frequently
skipping logging after 80128 examples to avoid logging too frequently
skipping logging after 80192 examples to avoid logging too frequently
skipping logging after 80256 examples to avoid logging too frequently
train stats after 80320 examples: {'rewards_train/chosen': '0.33939', 'rewards_train/rejected': '-0.049708', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.3891', 'logps_train/rejected': '-217.98', 'logps_train/chosen': '-200.83', 'loss/train': '0.59634', 'examples_per_second': '557.76', 'grad_norm': '50.355', 'counters/examples': 80320, 'counters/updates': 1255}
skipping logging after 80384 examples to avoid logging too frequently
skipping logging after 80448 examples to avoid logging too frequently
skipping logging after 80512 examples to avoid logging too frequently
skipping logging after 80576 examples to avoid logging too frequently
skipping logging after 80640 examples to avoid logging too frequently
train stats after 80704 examples: {'rewards_train/chosen': '0.42171', 'rewards_train/rejected': '-0.020963', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.44267', 'logps_train/rejected': '-185.2', 'logps_train/chosen': '-233.26', 'loss/train': '0.59863', 'examples_per_second': '560.54', 'grad_norm': '55.622', 'counters/examples': 80704, 'counters/updates': 1261}
skipping logging after 80768 examples to avoid logging too frequently
skipping logging after 80832 examples to avoid logging too frequently
skipping logging after 80896 examples to avoid logging too frequently
skipping logging after 80960 examples to avoid logging too frequently
skipping logging after 81024 examples to avoid logging too frequently
train stats after 81088 examples: {'rewards_train/chosen': '0.35748', 'rewards_train/rejected': '-0.030945', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.38843', 'logps_train/rejected': '-205.49', 'logps_train/chosen': '-225.91', 'loss/train': '0.61334', 'examples_per_second': '544.29', 'grad_norm': '62.364', 'counters/examples': 81088, 'counters/updates': 1267}
skipping logging after 81152 examples to avoid logging too frequently
skipping logging after 81216 examples to avoid logging too frequently
skipping logging after 81280 examples to avoid logging too frequently
skipping logging after 81344 examples to avoid logging too frequently
skipping logging after 81408 examples to avoid logging too frequently
train stats after 81472 examples: {'rewards_train/chosen': '0.38241', 'rewards_train/rejected': '0.19325', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18916', 'logps_train/rejected': '-207.86', 'logps_train/chosen': '-247.56', 'loss/train': '0.69281', 'examples_per_second': '553.84', 'grad_norm': '63.612', 'counters/examples': 81472, 'counters/updates': 1273}
skipping logging after 81536 examples to avoid logging too frequently
skipping logging after 81600 examples to avoid logging too frequently
skipping logging after 81664 examples to avoid logging too frequently
skipping logging after 81728 examples to avoid logging too frequently
skipping logging after 81792 examples to avoid logging too frequently
train stats after 81856 examples: {'rewards_train/chosen': '0.21833', 'rewards_train/rejected': '0.030164', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.18817', 'logps_train/rejected': '-174.91', 'logps_train/chosen': '-201.82', 'loss/train': '0.70931', 'examples_per_second': '570', 'grad_norm': '59.722', 'counters/examples': 81856, 'counters/updates': 1279}
skipping logging after 81920 examples to avoid logging too frequently
skipping logging after 81984 examples to avoid logging too frequently
skipping logging after 82048 examples to avoid logging too frequently
skipping logging after 82112 examples to avoid logging too frequently
skipping logging after 82176 examples to avoid logging too frequently
train stats after 82240 examples: {'rewards_train/chosen': '0.4082', 'rewards_train/rejected': '-0.036535', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.44474', 'logps_train/rejected': '-169.65', 'logps_train/chosen': '-271.2', 'loss/train': '0.61218', 'examples_per_second': '586.7', 'grad_norm': '73.139', 'counters/examples': 82240, 'counters/updates': 1285}
skipping logging after 82304 examples to avoid logging too frequently
skipping logging after 82368 examples to avoid logging too frequently
skipping logging after 82432 examples to avoid logging too frequently
skipping logging after 82496 examples to avoid logging too frequently
skipping logging after 82560 examples to avoid logging too frequently
train stats after 82624 examples: {'rewards_train/chosen': '0.37199', 'rewards_train/rejected': '-0.070055', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.44205', 'logps_train/rejected': '-176.14', 'logps_train/chosen': '-219.33', 'loss/train': '0.57462', 'examples_per_second': '565.93', 'grad_norm': '48.209', 'counters/examples': 82624, 'counters/updates': 1291}
skipping logging after 82688 examples to avoid logging too frequently
skipping logging after 82752 examples to avoid logging too frequently
skipping logging after 82816 examples to avoid logging too frequently
skipping logging after 82880 examples to avoid logging too frequently
skipping logging after 82944 examples to avoid logging too frequently
train stats after 83008 examples: {'rewards_train/chosen': '0.28894', 'rewards_train/rejected': '-0.047696', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.33663', 'logps_train/rejected': '-206.9', 'logps_train/chosen': '-229.11', 'loss/train': '0.63667', 'examples_per_second': '567.41', 'grad_norm': '51.667', 'counters/examples': 83008, 'counters/updates': 1297}
skipping logging after 83072 examples to avoid logging too frequently
skipping logging after 83136 examples to avoid logging too frequently
skipping logging after 83200 examples to avoid logging too frequently
skipping logging after 83264 examples to avoid logging too frequently
skipping logging after 83328 examples to avoid logging too frequently
train stats after 83392 examples: {'rewards_train/chosen': '0.24449', 'rewards_train/rejected': '0.053524', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19097', 'logps_train/rejected': '-133.26', 'logps_train/chosen': '-209.71', 'loss/train': '0.6789', 'examples_per_second': '568.78', 'grad_norm': '63.294', 'counters/examples': 83392, 'counters/updates': 1303}
skipping logging after 83456 examples to avoid logging too frequently
skipping logging after 83520 examples to avoid logging too frequently
skipping logging after 83584 examples to avoid logging too frequently
skipping logging after 83648 examples to avoid logging too frequently
skipping logging after 83712 examples to avoid logging too frequently
train stats after 83776 examples: {'rewards_train/chosen': '0.36798', 'rewards_train/rejected': '-0.025887', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.39387', 'logps_train/rejected': '-190.95', 'logps_train/chosen': '-230.87', 'loss/train': '0.61986', 'examples_per_second': '558.33', 'grad_norm': '65.96', 'counters/examples': 83776, 'counters/updates': 1309}
Running evaluation after 83776 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 31.54it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 31.72it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 31.74it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.71it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.68it/s]
eval after 83776: {'rewards_eval/chosen': '0.32017', 'rewards_eval/rejected': '0.073014', 'rewards_eval/accuracies': '0.58984', 'rewards_eval/margins': '0.24715', 'logps_eval/rejected': '-186.63', 'logps_eval/chosen': '-220.34', 'loss/eval': '0.677'}
creating checkpoint to write to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-83776...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-83776/policy.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-83776/optimizer.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-83776/scheduler.pt...
train stats after 83840 examples: {'rewards_train/chosen': '0.19391', 'rewards_train/rejected': '-0.10341', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.29732', 'logps_train/rejected': '-160.84', 'logps_train/chosen': '-169.37', 'loss/train': '0.60841', 'examples_per_second': '512.75', 'grad_norm': '50.721', 'counters/examples': 83840, 'counters/updates': 1310}
skipping logging after 83904 examples to avoid logging too frequently
skipping logging after 83968 examples to avoid logging too frequently
skipping logging after 84032 examples to avoid logging too frequently
skipping logging after 84096 examples to avoid logging too frequently
skipping logging after 84160 examples to avoid logging too frequently
train stats after 84224 examples: {'rewards_train/chosen': '0.36162', 'rewards_train/rejected': '0.0061731', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.35544', 'logps_train/rejected': '-190.68', 'logps_train/chosen': '-208.55', 'loss/train': '0.61535', 'examples_per_second': '556.73', 'grad_norm': '55.865', 'counters/examples': 84224, 'counters/updates': 1316}
skipping logging after 84288 examples to avoid logging too frequently
skipping logging after 84352 examples to avoid logging too frequently
skipping logging after 84416 examples to avoid logging too frequently
skipping logging after 84480 examples to avoid logging too frequently
skipping logging after 84544 examples to avoid logging too frequently
train stats after 84608 examples: {'rewards_train/chosen': '0.28753', 'rewards_train/rejected': '-0.059185', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.34671', 'logps_train/rejected': '-182.02', 'logps_train/chosen': '-197.63', 'loss/train': '0.62152', 'examples_per_second': '560.29', 'grad_norm': '57.381', 'counters/examples': 84608, 'counters/updates': 1322}
skipping logging after 84672 examples to avoid logging too frequently
skipping logging after 84736 examples to avoid logging too frequently
skipping logging after 84800 examples to avoid logging too frequently
skipping logging after 84864 examples to avoid logging too frequently
skipping logging after 84928 examples to avoid logging too frequently
train stats after 84992 examples: {'rewards_train/chosen': '0.2946', 'rewards_train/rejected': '-0.0054976', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.30009', 'logps_train/rejected': '-178.68', 'logps_train/chosen': '-199.93', 'loss/train': '0.61262', 'examples_per_second': '558.54', 'grad_norm': '61.373', 'counters/examples': 84992, 'counters/updates': 1328}
skipping logging after 85056 examples to avoid logging too frequently
skipping logging after 85120 examples to avoid logging too frequently
skipping logging after 85184 examples to avoid logging too frequently
skipping logging after 85248 examples to avoid logging too frequently
skipping logging after 85312 examples to avoid logging too frequently
train stats after 85376 examples: {'rewards_train/chosen': '0.23442', 'rewards_train/rejected': '-0.080286', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.31471', 'logps_train/rejected': '-190.99', 'logps_train/chosen': '-213.34', 'loss/train': '0.6374', 'examples_per_second': '591.73', 'grad_norm': '57.183', 'counters/examples': 85376, 'counters/updates': 1334}
skipping logging after 85440 examples to avoid logging too frequently
skipping logging after 85504 examples to avoid logging too frequently
skipping logging after 85568 examples to avoid logging too frequently
skipping logging after 85632 examples to avoid logging too frequently
skipping logging after 85696 examples to avoid logging too frequently
train stats after 85760 examples: {'rewards_train/chosen': '0.32483', 'rewards_train/rejected': '0.080623', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.24421', 'logps_train/rejected': '-177.02', 'logps_train/chosen': '-196.33', 'loss/train': '0.66237', 'examples_per_second': '553.95', 'grad_norm': '57.9', 'counters/examples': 85760, 'counters/updates': 1340}
skipping logging after 85824 examples to avoid logging too frequently
skipping logging after 85888 examples to avoid logging too frequently
skipping logging after 85952 examples to avoid logging too frequently
skipping logging after 86016 examples to avoid logging too frequently
skipping logging after 86080 examples to avoid logging too frequently
train stats after 86144 examples: {'rewards_train/chosen': '0.33809', 'rewards_train/rejected': '0.15819', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17989', 'logps_train/rejected': '-200.12', 'logps_train/chosen': '-216.21', 'loss/train': '0.69583', 'examples_per_second': '563.95', 'grad_norm': '65.974', 'counters/examples': 86144, 'counters/updates': 1346}
skipping logging after 86208 examples to avoid logging too frequently
skipping logging after 86272 examples to avoid logging too frequently
skipping logging after 86336 examples to avoid logging too frequently
skipping logging after 86400 examples to avoid logging too frequently
skipping logging after 86464 examples to avoid logging too frequently
train stats after 86528 examples: {'rewards_train/chosen': '0.25143', 'rewards_train/rejected': '0.15044', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.10098', 'logps_train/rejected': '-189.22', 'logps_train/chosen': '-217.87', 'loss/train': '0.71546', 'examples_per_second': '559.7', 'grad_norm': '59.302', 'counters/examples': 86528, 'counters/updates': 1352}
skipping logging after 86592 examples to avoid logging too frequently
skipping logging after 86656 examples to avoid logging too frequently
skipping logging after 86720 examples to avoid logging too frequently
skipping logging after 86784 examples to avoid logging too frequently
skipping logging after 86848 examples to avoid logging too frequently
train stats after 86912 examples: {'rewards_train/chosen': '0.27526', 'rewards_train/rejected': '-0.15646', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.43172', 'logps_train/rejected': '-235.75', 'logps_train/chosen': '-251.76', 'loss/train': '0.62137', 'examples_per_second': '563.61', 'grad_norm': '72.026', 'counters/examples': 86912, 'counters/updates': 1358}
skipping logging after 86976 examples to avoid logging too frequently
skipping logging after 87040 examples to avoid logging too frequently
skipping logging after 87104 examples to avoid logging too frequently
skipping logging after 87168 examples to avoid logging too frequently
skipping logging after 87232 examples to avoid logging too frequently
train stats after 87296 examples: {'rewards_train/chosen': '0.13829', 'rewards_train/rejected': '-0.12944', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.26773', 'logps_train/rejected': '-215.12', 'logps_train/chosen': '-252.65', 'loss/train': '0.65044', 'examples_per_second': '583.1', 'grad_norm': '64.853', 'counters/examples': 87296, 'counters/updates': 1364}
skipping logging after 87360 examples to avoid logging too frequently
skipping logging after 87424 examples to avoid logging too frequently
skipping logging after 87488 examples to avoid logging too frequently
skipping logging after 87552 examples to avoid logging too frequently
skipping logging after 87616 examples to avoid logging too frequently
train stats after 87680 examples: {'rewards_train/chosen': '0.14657', 'rewards_train/rejected': '-0.20251', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.34908', 'logps_train/rejected': '-179.15', 'logps_train/chosen': '-213.48', 'loss/train': '0.64354', 'examples_per_second': '566.82', 'grad_norm': '68.248', 'counters/examples': 87680, 'counters/updates': 1370}
skipping logging after 87744 examples to avoid logging too frequently
skipping logging after 87808 examples to avoid logging too frequently
skipping logging after 87872 examples to avoid logging too frequently
skipping logging after 87936 examples to avoid logging too frequently
skipping logging after 88000 examples to avoid logging too frequently
train stats after 88064 examples: {'rewards_train/chosen': '0.35028', 'rewards_train/rejected': '0.014948', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.33533', 'logps_train/rejected': '-177.34', 'logps_train/chosen': '-236.53', 'loss/train': '0.60933', 'examples_per_second': '566.45', 'grad_norm': '61.041', 'counters/examples': 88064, 'counters/updates': 1376}
skipping logging after 88128 examples to avoid logging too frequently
skipping logging after 88192 examples to avoid logging too frequently
skipping logging after 88256 examples to avoid logging too frequently
skipping logging after 88320 examples to avoid logging too frequently
skipping logging after 88384 examples to avoid logging too frequently
train stats after 88448 examples: {'rewards_train/chosen': '0.24179', 'rewards_train/rejected': '-0.22587', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.46766', 'logps_train/rejected': '-190.28', 'logps_train/chosen': '-240.84', 'loss/train': '0.58214', 'examples_per_second': '573.87', 'grad_norm': '56.365', 'counters/examples': 88448, 'counters/updates': 1382}
skipping logging after 88512 examples to avoid logging too frequently
skipping logging after 88576 examples to avoid logging too frequently
skipping logging after 88640 examples to avoid logging too frequently
skipping logging after 88704 examples to avoid logging too frequently
skipping logging after 88768 examples to avoid logging too frequently
train stats after 88832 examples: {'rewards_train/chosen': '0.19296', 'rewards_train/rejected': '-0.02485', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.21781', 'logps_train/rejected': '-183.12', 'logps_train/chosen': '-222.09', 'loss/train': '0.70192', 'examples_per_second': '556.3', 'grad_norm': '60.979', 'counters/examples': 88832, 'counters/updates': 1388}
skipping logging after 88896 examples to avoid logging too frequently
skipping logging after 88960 examples to avoid logging too frequently
skipping logging after 89024 examples to avoid logging too frequently
skipping logging after 89088 examples to avoid logging too frequently
skipping logging after 89152 examples to avoid logging too frequently
train stats after 89216 examples: {'rewards_train/chosen': '0.2632', 'rewards_train/rejected': '-0.0098653', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.27306', 'logps_train/rejected': '-189.71', 'logps_train/chosen': '-273.29', 'loss/train': '0.63325', 'examples_per_second': '546.87', 'grad_norm': '60.817', 'counters/examples': 89216, 'counters/updates': 1394}
skipping logging after 89280 examples to avoid logging too frequently
skipping logging after 89344 examples to avoid logging too frequently
skipping logging after 89408 examples to avoid logging too frequently
skipping logging after 89472 examples to avoid logging too frequently
skipping logging after 89536 examples to avoid logging too frequently
train stats after 89600 examples: {'rewards_train/chosen': '0.096122', 'rewards_train/rejected': '0.053345', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.042777', 'logps_train/rejected': '-191.21', 'logps_train/chosen': '-215.72', 'loss/train': '0.74719', 'examples_per_second': '501.35', 'grad_norm': '71.024', 'counters/examples': 89600, 'counters/updates': 1400}
skipping logging after 89664 examples to avoid logging too frequently
skipping logging after 89728 examples to avoid logging too frequently
skipping logging after 89792 examples to avoid logging too frequently
skipping logging after 89856 examples to avoid logging too frequently
skipping logging after 89920 examples to avoid logging too frequently
train stats after 89984 examples: {'rewards_train/chosen': '0.21418', 'rewards_train/rejected': '-0.031545', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.24573', 'logps_train/rejected': '-202.74', 'logps_train/chosen': '-276.53', 'loss/train': '0.67831', 'examples_per_second': '560.22', 'grad_norm': '60.087', 'counters/examples': 89984, 'counters/updates': 1406}
skipping logging after 90048 examples to avoid logging too frequently
skipping logging after 90112 examples to avoid logging too frequently
skipping logging after 90176 examples to avoid logging too frequently
skipping logging after 90240 examples to avoid logging too frequently
skipping logging after 90304 examples to avoid logging too frequently
train stats after 90368 examples: {'rewards_train/chosen': '0.37903', 'rewards_train/rejected': '0.0023629', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.37667', 'logps_train/rejected': '-181.77', 'logps_train/chosen': '-194.41', 'loss/train': '0.61494', 'examples_per_second': '530.51', 'grad_norm': '54.449', 'counters/examples': 90368, 'counters/updates': 1412}
skipping logging after 90432 examples to avoid logging too frequently
skipping logging after 90496 examples to avoid logging too frequently
skipping logging after 90560 examples to avoid logging too frequently
skipping logging after 90624 examples to avoid logging too frequently
skipping logging after 90688 examples to avoid logging too frequently
train stats after 90752 examples: {'rewards_train/chosen': '0.27945', 'rewards_train/rejected': '-0.069993', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.34944', 'logps_train/rejected': '-180.66', 'logps_train/chosen': '-212.66', 'loss/train': '0.5993', 'examples_per_second': '554.17', 'grad_norm': '51.628', 'counters/examples': 90752, 'counters/updates': 1418}
skipping logging after 90816 examples to avoid logging too frequently
skipping logging after 90880 examples to avoid logging too frequently
skipping logging after 90944 examples to avoid logging too frequently
skipping logging after 91008 examples to avoid logging too frequently
skipping logging after 91072 examples to avoid logging too frequently
train stats after 91136 examples: {'rewards_train/chosen': '0.15833', 'rewards_train/rejected': '-0.15905', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.31738', 'logps_train/rejected': '-171.72', 'logps_train/chosen': '-220', 'loss/train': '0.62632', 'examples_per_second': '555.06', 'grad_norm': '52.717', 'counters/examples': 91136, 'counters/updates': 1424}
skipping logging after 91200 examples to avoid logging too frequently
skipping logging after 91264 examples to avoid logging too frequently
skipping logging after 91328 examples to avoid logging too frequently
skipping logging after 91392 examples to avoid logging too frequently
skipping logging after 91456 examples to avoid logging too frequently
train stats after 91520 examples: {'rewards_train/chosen': '0.34909', 'rewards_train/rejected': '-0.1241', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.47319', 'logps_train/rejected': '-191.89', 'logps_train/chosen': '-189.33', 'loss/train': '0.575', 'examples_per_second': '591.55', 'grad_norm': '54.115', 'counters/examples': 91520, 'counters/updates': 1430}
skipping logging after 91584 examples to avoid logging too frequently
skipping logging after 91648 examples to avoid logging too frequently
skipping logging after 91712 examples to avoid logging too frequently
skipping logging after 91776 examples to avoid logging too frequently
skipping logging after 91840 examples to avoid logging too frequently
train stats after 91904 examples: {'rewards_train/chosen': '0.33209', 'rewards_train/rejected': '0.045476', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.28661', 'logps_train/rejected': '-212.17', 'logps_train/chosen': '-221.35', 'loss/train': '0.66022', 'examples_per_second': '517.81', 'grad_norm': '70.116', 'counters/examples': 91904, 'counters/updates': 1436}
skipping logging after 91968 examples to avoid logging too frequently
skipping logging after 92032 examples to avoid logging too frequently
skipping logging after 92096 examples to avoid logging too frequently
skipping logging after 92160 examples to avoid logging too frequently
skipping logging after 92224 examples to avoid logging too frequently
train stats after 92288 examples: {'rewards_train/chosen': '0.26697', 'rewards_train/rejected': '-0.16512', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.43208', 'logps_train/rejected': '-165.69', 'logps_train/chosen': '-216.05', 'loss/train': '0.57543', 'examples_per_second': '567.83', 'grad_norm': '58.398', 'counters/examples': 92288, 'counters/updates': 1442}
skipping logging after 92352 examples to avoid logging too frequently
skipping logging after 92416 examples to avoid logging too frequently
skipping logging after 92480 examples to avoid logging too frequently
skipping logging after 92544 examples to avoid logging too frequently
skipping logging after 92608 examples to avoid logging too frequently
train stats after 92672 examples: {'rewards_train/chosen': '0.3455', 'rewards_train/rejected': '-0.16865', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.51416', 'logps_train/rejected': '-178.63', 'logps_train/chosen': '-246.6', 'loss/train': '0.57452', 'examples_per_second': '550.7', 'grad_norm': '50.688', 'counters/examples': 92672, 'counters/updates': 1448}
skipping logging after 92736 examples to avoid logging too frequently
skipping logging after 92800 examples to avoid logging too frequently
skipping logging after 92864 examples to avoid logging too frequently
skipping logging after 92928 examples to avoid logging too frequently
skipping logging after 92992 examples to avoid logging too frequently
train stats after 93056 examples: {'rewards_train/chosen': '0.42647', 'rewards_train/rejected': '0.0029085', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.42356', 'logps_train/rejected': '-188.18', 'logps_train/chosen': '-242.99', 'loss/train': '0.60913', 'examples_per_second': '556.89', 'grad_norm': '66.611', 'counters/examples': 93056, 'counters/updates': 1454}
skipping logging after 93120 examples to avoid logging too frequently
skipping logging after 93184 examples to avoid logging too frequently
skipping logging after 93248 examples to avoid logging too frequently
skipping logging after 93312 examples to avoid logging too frequently
skipping logging after 93376 examples to avoid logging too frequently
train stats after 93440 examples: {'rewards_train/chosen': '0.59744', 'rewards_train/rejected': '0.22465', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.37279', 'logps_train/rejected': '-199.64', 'logps_train/chosen': '-253.5', 'loss/train': '0.61187', 'examples_per_second': '541.29', 'grad_norm': '70.216', 'counters/examples': 93440, 'counters/updates': 1460}
skipping logging after 93504 examples to avoid logging too frequently
skipping logging after 93568 examples to avoid logging too frequently
skipping logging after 93632 examples to avoid logging too frequently
skipping logging after 93696 examples to avoid logging too frequently
skipping logging after 93760 examples to avoid logging too frequently
train stats after 93824 examples: {'rewards_train/chosen': '0.26121', 'rewards_train/rejected': '-0.050101', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.31132', 'logps_train/rejected': '-188.83', 'logps_train/chosen': '-208.29', 'loss/train': '0.65354', 'examples_per_second': '563.34', 'grad_norm': '65.589', 'counters/examples': 93824, 'counters/updates': 1466}
skipping logging after 93888 examples to avoid logging too frequently
skipping logging after 93952 examples to avoid logging too frequently
skipping logging after 94016 examples to avoid logging too frequently
skipping logging after 94080 examples to avoid logging too frequently
skipping logging after 94144 examples to avoid logging too frequently
train stats after 94208 examples: {'rewards_train/chosen': '0.55717', 'rewards_train/rejected': '-0.048529', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.6057', 'logps_train/rejected': '-217.67', 'logps_train/chosen': '-256.34', 'loss/train': '0.52521', 'examples_per_second': '560.82', 'grad_norm': '58.047', 'counters/examples': 94208, 'counters/updates': 1472}
skipping logging after 94272 examples to avoid logging too frequently
skipping logging after 94336 examples to avoid logging too frequently
skipping logging after 94400 examples to avoid logging too frequently
skipping logging after 94464 examples to avoid logging too frequently
skipping logging after 94528 examples to avoid logging too frequently
train stats after 94592 examples: {'rewards_train/chosen': '0.4465', 'rewards_train/rejected': '0.095192', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.35131', 'logps_train/rejected': '-193.89', 'logps_train/chosen': '-227.59', 'loss/train': '0.6292', 'examples_per_second': '569.72', 'grad_norm': '58.595', 'counters/examples': 94592, 'counters/updates': 1478}
skipping logging after 94656 examples to avoid logging too frequently
skipping logging after 94720 examples to avoid logging too frequently
skipping logging after 94784 examples to avoid logging too frequently
skipping logging after 94848 examples to avoid logging too frequently
skipping logging after 94912 examples to avoid logging too frequently
train stats after 94976 examples: {'rewards_train/chosen': '0.18057', 'rewards_train/rejected': '0.020125', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16045', 'logps_train/rejected': '-195.35', 'logps_train/chosen': '-222.63', 'loss/train': '0.71027', 'examples_per_second': '586.39', 'grad_norm': '68.832', 'counters/examples': 94976, 'counters/updates': 1484}
skipping logging after 95040 examples to avoid logging too frequently
skipping logging after 95104 examples to avoid logging too frequently
skipping logging after 95168 examples to avoid logging too frequently
skipping logging after 95232 examples to avoid logging too frequently
skipping logging after 95296 examples to avoid logging too frequently
train stats after 95360 examples: {'rewards_train/chosen': '0.22326', 'rewards_train/rejected': '0.17943', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.043827', 'logps_train/rejected': '-227.1', 'logps_train/chosen': '-211.78', 'loss/train': '0.74653', 'examples_per_second': '558.71', 'grad_norm': '61.768', 'counters/examples': 95360, 'counters/updates': 1490}
skipping logging after 95424 examples to avoid logging too frequently
skipping logging after 95488 examples to avoid logging too frequently
skipping logging after 95552 examples to avoid logging too frequently
skipping logging after 95616 examples to avoid logging too frequently
skipping logging after 95680 examples to avoid logging too frequently
train stats after 95744 examples: {'rewards_train/chosen': '0.21063', 'rewards_train/rejected': '0.23774', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '-0.027105', 'logps_train/rejected': '-209.97', 'logps_train/chosen': '-206.49', 'loss/train': '0.82272', 'examples_per_second': '545.92', 'grad_norm': '70.471', 'counters/examples': 95744, 'counters/updates': 1496}
Running evaluation after 95744 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 31.16it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 31.53it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 31.52it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.47it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 31.44it/s]
eval after 95744: {'rewards_eval/chosen': '0.34898', 'rewards_eval/rejected': '0.085598', 'rewards_eval/accuracies': '0.60938', 'rewards_eval/margins': '0.26339', 'logps_eval/rejected': '-186.5', 'logps_eval/chosen': '-220.05', 'loss/eval': '0.66898'}
creating checkpoint to write to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-95744...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-95744/policy.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-95744/optimizer.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/step-95744/scheduler.pt...
train stats after 95808 examples: {'rewards_train/chosen': '0.25124', 'rewards_train/rejected': '-0.014659', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.2659', 'logps_train/rejected': '-206.55', 'logps_train/chosen': '-219.04', 'loss/train': '0.63253', 'examples_per_second': '465.42', 'grad_norm': '57.404', 'counters/examples': 95808, 'counters/updates': 1497}
skipping logging after 95872 examples to avoid logging too frequently
skipping logging after 95936 examples to avoid logging too frequently
skipping logging after 96000 examples to avoid logging too frequently
skipping logging after 96064 examples to avoid logging too frequently
skipping logging after 96128 examples to avoid logging too frequently
train stats after 96192 examples: {'rewards_train/chosen': '0.27462', 'rewards_train/rejected': '0.11181', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.16281', 'logps_train/rejected': '-167.31', 'logps_train/chosen': '-197.45', 'loss/train': '0.69753', 'examples_per_second': '551.27', 'grad_norm': '60.81', 'counters/examples': 96192, 'counters/updates': 1503}
skipping logging after 96256 examples to avoid logging too frequently
Finished generating 1 epochs on train split
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/LATEST/policy.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/LATEST/optimizer.pt...
writing checkpoint to .cache/laura/pythia70m_dpo_seed0_2024-01-12_14-42-12_093994/LATEST/scheduler.pt...
4 initializing distributed
Creating trainer on process 4 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 4
Loading HH static dataset (train split) from Huggingface...
done
1 initializing distributed
Creating trainer on process 1 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 1
Loading HH static dataset (train split) from Huggingface...
done
7 initializing distributed
Creating trainer on process 7 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 7
Loading HH static dataset (train split) from Huggingface...
done
6 initializing distributed
Creating trainer on process 6 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 6
Loading HH static dataset (train split) from Huggingface...
done
3 initializing distributed
Creating trainer on process 3 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 3
Loading HH static dataset (train split) from Huggingface...
done
2 initializing distributed
Creating trainer on process 2 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 2
Loading HH static dataset (train split) from Huggingface...
done
5 initializing distributed
Creating trainer on process 5 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 5
Loading HH static dataset (train split) from Huggingface...
done
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: \ 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: | 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: / 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: - 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: \ 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: | 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: / 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:        counters/examples ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:         counters/updates ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      examples_per_second ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ
wandb:                grad_norm ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÇ‚ñÑ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÖ
wandb:        logps_eval/chosen ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñà
wandb:      logps_eval/rejected ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ
wandb:       logps_train/chosen ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÖ
wandb:     logps_train/rejected ‚ñÇ‚ñÖ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÉ‚ñà‚ñÖ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÉ
wandb:                loss/eval ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ
wandb:               loss/train ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñà
wandb:  rewards_eval/accuracies ‚ñÅ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá
wandb:      rewards_eval/chosen ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñà
wandb:     rewards_eval/margins ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:    rewards_eval/rejected ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ
wandb: rewards_train/accuracies ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÇ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñá‚ñÉ
wandb:     rewards_train/chosen ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÉ
wandb:    rewards_train/margins ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñá‚ñÅ
wandb:   rewards_train/rejected ‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñà
wandb: 
wandb: Run summary:
wandb:        counters/examples 96192
wandb:         counters/updates 1503
wandb:      examples_per_second 551.27235
wandb:                grad_norm 60.80981
wandb:        logps_eval/chosen -220.05452
wandb:      logps_eval/rejected -186.50195
wandb:       logps_train/chosen -197.45164
wandb:     logps_train/rejected -167.31449
wandb:                loss/eval 0.66898
wandb:               loss/train 0.69753
wandb:  rewards_eval/accuracies 0.60938
wandb:      rewards_eval/chosen 0.34898
wandb:     rewards_eval/margins 0.26339
wandb:    rewards_eval/rejected 0.0856
wandb: rewards_train/accuracies 0.625
wandb:     rewards_train/chosen 0.27462
wandb:    rewards_train/margins 0.16281
wandb:   rewards_train/rejected 0.11181
wandb: 
wandb: üöÄ View run pythia70m_dpo_seed0 at: https://wandb.ai/lauraomahony999/pythia-dpo/runs/wc2q2vp1
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: .cache/laura/wandb/run-20240112_144227-wc2q2vp1/logs
WARNING: eval_every must be divisible by batch_size
Setting eval_every to 11968
no FSDP port specified; using open port for FSDP: 49289
seed: 0
exp_name: pythia160m_dpo_seed0
batch_size: 64
eval_batch_size: 16
debug: false
fsdp_port: 49289
datasets:
- hh_static
wandb:
  enabled: true
  entity: lauraomahony999
  project: pythia-dpo
local_dirs:
- /scr-ssd
- /scr
- .cache
sample_during_eval: false
n_eval_model_samples: 16
do_first_eval: true
local_run_dir: .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351
lr: 1.0e-06
gradient_accumulation_steps: 1
max_grad_norm: 10.0
max_length: 512
max_prompt_length: 256
n_epochs: 1
n_examples: null
n_eval_examples: 256
trainer: FSDPTrainer
optimizer: RMSprop
warmup_steps: 150
activation_checkpointing: false
eval_every: 11968
minimum_log_interval_secs: 1.0
model:
  name_or_path: lomahony/pythia-160m-helpful-sft
  tokenizer_name_or_path: null
  archive: null
  block_name: GPTNeoXLayer
  policy_dtype: float32
  fsdp_policy_mp: null
  reference_dtype: float16
loss:
  name: dpo
  beta: 0.1
  label_smoothing: 0
  reference_free: false

================================================================================
Writing to ip-10-0-222-166:.cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351
================================================================================
building policy
Some weights of GPTNeoXForCausalLM were not initialized from the model checkpoint at lomahony/pythia-160m-helpful-sft and are newly initialized: ['gpt_neox.layers.10.attention.bias', 'gpt_neox.layers.5.attention.bias', 'gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.11.attention.bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.8.attention.masked_bias', 'gpt_neox.layers.7.attention.bias', 'gpt_neox.layers.9.attention.masked_bias', 'gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.11.attention.masked_bias', 'gpt_neox.layers.6.attention.masked_bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.9.attention.bias', 'gpt_neox.layers.7.attention.masked_bias', 'gpt_neox.layers.10.attention.masked_bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.8.attention.bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.4.attention.masked_bias', 'gpt_neox.layers.6.attention.bias', 'gpt_neox.layers.5.attention.masked_bias', 'gpt_neox.layers.1.attention.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
building reference model
Some weights of GPTNeoXForCausalLM were not initialized from the model checkpoint at lomahony/pythia-160m-helpful-sft and are newly initialized: ['gpt_neox.layers.10.attention.bias', 'gpt_neox.layers.5.attention.bias', 'gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.11.attention.bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.8.attention.masked_bias', 'gpt_neox.layers.7.attention.bias', 'gpt_neox.layers.9.attention.masked_bias', 'gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.11.attention.masked_bias', 'gpt_neox.layers.6.attention.masked_bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.9.attention.bias', 'gpt_neox.layers.7.attention.masked_bias', 'gpt_neox.layers.10.attention.masked_bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.8.attention.bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.4.attention.masked_bias', 'gpt_neox.layers.6.attention.bias', 'gpt_neox.layers.5.attention.masked_bias', 'gpt_neox.layers.1.attention.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
starting 8 processes for FSDP training
setting RLIMIT_NOFILE soft limit to 131072 from 8192
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
wandb: Currently logged in as: lauraomahony999. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in .cache/laura/wandb/run-20240112_144921-3djpa41v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pythia160m_dpo_seed0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lauraomahony999/pythia-dpo
wandb: üöÄ View run at https://wandb.ai/lauraomahony999/pythia-dpo/runs/3djpa41v
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
0 initializing distributed
Creating trainer on process 0 with world size 8
Loading tokenizer lomahony/pythia-160m-helpful-sft
Loaded train data iterator
Loading HH static dataset (test split) from Huggingface...
done
Processing HH static:   0%|          | 0/5103 [00:00<?, ?it/s]Processing HH static:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2972/5103 [00:00<00:00, 29707.14it/s]Processing HH static: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5103/5103 [00:00<00:00, 29583.32it/s]
FINISHED 256 EXAMPLES on test split
Loaded 16 eval batches of size 16
Sharding policy...
Sharding reference model...
Loaded model on rank 0
Using RMSprop optimizer
Loading HH static dataset (train split) from Huggingface...
done
Processing HH static:   0%|          | 0/96256 [00:00<?, ?it/s]Processing HH static:   3%|‚ñé         | 2872/96256 [00:00<00:03, 28708.32it/s]Processing HH static:   6%|‚ñå         | 5766/96256 [00:00<00:03, 28842.70it/s]Processing HH static:   9%|‚ñâ         | 8651/96256 [00:00<00:05, 15757.52it/s]Processing HH static:  12%|‚ñà‚ñè        | 11542/96256 [00:00<00:04, 19212.04it/s]Processing HH static:  15%|‚ñà‚ñå        | 14450/96256 [00:00<00:03, 21902.76it/s]Processing HH static:  18%|‚ñà‚ñä        | 17271/96256 [00:00<00:03, 23670.97it/s]Processing HH static:  21%|‚ñà‚ñà        | 20190/96256 [00:00<00:03, 25248.48it/s]Processing HH static:  24%|‚ñà‚ñà‚ñç       | 23071/96256 [00:00<00:02, 26279.93it/s]Processing HH static:  27%|‚ñà‚ñà‚ñã       | 25987/96256 [00:01<00:02, 27121.89it/s]Processing HH static:  30%|‚ñà‚ñà‚ñà       | 28892/96256 [00:01<00:02, 27690.23it/s]Processing HH static:  33%|‚ñà‚ñà‚ñà‚ñé      | 31799/96256 [00:01<00:02, 28097.28it/s]Processing HH static:  36%|‚ñà‚ñà‚ñà‚ñå      | 34669/96256 [00:01<00:02, 28262.44it/s]Processing HH static:  39%|‚ñà‚ñà‚ñà‚ñâ      | 37549/96256 [00:01<00:02, 28419.98it/s]Processing HH static:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 40420/96256 [00:01<00:02, 19037.62it/s]Processing HH static:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 43246/96256 [00:01<00:02, 21081.62it/s]Processing HH static:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 45981/96256 [00:01<00:02, 22589.25it/s]Processing HH static:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 48719/96256 [00:02<00:01, 23813.01it/s]Processing HH static:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 51481/96256 [00:02<00:01, 24830.41it/s]Processing HH static:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 54242/96256 [00:02<00:01, 25597.26it/s]Processing HH static:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 56992/96256 [00:02<00:01, 26134.47it/s]Processing HH static:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 59698/96256 [00:02<00:01, 26222.04it/s]Processing HH static:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 62427/96256 [00:02<00:01, 26530.23it/s]Processing HH static:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 65188/96256 [00:02<00:01, 26845.30it/s]Processing HH static:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 67939/96256 [00:02<00:01, 27040.74it/s]Processing HH static:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 70698/96256 [00:02<00:00, 27203.02it/s]Processing HH static:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 73446/96256 [00:02<00:00, 27284.45it/s]Processing HH static:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 76197/96256 [00:03<00:00, 27349.42it/s]Processing HH static:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 78941/96256 [00:03<00:00, 27369.00it/s]Processing HH static:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 81684/96256 [00:03<00:00, 17021.40it/s]Processing HH static:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 84418/96256 [00:03<00:00, 19185.72it/s]Processing HH static:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 87167/96256 [00:03<00:00, 21100.34it/s]Processing HH static:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 89820/96256 [00:03<00:00, 22445.50it/s]Processing HH static:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 92574/96256 [00:03<00:00, 23775.87it/s]Processing HH static:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 95324/96256 [00:03<00:00, 24786.36it/s]Processing HH static: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96256/96256 [00:03<00:00, 24124.53it/s]
Running evaluation after 0 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:   6%|‚ñã         | 1/16 [00:01<00:22,  1.49s/it]Computing eval metrics:  19%|‚ñà‚ñâ        | 3/16 [00:01<00:05,  2.30it/s]Computing eval metrics:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:01<00:02,  4.13it/s]Computing eval metrics:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:01<00:01,  6.07it/s]Computing eval metrics:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:01<00:00,  8.05it/s]Computing eval metrics:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:02<00:00,  9.88it/s]Computing eval metrics:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:02<00:00, 11.56it/s]Computing eval metrics:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [00:02<00:00, 12.96it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:02<00:00,  6.72it/s]
eval after 0: {'rewards_eval/chosen': '0.041671', 'rewards_eval/rejected': '0.030838', 'rewards_eval/accuracies': '0.53125', 'rewards_eval/margins': '0.010832', 'logps_eval/rejected': '-149.56', 'logps_eval/chosen': '-177.45', 'loss/eval': '0.69091'}
train stats after 64 examples: {'rewards_train/chosen': '0.031005', 'rewards_train/rejected': '0.049398', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '-0.018393', 'logps_train/rejected': '-170.77', 'logps_train/chosen': '-173.68', 'loss/train': '0.70424', 'examples_per_second': '169.34', 'grad_norm': '41.545', 'counters/examples': 64, 'counters/updates': 1}
skipping logging after 128 examples to avoid logging too frequently
skipping logging after 192 examples to avoid logging too frequently
train stats after 256 examples: {'rewards_train/chosen': '0.053273', 'rewards_train/rejected': '0.030308', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.022965', 'logps_train/rejected': '-172.23', 'logps_train/chosen': '-203.84', 'loss/train': '0.68703', 'examples_per_second': '267.2', 'grad_norm': '47.567', 'counters/examples': 256, 'counters/updates': 4}
skipping logging after 320 examples to avoid logging too frequently
skipping logging after 384 examples to avoid logging too frequently
skipping logging after 448 examples to avoid logging too frequently
train stats after 512 examples: {'rewards_train/chosen': '0.047706', 'rewards_train/rejected': '0.012719', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.034987', 'logps_train/rejected': '-156.5', 'logps_train/chosen': '-180.75', 'loss/train': '0.67856', 'examples_per_second': '300.91', 'grad_norm': '43.468', 'counters/examples': 512, 'counters/updates': 8}
skipping logging after 576 examples to avoid logging too frequently
skipping logging after 640 examples to avoid logging too frequently
skipping logging after 704 examples to avoid logging too frequently
train stats after 768 examples: {'rewards_train/chosen': '0.044534', 'rewards_train/rejected': '0.044402', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.00013179', 'logps_train/rejected': '-137.85', 'logps_train/chosen': '-155.48', 'loss/train': '0.69623', 'examples_per_second': '292.17', 'grad_norm': '43.558', 'counters/examples': 768, 'counters/updates': 12}
skipping logging after 832 examples to avoid logging too frequently
skipping logging after 896 examples to avoid logging too frequently
skipping logging after 960 examples to avoid logging too frequently
train stats after 1024 examples: {'rewards_train/chosen': '0.06781', 'rewards_train/rejected': '0.0445', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.02331', 'logps_train/rejected': '-180.94', 'logps_train/chosen': '-178.13', 'loss/train': '0.68508', 'examples_per_second': '271.89', 'grad_norm': '43.373', 'counters/examples': 1024, 'counters/updates': 16}
skipping logging after 1088 examples to avoid logging too frequently
skipping logging after 1152 examples to avoid logging too frequently
skipping logging after 1216 examples to avoid logging too frequently
train stats after 1280 examples: {'rewards_train/chosen': '0.062591', 'rewards_train/rejected': '0.031219', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.031372', 'logps_train/rejected': '-158.05', 'logps_train/chosen': '-178.55', 'loss/train': '0.68108', 'examples_per_second': '272.52', 'grad_norm': '43.722', 'counters/examples': 1280, 'counters/updates': 20}
skipping logging after 1344 examples to avoid logging too frequently
skipping logging after 1408 examples to avoid logging too frequently
skipping logging after 1472 examples to avoid logging too frequently
train stats after 1536 examples: {'rewards_train/chosen': '0.040109', 'rewards_train/rejected': '0.04751', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '-0.0074018', 'logps_train/rejected': '-147.2', 'logps_train/chosen': '-175.13', 'loss/train': '0.69854', 'examples_per_second': '270.87', 'grad_norm': '40.871', 'counters/examples': 1536, 'counters/updates': 24}
skipping logging after 1600 examples to avoid logging too frequently
skipping logging after 1664 examples to avoid logging too frequently
skipping logging after 1728 examples to avoid logging too frequently
train stats after 1792 examples: {'rewards_train/chosen': '0.074916', 'rewards_train/rejected': '0.036005', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.038911', 'logps_train/rejected': '-162.19', 'logps_train/chosen': '-230.53', 'loss/train': '0.67741', 'examples_per_second': '261.56', 'grad_norm': '43.632', 'counters/examples': 1792, 'counters/updates': 28}
skipping logging after 1856 examples to avoid logging too frequently
skipping logging after 1920 examples to avoid logging too frequently
skipping logging after 1984 examples to avoid logging too frequently
train stats after 2048 examples: {'rewards_train/chosen': '0.062775', 'rewards_train/rejected': '0.046124', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.016651', 'logps_train/rejected': '-193.16', 'logps_train/chosen': '-189.21', 'loss/train': '0.68861', 'examples_per_second': '273.45', 'grad_norm': '43.52', 'counters/examples': 2048, 'counters/updates': 32}
skipping logging after 2112 examples to avoid logging too frequently
skipping logging after 2176 examples to avoid logging too frequently
skipping logging after 2240 examples to avoid logging too frequently
train stats after 2304 examples: {'rewards_train/chosen': '0.069657', 'rewards_train/rejected': '0.011456', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.058201', 'logps_train/rejected': '-130.48', 'logps_train/chosen': '-161.57', 'loss/train': '0.66804', 'examples_per_second': '278.44', 'grad_norm': '38.537', 'counters/examples': 2304, 'counters/updates': 36}
skipping logging after 2368 examples to avoid logging too frequently
skipping logging after 2432 examples to avoid logging too frequently
skipping logging after 2496 examples to avoid logging too frequently
train stats after 2560 examples: {'rewards_train/chosen': '0.044603', 'rewards_train/rejected': '0.034786', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.0098168', 'logps_train/rejected': '-149.71', 'logps_train/chosen': '-178.03', 'loss/train': '0.69081', 'examples_per_second': '266.96', 'grad_norm': '45.601', 'counters/examples': 2560, 'counters/updates': 40}
skipping logging after 2624 examples to avoid logging too frequently
skipping logging after 2688 examples to avoid logging too frequently
skipping logging after 2752 examples to avoid logging too frequently
train stats after 2816 examples: {'rewards_train/chosen': '0.040193', 'rewards_train/rejected': '0.0388', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.001393', 'logps_train/rejected': '-170.51', 'logps_train/chosen': '-178.35', 'loss/train': '0.69594', 'examples_per_second': '265.38', 'grad_norm': '41.072', 'counters/examples': 2816, 'counters/updates': 44}
skipping logging after 2880 examples to avoid logging too frequently
skipping logging after 2944 examples to avoid logging too frequently
skipping logging after 3008 examples to avoid logging too frequently
train stats after 3072 examples: {'rewards_train/chosen': '0.079078', 'rewards_train/rejected': '0.028797', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.050281', 'logps_train/rejected': '-153.46', 'logps_train/chosen': '-176.06', 'loss/train': '0.67153', 'examples_per_second': '284.52', 'grad_norm': '41.245', 'counters/examples': 3072, 'counters/updates': 48}
skipping logging after 3136 examples to avoid logging too frequently
skipping logging after 3200 examples to avoid logging too frequently
skipping logging after 3264 examples to avoid logging too frequently
train stats after 3328 examples: {'rewards_train/chosen': '0.046741', 'rewards_train/rejected': '0.013732', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.03301', 'logps_train/rejected': '-163.03', 'logps_train/chosen': '-190.16', 'loss/train': '0.68039', 'examples_per_second': '265.9', 'grad_norm': '42.854', 'counters/examples': 3328, 'counters/updates': 52}
skipping logging after 3392 examples to avoid logging too frequently
skipping logging after 3456 examples to avoid logging too frequently
skipping logging after 3520 examples to avoid logging too frequently
train stats after 3584 examples: {'rewards_train/chosen': '0.085371', 'rewards_train/rejected': '0.04139', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.043981', 'logps_train/rejected': '-153.64', 'logps_train/chosen': '-212.18', 'loss/train': '0.67616', 'examples_per_second': '274.58', 'grad_norm': '44.981', 'counters/examples': 3584, 'counters/updates': 56}
skipping logging after 3648 examples to avoid logging too frequently
skipping logging after 3712 examples to avoid logging too frequently
skipping logging after 3776 examples to avoid logging too frequently
train stats after 3840 examples: {'rewards_train/chosen': '0.010873', 'rewards_train/rejected': '-0.0021721', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.013045', 'logps_train/rejected': '-139.85', 'logps_train/chosen': '-163.77', 'loss/train': '0.68988', 'examples_per_second': '273.92', 'grad_norm': '37.339', 'counters/examples': 3840, 'counters/updates': 60}
skipping logging after 3904 examples to avoid logging too frequently
skipping logging after 3968 examples to avoid logging too frequently
train stats after 4032 examples: {'rewards_train/chosen': '0.038371', 'rewards_train/rejected': '0.016477', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.021894', 'logps_train/rejected': '-152.78', 'logps_train/chosen': '-167.29', 'loss/train': '0.68665', 'examples_per_second': '271.31', 'grad_norm': '47.893', 'counters/examples': 4032, 'counters/updates': 63}
skipping logging after 4096 examples to avoid logging too frequently
skipping logging after 4160 examples to avoid logging too frequently
skipping logging after 4224 examples to avoid logging too frequently
train stats after 4288 examples: {'rewards_train/chosen': '0.059769', 'rewards_train/rejected': '0.0072404', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.052528', 'logps_train/rejected': '-162.39', 'logps_train/chosen': '-159.93', 'loss/train': '0.67107', 'examples_per_second': '262.68', 'grad_norm': '43.066', 'counters/examples': 4288, 'counters/updates': 67}
skipping logging after 4352 examples to avoid logging too frequently
skipping logging after 4416 examples to avoid logging too frequently
skipping logging after 4480 examples to avoid logging too frequently
train stats after 4544 examples: {'rewards_train/chosen': '0.05164', 'rewards_train/rejected': '0.019636', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.032005', 'logps_train/rejected': '-150.89', 'logps_train/chosen': '-173.65', 'loss/train': '0.68442', 'examples_per_second': '266.95', 'grad_norm': '38.772', 'counters/examples': 4544, 'counters/updates': 71}
skipping logging after 4608 examples to avoid logging too frequently
skipping logging after 4672 examples to avoid logging too frequently
skipping logging after 4736 examples to avoid logging too frequently
train stats after 4800 examples: {'rewards_train/chosen': '0.11126', 'rewards_train/rejected': '0.021738', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.08952', 'logps_train/rejected': '-137.17', 'logps_train/chosen': '-148.79', 'loss/train': '0.65618', 'examples_per_second': '276.22', 'grad_norm': '38.504', 'counters/examples': 4800, 'counters/updates': 75}
skipping logging after 4864 examples to avoid logging too frequently
skipping logging after 4928 examples to avoid logging too frequently
skipping logging after 4992 examples to avoid logging too frequently
train stats after 5056 examples: {'rewards_train/chosen': '0.072206', 'rewards_train/rejected': '-0.027397', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.099602', 'logps_train/rejected': '-173.24', 'logps_train/chosen': '-157.56', 'loss/train': '0.65461', 'examples_per_second': '271.76', 'grad_norm': '39.55', 'counters/examples': 5056, 'counters/updates': 79}
skipping logging after 5120 examples to avoid logging too frequently
skipping logging after 5184 examples to avoid logging too frequently
skipping logging after 5248 examples to avoid logging too frequently
train stats after 5312 examples: {'rewards_train/chosen': '0.102', 'rewards_train/rejected': '0.013176', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.088821', 'logps_train/rejected': '-154.83', 'logps_train/chosen': '-176.17', 'loss/train': '0.65604', 'examples_per_second': '268.26', 'grad_norm': '38.194', 'counters/examples': 5312, 'counters/updates': 83}
skipping logging after 5376 examples to avoid logging too frequently
skipping logging after 5440 examples to avoid logging too frequently
skipping logging after 5504 examples to avoid logging too frequently
train stats after 5568 examples: {'rewards_train/chosen': '0.10228', 'rewards_train/rejected': '-0.0040418', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.10632', 'logps_train/rejected': '-133.12', 'logps_train/chosen': '-150.89', 'loss/train': '0.65019', 'examples_per_second': '228.27', 'grad_norm': '38.755', 'counters/examples': 5568, 'counters/updates': 87}
skipping logging after 5632 examples to avoid logging too frequently
skipping logging after 5696 examples to avoid logging too frequently
skipping logging after 5760 examples to avoid logging too frequently
train stats after 5824 examples: {'rewards_train/chosen': '0.085416', 'rewards_train/rejected': '0.0053027', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.080113', 'logps_train/rejected': '-176.87', 'logps_train/chosen': '-210.66', 'loss/train': '0.66626', 'examples_per_second': '274.42', 'grad_norm': '46.641', 'counters/examples': 5824, 'counters/updates': 91}
skipping logging after 5888 examples to avoid logging too frequently
skipping logging after 5952 examples to avoid logging too frequently
skipping logging after 6016 examples to avoid logging too frequently
train stats after 6080 examples: {'rewards_train/chosen': '0.038703', 'rewards_train/rejected': '0.040222', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.0015182', 'logps_train/rejected': '-178.39', 'logps_train/chosen': '-192.27', 'loss/train': '0.70435', 'examples_per_second': '273.66', 'grad_norm': '51.786', 'counters/examples': 6080, 'counters/updates': 95}
skipping logging after 6144 examples to avoid logging too frequently
skipping logging after 6208 examples to avoid logging too frequently
skipping logging after 6272 examples to avoid logging too frequently
train stats after 6336 examples: {'rewards_train/chosen': '0.084599', 'rewards_train/rejected': '0.023918', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.060681', 'logps_train/rejected': '-156.01', 'logps_train/chosen': '-187.16', 'loss/train': '0.6744', 'examples_per_second': '268.9', 'grad_norm': '42.608', 'counters/examples': 6336, 'counters/updates': 99}
skipping logging after 6400 examples to avoid logging too frequently
skipping logging after 6464 examples to avoid logging too frequently
skipping logging after 6528 examples to avoid logging too frequently
train stats after 6592 examples: {'rewards_train/chosen': '0.052021', 'rewards_train/rejected': '0.020795', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.031226', 'logps_train/rejected': '-187.04', 'logps_train/chosen': '-170.21', 'loss/train': '0.69011', 'examples_per_second': '271.7', 'grad_norm': '43.22', 'counters/examples': 6592, 'counters/updates': 103}
skipping logging after 6656 examples to avoid logging too frequently
skipping logging after 6720 examples to avoid logging too frequently
skipping logging after 6784 examples to avoid logging too frequently
train stats after 6848 examples: {'rewards_train/chosen': '0.037835', 'rewards_train/rejected': '-0.042889', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.080724', 'logps_train/rejected': '-171.72', 'logps_train/chosen': '-186.46', 'loss/train': '0.67132', 'examples_per_second': '273.58', 'grad_norm': '44.829', 'counters/examples': 6848, 'counters/updates': 107}
skipping logging after 6912 examples to avoid logging too frequently
skipping logging after 6976 examples to avoid logging too frequently
skipping logging after 7040 examples to avoid logging too frequently
train stats after 7104 examples: {'rewards_train/chosen': '0.036825', 'rewards_train/rejected': '-0.029509', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.066334', 'logps_train/rejected': '-136.28', 'logps_train/chosen': '-169.58', 'loss/train': '0.67318', 'examples_per_second': '269.51', 'grad_norm': '40.53', 'counters/examples': 7104, 'counters/updates': 111}
skipping logging after 7168 examples to avoid logging too frequently
skipping logging after 7232 examples to avoid logging too frequently
skipping logging after 7296 examples to avoid logging too frequently
train stats after 7360 examples: {'rewards_train/chosen': '0.050809', 'rewards_train/rejected': '-0.11261', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.16342', 'logps_train/rejected': '-142.3', 'logps_train/chosen': '-175.27', 'loss/train': '0.62839', 'examples_per_second': '280.5', 'grad_norm': '38.126', 'counters/examples': 7360, 'counters/updates': 115}
skipping logging after 7424 examples to avoid logging too frequently
skipping logging after 7488 examples to avoid logging too frequently
skipping logging after 7552 examples to avoid logging too frequently
train stats after 7616 examples: {'rewards_train/chosen': '0.018905', 'rewards_train/rejected': '0.0003013', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.018603', 'logps_train/rejected': '-151.71', 'logps_train/chosen': '-161.61', 'loss/train': '0.69931', 'examples_per_second': '271.27', 'grad_norm': '45.958', 'counters/examples': 7616, 'counters/updates': 119}
skipping logging after 7680 examples to avoid logging too frequently
skipping logging after 7744 examples to avoid logging too frequently
skipping logging after 7808 examples to avoid logging too frequently
train stats after 7872 examples: {'rewards_train/chosen': '0.022882', 'rewards_train/rejected': '-0.035791', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.058673', 'logps_train/rejected': '-167.72', 'logps_train/chosen': '-175.01', 'loss/train': '0.67722', 'examples_per_second': '273.42', 'grad_norm': '41.389', 'counters/examples': 7872, 'counters/updates': 123}
skipping logging after 7936 examples to avoid logging too frequently
skipping logging after 8000 examples to avoid logging too frequently
skipping logging after 8064 examples to avoid logging too frequently
train stats after 8128 examples: {'rewards_train/chosen': '0.050869', 'rewards_train/rejected': '-0.059062', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10993', 'logps_train/rejected': '-179.95', 'logps_train/chosen': '-193.05', 'loss/train': '0.66179', 'examples_per_second': '269.44', 'grad_norm': '47.03', 'counters/examples': 8128, 'counters/updates': 127}
skipping logging after 8192 examples to avoid logging too frequently
skipping logging after 8256 examples to avoid logging too frequently
skipping logging after 8320 examples to avoid logging too frequently
train stats after 8384 examples: {'rewards_train/chosen': '0.10109', 'rewards_train/rejected': '-0.071751', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.17284', 'logps_train/rejected': '-139.66', 'logps_train/chosen': '-178.36', 'loss/train': '0.62764', 'examples_per_second': '267.83', 'grad_norm': '37.147', 'counters/examples': 8384, 'counters/updates': 131}
skipping logging after 8448 examples to avoid logging too frequently
skipping logging after 8512 examples to avoid logging too frequently
skipping logging after 8576 examples to avoid logging too frequently
train stats after 8640 examples: {'rewards_train/chosen': '-0.0055076', 'rewards_train/rejected': '-0.11135', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.10584', 'logps_train/rejected': '-129.97', 'logps_train/chosen': '-160.82', 'loss/train': '0.65926', 'examples_per_second': '273.26', 'grad_norm': '39.686', 'counters/examples': 8640, 'counters/updates': 135}
skipping logging after 8704 examples to avoid logging too frequently
skipping logging after 8768 examples to avoid logging too frequently
skipping logging after 8832 examples to avoid logging too frequently
train stats after 8896 examples: {'rewards_train/chosen': '0.026138', 'rewards_train/rejected': '-0.10951', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.13564', 'logps_train/rejected': '-136.33', 'logps_train/chosen': '-178', 'loss/train': '0.64246', 'examples_per_second': '271.43', 'grad_norm': '41.24', 'counters/examples': 8896, 'counters/updates': 139}
skipping logging after 8960 examples to avoid logging too frequently
skipping logging after 9024 examples to avoid logging too frequently
skipping logging after 9088 examples to avoid logging too frequently
train stats after 9152 examples: {'rewards_train/chosen': '0.060373', 'rewards_train/rejected': '-0.12158', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.18195', 'logps_train/rejected': '-142.31', 'logps_train/chosen': '-170.7', 'loss/train': '0.6349', 'examples_per_second': '272.48', 'grad_norm': '36.639', 'counters/examples': 9152, 'counters/updates': 143}
skipping logging after 9216 examples to avoid logging too frequently
skipping logging after 9280 examples to avoid logging too frequently
skipping logging after 9344 examples to avoid logging too frequently
train stats after 9408 examples: {'rewards_train/chosen': '0.12784', 'rewards_train/rejected': '-0.074477', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.20232', 'logps_train/rejected': '-145.81', 'logps_train/chosen': '-147.53', 'loss/train': '0.61974', 'examples_per_second': '269.94', 'grad_norm': '40.07', 'counters/examples': 9408, 'counters/updates': 147}
skipping logging after 9472 examples to avoid logging too frequently
skipping logging after 9536 examples to avoid logging too frequently
skipping logging after 9600 examples to avoid logging too frequently
train stats after 9664 examples: {'rewards_train/chosen': '0.10381', 'rewards_train/rejected': '-0.14781', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.25162', 'logps_train/rejected': '-162.01', 'logps_train/chosen': '-221.54', 'loss/train': '0.5955', 'examples_per_second': '271.01', 'grad_norm': '40.453', 'counters/examples': 9664, 'counters/updates': 151}
skipping logging after 9728 examples to avoid logging too frequently
skipping logging after 9792 examples to avoid logging too frequently
skipping logging after 9856 examples to avoid logging too frequently
train stats after 9920 examples: {'rewards_train/chosen': '0.021082', 'rewards_train/rejected': '-0.17111', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.1922', 'logps_train/rejected': '-146.98', 'logps_train/chosen': '-145.95', 'loss/train': '0.62691', 'examples_per_second': '271.4', 'grad_norm': '39.938', 'counters/examples': 9920, 'counters/updates': 155}
skipping logging after 9984 examples to avoid logging too frequently
skipping logging after 10048 examples to avoid logging too frequently
skipping logging after 10112 examples to avoid logging too frequently
train stats after 10176 examples: {'rewards_train/chosen': '0.011946', 'rewards_train/rejected': '-0.21633', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.22828', 'logps_train/rejected': '-143.58', 'logps_train/chosen': '-203.38', 'loss/train': '0.62751', 'examples_per_second': '271.84', 'grad_norm': '43.086', 'counters/examples': 10176, 'counters/updates': 159}
skipping logging after 10240 examples to avoid logging too frequently
skipping logging after 10304 examples to avoid logging too frequently
skipping logging after 10368 examples to avoid logging too frequently
train stats after 10432 examples: {'rewards_train/chosen': '0.03478', 'rewards_train/rejected': '-0.098053', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.13283', 'logps_train/rejected': '-175.81', 'logps_train/chosen': '-221.97', 'loss/train': '0.66018', 'examples_per_second': '269.14', 'grad_norm': '44.187', 'counters/examples': 10432, 'counters/updates': 163}
skipping logging after 10496 examples to avoid logging too frequently
skipping logging after 10560 examples to avoid logging too frequently
skipping logging after 10624 examples to avoid logging too frequently
train stats after 10688 examples: {'rewards_train/chosen': '0.12625', 'rewards_train/rejected': '-0.13721', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.26347', 'logps_train/rejected': '-141.11', 'logps_train/chosen': '-164.41', 'loss/train': '0.59708', 'examples_per_second': '272.45', 'grad_norm': '41.834', 'counters/examples': 10688, 'counters/updates': 167}
skipping logging after 10752 examples to avoid logging too frequently
skipping logging after 10816 examples to avoid logging too frequently
skipping logging after 10880 examples to avoid logging too frequently
train stats after 10944 examples: {'rewards_train/chosen': '-0.034489', 'rewards_train/rejected': '-0.26847', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.23398', 'logps_train/rejected': '-153.96', 'logps_train/chosen': '-186.21', 'loss/train': '0.62072', 'examples_per_second': '272.26', 'grad_norm': '37.341', 'counters/examples': 10944, 'counters/updates': 171}
skipping logging after 11008 examples to avoid logging too frequently
skipping logging after 11072 examples to avoid logging too frequently
skipping logging after 11136 examples to avoid logging too frequently
train stats after 11200 examples: {'rewards_train/chosen': '0.031008', 'rewards_train/rejected': '-0.22942', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.26043', 'logps_train/rejected': '-166.12', 'logps_train/chosen': '-180.13', 'loss/train': '0.60809', 'examples_per_second': '272.18', 'grad_norm': '42.347', 'counters/examples': 11200, 'counters/updates': 175}
skipping logging after 11264 examples to avoid logging too frequently
skipping logging after 11328 examples to avoid logging too frequently
skipping logging after 11392 examples to avoid logging too frequently
train stats after 11456 examples: {'rewards_train/chosen': '0.063102', 'rewards_train/rejected': '-0.22558', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '0.28868', 'logps_train/rejected': '-170.41', 'logps_train/chosen': '-175.44', 'loss/train': '0.58858', 'examples_per_second': '272.31', 'grad_norm': '40.556', 'counters/examples': 11456, 'counters/updates': 179}
skipping logging after 11520 examples to avoid logging too frequently
skipping logging after 11584 examples to avoid logging too frequently
skipping logging after 11648 examples to avoid logging too frequently
train stats after 11712 examples: {'rewards_train/chosen': '-0.05866', 'rewards_train/rejected': '-0.28764', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.22898', 'logps_train/rejected': '-159.62', 'logps_train/chosen': '-167.99', 'loss/train': '0.61455', 'examples_per_second': '273.03', 'grad_norm': '38.742', 'counters/examples': 11712, 'counters/updates': 183}
skipping logging after 11776 examples to avoid logging too frequently
skipping logging after 11840 examples to avoid logging too frequently
skipping logging after 11904 examples to avoid logging too frequently
train stats after 11968 examples: {'rewards_train/chosen': '-0.091954', 'rewards_train/rejected': '-0.38406', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.29211', 'logps_train/rejected': '-168.59', 'logps_train/chosen': '-184.93', 'loss/train': '0.61634', 'examples_per_second': '270.98', 'grad_norm': '43.099', 'counters/examples': 11968, 'counters/updates': 187}
Running evaluation after 11968 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:00, 17.13it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 17.06it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:00, 17.17it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 17.12it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:00<00:00, 17.21it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 17.25it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:00<00:00, 17.26it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.27it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.21it/s]
eval after 11968: {'rewards_eval/chosen': '-0.014888', 'rewards_eval/rejected': '-0.26977', 'rewards_eval/accuracies': '0.64453', 'rewards_eval/margins': '0.25488', 'logps_eval/rejected': '-152.57', 'logps_eval/chosen': '-178.01', 'loss/eval': '0.61511'}
creating checkpoint to write to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-11968...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-11968/policy.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-11968/optimizer.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-11968/scheduler.pt...
train stats after 12032 examples: {'rewards_train/chosen': '0.039306', 'rewards_train/rejected': '-0.21875', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.25806', 'logps_train/rejected': '-137.66', 'logps_train/chosen': '-182.04', 'loss/train': '0.62071', 'examples_per_second': '256.15', 'grad_norm': '39.001', 'counters/examples': 12032, 'counters/updates': 188}
skipping logging after 12096 examples to avoid logging too frequently
skipping logging after 12160 examples to avoid logging too frequently
skipping logging after 12224 examples to avoid logging too frequently
train stats after 12288 examples: {'rewards_train/chosen': '-0.13783', 'rewards_train/rejected': '-0.33132', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.19349', 'logps_train/rejected': '-161.6', 'logps_train/chosen': '-180.49', 'loss/train': '0.6593', 'examples_per_second': '272.86', 'grad_norm': '40.743', 'counters/examples': 12288, 'counters/updates': 192}
skipping logging after 12352 examples to avoid logging too frequently
skipping logging after 12416 examples to avoid logging too frequently
skipping logging after 12480 examples to avoid logging too frequently
train stats after 12544 examples: {'rewards_train/chosen': '-0.044898', 'rewards_train/rejected': '-0.21015', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16525', 'logps_train/rejected': '-140.67', 'logps_train/chosen': '-187.84', 'loss/train': '0.67845', 'examples_per_second': '271.27', 'grad_norm': '48.463', 'counters/examples': 12544, 'counters/updates': 196}
skipping logging after 12608 examples to avoid logging too frequently
skipping logging after 12672 examples to avoid logging too frequently
skipping logging after 12736 examples to avoid logging too frequently
train stats after 12800 examples: {'rewards_train/chosen': '-0.022589', 'rewards_train/rejected': '-0.26253', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.23994', 'logps_train/rejected': '-147.6', 'logps_train/chosen': '-173.78', 'loss/train': '0.62135', 'examples_per_second': '273.57', 'grad_norm': '43.119', 'counters/examples': 12800, 'counters/updates': 200}
skipping logging after 12864 examples to avoid logging too frequently
skipping logging after 12928 examples to avoid logging too frequently
skipping logging after 12992 examples to avoid logging too frequently
train stats after 13056 examples: {'rewards_train/chosen': '-0.017028', 'rewards_train/rejected': '-0.28536', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.26834', 'logps_train/rejected': '-137', 'logps_train/chosen': '-142.93', 'loss/train': '0.62602', 'examples_per_second': '274.24', 'grad_norm': '35.764', 'counters/examples': 13056, 'counters/updates': 204}
skipping logging after 13120 examples to avoid logging too frequently
skipping logging after 13184 examples to avoid logging too frequently
skipping logging after 13248 examples to avoid logging too frequently
train stats after 13312 examples: {'rewards_train/chosen': '0.10567', 'rewards_train/rejected': '-0.24613', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.35179', 'logps_train/rejected': '-153.46', 'logps_train/chosen': '-210.29', 'loss/train': '0.5664', 'examples_per_second': '273.71', 'grad_norm': '40.629', 'counters/examples': 13312, 'counters/updates': 208}
skipping logging after 13376 examples to avoid logging too frequently
skipping logging after 13440 examples to avoid logging too frequently
skipping logging after 13504 examples to avoid logging too frequently
train stats after 13568 examples: {'rewards_train/chosen': '0.021347', 'rewards_train/rejected': '-0.27697', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.29832', 'logps_train/rejected': '-171.23', 'logps_train/chosen': '-177.23', 'loss/train': '0.60395', 'examples_per_second': '270.15', 'grad_norm': '40.399', 'counters/examples': 13568, 'counters/updates': 212}
skipping logging after 13632 examples to avoid logging too frequently
skipping logging after 13696 examples to avoid logging too frequently
skipping logging after 13760 examples to avoid logging too frequently
train stats after 13824 examples: {'rewards_train/chosen': '-0.055135', 'rewards_train/rejected': '-0.16993', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.1148', 'logps_train/rejected': '-163.17', 'logps_train/chosen': '-180.51', 'loss/train': '0.68505', 'examples_per_second': '273.99', 'grad_norm': '45.921', 'counters/examples': 13824, 'counters/updates': 216}
skipping logging after 13888 examples to avoid logging too frequently
skipping logging after 13952 examples to avoid logging too frequently
skipping logging after 14016 examples to avoid logging too frequently
train stats after 14080 examples: {'rewards_train/chosen': '0.031039', 'rewards_train/rejected': '-0.16428', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.19532', 'logps_train/rejected': '-164.65', 'logps_train/chosen': '-153.8', 'loss/train': '0.64271', 'examples_per_second': '257.01', 'grad_norm': '41.601', 'counters/examples': 14080, 'counters/updates': 220}
skipping logging after 14144 examples to avoid logging too frequently
skipping logging after 14208 examples to avoid logging too frequently
skipping logging after 14272 examples to avoid logging too frequently
train stats after 14336 examples: {'rewards_train/chosen': '0.022958', 'rewards_train/rejected': '-0.11923', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14219', 'logps_train/rejected': '-183.29', 'logps_train/chosen': '-179.43', 'loss/train': '0.66226', 'examples_per_second': '269.23', 'grad_norm': '45.772', 'counters/examples': 14336, 'counters/updates': 224}
skipping logging after 14400 examples to avoid logging too frequently
skipping logging after 14464 examples to avoid logging too frequently
skipping logging after 14528 examples to avoid logging too frequently
train stats after 14592 examples: {'rewards_train/chosen': '0.12268', 'rewards_train/rejected': '-0.1323', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.25498', 'logps_train/rejected': '-158.46', 'logps_train/chosen': '-169.87', 'loss/train': '0.60231', 'examples_per_second': '273.55', 'grad_norm': '45.724', 'counters/examples': 14592, 'counters/updates': 228}
skipping logging after 14656 examples to avoid logging too frequently
skipping logging after 14720 examples to avoid logging too frequently
skipping logging after 14784 examples to avoid logging too frequently
train stats after 14848 examples: {'rewards_train/chosen': '-0.032981', 'rewards_train/rejected': '-0.11357', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.080585', 'logps_train/rejected': '-159.33', 'logps_train/chosen': '-170.65', 'loss/train': '0.7137', 'examples_per_second': '273.21', 'grad_norm': '54.968', 'counters/examples': 14848, 'counters/updates': 232}
skipping logging after 14912 examples to avoid logging too frequently
skipping logging after 14976 examples to avoid logging too frequently
skipping logging after 15040 examples to avoid logging too frequently
train stats after 15104 examples: {'rewards_train/chosen': '-0.053341', 'rewards_train/rejected': '-0.22626', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17292', 'logps_train/rejected': '-158.54', 'logps_train/chosen': '-174.08', 'loss/train': '0.64608', 'examples_per_second': '266.58', 'grad_norm': '43.549', 'counters/examples': 15104, 'counters/updates': 236}
skipping logging after 15168 examples to avoid logging too frequently
skipping logging after 15232 examples to avoid logging too frequently
skipping logging after 15296 examples to avoid logging too frequently
train stats after 15360 examples: {'rewards_train/chosen': '0.025958', 'rewards_train/rejected': '-0.25074', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.2767', 'logps_train/rejected': '-156.85', 'logps_train/chosen': '-193.91', 'loss/train': '0.60343', 'examples_per_second': '264.83', 'grad_norm': '41.787', 'counters/examples': 15360, 'counters/updates': 240}
skipping logging after 15424 examples to avoid logging too frequently
skipping logging after 15488 examples to avoid logging too frequently
skipping logging after 15552 examples to avoid logging too frequently
train stats after 15616 examples: {'rewards_train/chosen': '0.077566', 'rewards_train/rejected': '-0.13293', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.2105', 'logps_train/rejected': '-152.8', 'logps_train/chosen': '-184.66', 'loss/train': '0.64925', 'examples_per_second': '273.33', 'grad_norm': '43.204', 'counters/examples': 15616, 'counters/updates': 244}
skipping logging after 15680 examples to avoid logging too frequently
skipping logging after 15744 examples to avoid logging too frequently
skipping logging after 15808 examples to avoid logging too frequently
train stats after 15872 examples: {'rewards_train/chosen': '-0.013029', 'rewards_train/rejected': '-0.26933', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.2563', 'logps_train/rejected': '-176.44', 'logps_train/chosen': '-166.01', 'loss/train': '0.61941', 'examples_per_second': '274.26', 'grad_norm': '40.695', 'counters/examples': 15872, 'counters/updates': 248}
skipping logging after 15936 examples to avoid logging too frequently
skipping logging after 16000 examples to avoid logging too frequently
skipping logging after 16064 examples to avoid logging too frequently
train stats after 16128 examples: {'rewards_train/chosen': '0.026713', 'rewards_train/rejected': '-0.18582', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21254', 'logps_train/rejected': '-182.52', 'logps_train/chosen': '-199.06', 'loss/train': '0.65179', 'examples_per_second': '274.17', 'grad_norm': '44.93', 'counters/examples': 16128, 'counters/updates': 252}
skipping logging after 16192 examples to avoid logging too frequently
skipping logging after 16256 examples to avoid logging too frequently
skipping logging after 16320 examples to avoid logging too frequently
train stats after 16384 examples: {'rewards_train/chosen': '0.1076', 'rewards_train/rejected': '-0.084163', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.19176', 'logps_train/rejected': '-160', 'logps_train/chosen': '-182.73', 'loss/train': '0.63559', 'examples_per_second': '273.35', 'grad_norm': '43.688', 'counters/examples': 16384, 'counters/updates': 256}
skipping logging after 16448 examples to avoid logging too frequently
skipping logging after 16512 examples to avoid logging too frequently
skipping logging after 16576 examples to avoid logging too frequently
train stats after 16640 examples: {'rewards_train/chosen': '-0.050162', 'rewards_train/rejected': '-0.2014', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15124', 'logps_train/rejected': '-159.43', 'logps_train/chosen': '-177.56', 'loss/train': '0.67388', 'examples_per_second': '263.3', 'grad_norm': '42.545', 'counters/examples': 16640, 'counters/updates': 260}
skipping logging after 16704 examples to avoid logging too frequently
skipping logging after 16768 examples to avoid logging too frequently
skipping logging after 16832 examples to avoid logging too frequently
train stats after 16896 examples: {'rewards_train/chosen': '-0.031919', 'rewards_train/rejected': '-0.28536', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.25344', 'logps_train/rejected': '-207.34', 'logps_train/chosen': '-190.38', 'loss/train': '0.62132', 'examples_per_second': '270.78', 'grad_norm': '43.613', 'counters/examples': 16896, 'counters/updates': 264}
skipping logging after 16960 examples to avoid logging too frequently
skipping logging after 17024 examples to avoid logging too frequently
skipping logging after 17088 examples to avoid logging too frequently
train stats after 17152 examples: {'rewards_train/chosen': '-0.0073779', 'rewards_train/rejected': '-0.17334', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16596', 'logps_train/rejected': '-154.73', 'logps_train/chosen': '-184.86', 'loss/train': '0.66426', 'examples_per_second': '270.83', 'grad_norm': '43.571', 'counters/examples': 17152, 'counters/updates': 268}
skipping logging after 17216 examples to avoid logging too frequently
skipping logging after 17280 examples to avoid logging too frequently
skipping logging after 17344 examples to avoid logging too frequently
train stats after 17408 examples: {'rewards_train/chosen': '-0.044025', 'rewards_train/rejected': '-0.25259', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.20856', 'logps_train/rejected': '-170.93', 'logps_train/chosen': '-191.18', 'loss/train': '0.65198', 'examples_per_second': '266.59', 'grad_norm': '48.423', 'counters/examples': 17408, 'counters/updates': 272}
skipping logging after 17472 examples to avoid logging too frequently
skipping logging after 17536 examples to avoid logging too frequently
skipping logging after 17600 examples to avoid logging too frequently
train stats after 17664 examples: {'rewards_train/chosen': '0.039704', 'rewards_train/rejected': '-0.44903', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.48873', 'logps_train/rejected': '-168.06', 'logps_train/chosen': '-159', 'loss/train': '0.53401', 'examples_per_second': '265.24', 'grad_norm': '34.513', 'counters/examples': 17664, 'counters/updates': 276}
skipping logging after 17728 examples to avoid logging too frequently
skipping logging after 17792 examples to avoid logging too frequently
skipping logging after 17856 examples to avoid logging too frequently
train stats after 17920 examples: {'rewards_train/chosen': '-0.10492', 'rewards_train/rejected': '-0.37198', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.26706', 'logps_train/rejected': '-158.77', 'logps_train/chosen': '-150.9', 'loss/train': '0.61243', 'examples_per_second': '308.13', 'grad_norm': '39.146', 'counters/examples': 17920, 'counters/updates': 280}
skipping logging after 17984 examples to avoid logging too frequently
skipping logging after 18048 examples to avoid logging too frequently
skipping logging after 18112 examples to avoid logging too frequently
train stats after 18176 examples: {'rewards_train/chosen': '-0.042507', 'rewards_train/rejected': '-0.39881', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.35631', 'logps_train/rejected': '-137.9', 'logps_train/chosen': '-176.93', 'loss/train': '0.58978', 'examples_per_second': '264.13', 'grad_norm': '34.492', 'counters/examples': 18176, 'counters/updates': 284}
skipping logging after 18240 examples to avoid logging too frequently
skipping logging after 18304 examples to avoid logging too frequently
skipping logging after 18368 examples to avoid logging too frequently
train stats after 18432 examples: {'rewards_train/chosen': '-0.13234', 'rewards_train/rejected': '-0.28523', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15289', 'logps_train/rejected': '-136.17', 'logps_train/chosen': '-168.8', 'loss/train': '0.69194', 'examples_per_second': '265.64', 'grad_norm': '48.559', 'counters/examples': 18432, 'counters/updates': 288}
skipping logging after 18496 examples to avoid logging too frequently
skipping logging after 18560 examples to avoid logging too frequently
skipping logging after 18624 examples to avoid logging too frequently
train stats after 18688 examples: {'rewards_train/chosen': '0.085819', 'rewards_train/rejected': '-0.085509', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.17133', 'logps_train/rejected': '-162.55', 'logps_train/chosen': '-170.92', 'loss/train': '0.65524', 'examples_per_second': '278.65', 'grad_norm': '44.492', 'counters/examples': 18688, 'counters/updates': 292}
skipping logging after 18752 examples to avoid logging too frequently
skipping logging after 18816 examples to avoid logging too frequently
skipping logging after 18880 examples to avoid logging too frequently
train stats after 18944 examples: {'rewards_train/chosen': '-0.15846', 'rewards_train/rejected': '-0.2821', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12363', 'logps_train/rejected': '-154.2', 'logps_train/chosen': '-172.32', 'loss/train': '0.69282', 'examples_per_second': '272.35', 'grad_norm': '47.515', 'counters/examples': 18944, 'counters/updates': 296}
skipping logging after 19008 examples to avoid logging too frequently
skipping logging after 19072 examples to avoid logging too frequently
skipping logging after 19136 examples to avoid logging too frequently
train stats after 19200 examples: {'rewards_train/chosen': '-0.095234', 'rewards_train/rejected': '-0.27487', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.17963', 'logps_train/rejected': '-170.74', 'logps_train/chosen': '-203.56', 'loss/train': '0.66847', 'examples_per_second': '263.3', 'grad_norm': '46.574', 'counters/examples': 19200, 'counters/updates': 300}
skipping logging after 19264 examples to avoid logging too frequently
skipping logging after 19328 examples to avoid logging too frequently
skipping logging after 19392 examples to avoid logging too frequently
train stats after 19456 examples: {'rewards_train/chosen': '-0.0028718', 'rewards_train/rejected': '-0.18254', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.17967', 'logps_train/rejected': '-162.48', 'logps_train/chosen': '-212.1', 'loss/train': '0.65301', 'examples_per_second': '266.07', 'grad_norm': '48.577', 'counters/examples': 19456, 'counters/updates': 304}
skipping logging after 19520 examples to avoid logging too frequently
skipping logging after 19584 examples to avoid logging too frequently
skipping logging after 19648 examples to avoid logging too frequently
train stats after 19712 examples: {'rewards_train/chosen': '0.090829', 'rewards_train/rejected': '-0.16528', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.25611', 'logps_train/rejected': '-164.58', 'logps_train/chosen': '-176.76', 'loss/train': '0.63196', 'examples_per_second': '274.72', 'grad_norm': '45.831', 'counters/examples': 19712, 'counters/updates': 308}
skipping logging after 19776 examples to avoid logging too frequently
skipping logging after 19840 examples to avoid logging too frequently
skipping logging after 19904 examples to avoid logging too frequently
train stats after 19968 examples: {'rewards_train/chosen': '-0.0089069', 'rewards_train/rejected': '-0.29859', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.28969', 'logps_train/rejected': '-139.18', 'logps_train/chosen': '-205.49', 'loss/train': '0.60007', 'examples_per_second': '283.13', 'grad_norm': '43.072', 'counters/examples': 19968, 'counters/updates': 312}
skipping logging after 20032 examples to avoid logging too frequently
skipping logging after 20096 examples to avoid logging too frequently
skipping logging after 20160 examples to avoid logging too frequently
train stats after 20224 examples: {'rewards_train/chosen': '0.048038', 'rewards_train/rejected': '-0.29243', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.34047', 'logps_train/rejected': '-171.01', 'logps_train/chosen': '-207.33', 'loss/train': '0.58492', 'examples_per_second': '273.7', 'grad_norm': '45.65', 'counters/examples': 20224, 'counters/updates': 316}
skipping logging after 20288 examples to avoid logging too frequently
skipping logging after 20352 examples to avoid logging too frequently
skipping logging after 20416 examples to avoid logging too frequently
train stats after 20480 examples: {'rewards_train/chosen': '-0.079013', 'rewards_train/rejected': '-0.29362', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.2146', 'logps_train/rejected': '-204.98', 'logps_train/chosen': '-182.19', 'loss/train': '0.65138', 'examples_per_second': '274.56', 'grad_norm': '49.183', 'counters/examples': 20480, 'counters/updates': 320}
skipping logging after 20544 examples to avoid logging too frequently
skipping logging after 20608 examples to avoid logging too frequently
skipping logging after 20672 examples to avoid logging too frequently
train stats after 20736 examples: {'rewards_train/chosen': '0.030418', 'rewards_train/rejected': '-0.17049', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.2009', 'logps_train/rejected': '-166.03', 'logps_train/chosen': '-217.29', 'loss/train': '0.66817', 'examples_per_second': '274.01', 'grad_norm': '47.498', 'counters/examples': 20736, 'counters/updates': 324}
skipping logging after 20800 examples to avoid logging too frequently
skipping logging after 20864 examples to avoid logging too frequently
skipping logging after 20928 examples to avoid logging too frequently
train stats after 20992 examples: {'rewards_train/chosen': '0.0074913', 'rewards_train/rejected': '-0.3267', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.33419', 'logps_train/rejected': '-155.01', 'logps_train/chosen': '-194.13', 'loss/train': '0.60179', 'examples_per_second': '274.29', 'grad_norm': '46.057', 'counters/examples': 20992, 'counters/updates': 328}
skipping logging after 21056 examples to avoid logging too frequently
skipping logging after 21120 examples to avoid logging too frequently
skipping logging after 21184 examples to avoid logging too frequently
train stats after 21248 examples: {'rewards_train/chosen': '-0.058569', 'rewards_train/rejected': '-0.1647', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10613', 'logps_train/rejected': '-144.71', 'logps_train/chosen': '-155.62', 'loss/train': '0.69658', 'examples_per_second': '283.99', 'grad_norm': '41.949', 'counters/examples': 21248, 'counters/updates': 332}
skipping logging after 21312 examples to avoid logging too frequently
skipping logging after 21376 examples to avoid logging too frequently
skipping logging after 21440 examples to avoid logging too frequently
train stats after 21504 examples: {'rewards_train/chosen': '-0.036363', 'rewards_train/rejected': '-0.39494', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.35857', 'logps_train/rejected': '-156.39', 'logps_train/chosen': '-195.77', 'loss/train': '0.58983', 'examples_per_second': '274.42', 'grad_norm': '47.401', 'counters/examples': 21504, 'counters/updates': 336}
skipping logging after 21568 examples to avoid logging too frequently
skipping logging after 21632 examples to avoid logging too frequently
skipping logging after 21696 examples to avoid logging too frequently
train stats after 21760 examples: {'rewards_train/chosen': '0.0069495', 'rewards_train/rejected': '-0.21561', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.22256', 'logps_train/rejected': '-159.73', 'logps_train/chosen': '-209.8', 'loss/train': '0.66782', 'examples_per_second': '278.53', 'grad_norm': '49', 'counters/examples': 21760, 'counters/updates': 340}
skipping logging after 21824 examples to avoid logging too frequently
skipping logging after 21888 examples to avoid logging too frequently
skipping logging after 21952 examples to avoid logging too frequently
train stats after 22016 examples: {'rewards_train/chosen': '-0.15068', 'rewards_train/rejected': '-0.3103', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15962', 'logps_train/rejected': '-186.87', 'logps_train/chosen': '-167.98', 'loss/train': '0.67685', 'examples_per_second': '274.24', 'grad_norm': '49.704', 'counters/examples': 22016, 'counters/updates': 344}
skipping logging after 22080 examples to avoid logging too frequently
skipping logging after 22144 examples to avoid logging too frequently
skipping logging after 22208 examples to avoid logging too frequently
train stats after 22272 examples: {'rewards_train/chosen': '0.025292', 'rewards_train/rejected': '-0.2552', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.28049', 'logps_train/rejected': '-139.19', 'logps_train/chosen': '-163.15', 'loss/train': '0.61697', 'examples_per_second': '263.37', 'grad_norm': '37.817', 'counters/examples': 22272, 'counters/updates': 348}
skipping logging after 22336 examples to avoid logging too frequently
skipping logging after 22400 examples to avoid logging too frequently
skipping logging after 22464 examples to avoid logging too frequently
train stats after 22528 examples: {'rewards_train/chosen': '-0.058784', 'rewards_train/rejected': '-0.29064', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.23185', 'logps_train/rejected': '-162.62', 'logps_train/chosen': '-192.81', 'loss/train': '0.6182', 'examples_per_second': '274.04', 'grad_norm': '41.943', 'counters/examples': 22528, 'counters/updates': 352}
skipping logging after 22592 examples to avoid logging too frequently
skipping logging after 22656 examples to avoid logging too frequently
skipping logging after 22720 examples to avoid logging too frequently
train stats after 22784 examples: {'rewards_train/chosen': '-0.12098', 'rewards_train/rejected': '-0.38158', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.2606', 'logps_train/rejected': '-163.85', 'logps_train/chosen': '-176', 'loss/train': '0.61105', 'examples_per_second': '289.25', 'grad_norm': '41.16', 'counters/examples': 22784, 'counters/updates': 356}
skipping logging after 22848 examples to avoid logging too frequently
skipping logging after 22912 examples to avoid logging too frequently
skipping logging after 22976 examples to avoid logging too frequently
train stats after 23040 examples: {'rewards_train/chosen': '-0.039412', 'rewards_train/rejected': '-0.24251', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.2031', 'logps_train/rejected': '-145.6', 'logps_train/chosen': '-157.9', 'loss/train': '0.65217', 'examples_per_second': '264.9', 'grad_norm': '47.265', 'counters/examples': 23040, 'counters/updates': 360}
skipping logging after 23104 examples to avoid logging too frequently
skipping logging after 23168 examples to avoid logging too frequently
skipping logging after 23232 examples to avoid logging too frequently
train stats after 23296 examples: {'rewards_train/chosen': '0.043192', 'rewards_train/rejected': '-0.24104', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.28423', 'logps_train/rejected': '-180.88', 'logps_train/chosen': '-198.19', 'loss/train': '0.61507', 'examples_per_second': '274.85', 'grad_norm': '44.502', 'counters/examples': 23296, 'counters/updates': 364}
skipping logging after 23360 examples to avoid logging too frequently
skipping logging after 23424 examples to avoid logging too frequently
skipping logging after 23488 examples to avoid logging too frequently
train stats after 23552 examples: {'rewards_train/chosen': '-0.039495', 'rewards_train/rejected': '-0.3591', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.3196', 'logps_train/rejected': '-167.41', 'logps_train/chosen': '-163.85', 'loss/train': '0.62636', 'examples_per_second': '274.62', 'grad_norm': '44.399', 'counters/examples': 23552, 'counters/updates': 368}
skipping logging after 23616 examples to avoid logging too frequently
skipping logging after 23680 examples to avoid logging too frequently
skipping logging after 23744 examples to avoid logging too frequently
train stats after 23808 examples: {'rewards_train/chosen': '0.042731', 'rewards_train/rejected': '-0.17736', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.2201', 'logps_train/rejected': '-176.72', 'logps_train/chosen': '-178.86', 'loss/train': '0.63505', 'examples_per_second': '270.08', 'grad_norm': '44.37', 'counters/examples': 23808, 'counters/updates': 372}
skipping logging after 23872 examples to avoid logging too frequently
skipping logging after 23936 examples to avoid logging too frequently
Running evaluation after 23936 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:00, 17.28it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 17.43it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:00, 17.49it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 17.33it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:00<00:00, 17.31it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 17.34it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:00<00:00, 17.36it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.37it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.36it/s]
eval after 23936: {'rewards_eval/chosen': '-0.022772', 'rewards_eval/rejected': '-0.28637', 'rewards_eval/accuracies': '0.60547', 'rewards_eval/margins': '0.2636', 'logps_eval/rejected': '-152.73', 'logps_eval/chosen': '-178.09', 'loss/eval': '0.62979'}
creating checkpoint to write to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-23936...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-23936/policy.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-23936/optimizer.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-23936/scheduler.pt...
train stats after 24000 examples: {'rewards_train/chosen': '-0.094945', 'rewards_train/rejected': '-0.26411', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16916', 'logps_train/rejected': '-142.42', 'logps_train/chosen': '-170.63', 'loss/train': '0.67112', 'examples_per_second': '211.25', 'grad_norm': '45.073', 'counters/examples': 24000, 'counters/updates': 375}
skipping logging after 24064 examples to avoid logging too frequently
skipping logging after 24128 examples to avoid logging too frequently
skipping logging after 24192 examples to avoid logging too frequently
train stats after 24256 examples: {'rewards_train/chosen': '-0.15628', 'rewards_train/rejected': '-0.38304', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.22676', 'logps_train/rejected': '-149.19', 'logps_train/chosen': '-215.43', 'loss/train': '0.65842', 'examples_per_second': '274.65', 'grad_norm': '47.111', 'counters/examples': 24256, 'counters/updates': 379}
skipping logging after 24320 examples to avoid logging too frequently
skipping logging after 24384 examples to avoid logging too frequently
skipping logging after 24448 examples to avoid logging too frequently
train stats after 24512 examples: {'rewards_train/chosen': '-0.031556', 'rewards_train/rejected': '-0.40343', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.37187', 'logps_train/rejected': '-136.76', 'logps_train/chosen': '-178.08', 'loss/train': '0.5894', 'examples_per_second': '264.46', 'grad_norm': '39.635', 'counters/examples': 24512, 'counters/updates': 383}
skipping logging after 24576 examples to avoid logging too frequently
skipping logging after 24640 examples to avoid logging too frequently
skipping logging after 24704 examples to avoid logging too frequently
train stats after 24768 examples: {'rewards_train/chosen': '-0.05247', 'rewards_train/rejected': '-0.38434', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.33187', 'logps_train/rejected': '-177.56', 'logps_train/chosen': '-173.36', 'loss/train': '0.61093', 'examples_per_second': '282.03', 'grad_norm': '42.672', 'counters/examples': 24768, 'counters/updates': 387}
skipping logging after 24832 examples to avoid logging too frequently
skipping logging after 24896 examples to avoid logging too frequently
skipping logging after 24960 examples to avoid logging too frequently
train stats after 25024 examples: {'rewards_train/chosen': '0.021159', 'rewards_train/rejected': '-0.33634', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.3575', 'logps_train/rejected': '-166.55', 'logps_train/chosen': '-185.84', 'loss/train': '0.59041', 'examples_per_second': '265.56', 'grad_norm': '42.244', 'counters/examples': 25024, 'counters/updates': 391}
skipping logging after 25088 examples to avoid logging too frequently
skipping logging after 25152 examples to avoid logging too frequently
skipping logging after 25216 examples to avoid logging too frequently
train stats after 25280 examples: {'rewards_train/chosen': '0.0538', 'rewards_train/rejected': '-0.24931', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.30311', 'logps_train/rejected': '-157.84', 'logps_train/chosen': '-156.57', 'loss/train': '0.60866', 'examples_per_second': '274.49', 'grad_norm': '49.537', 'counters/examples': 25280, 'counters/updates': 395}
skipping logging after 25344 examples to avoid logging too frequently
skipping logging after 25408 examples to avoid logging too frequently
skipping logging after 25472 examples to avoid logging too frequently
train stats after 25536 examples: {'rewards_train/chosen': '-0.20575', 'rewards_train/rejected': '-0.42034', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.21459', 'logps_train/rejected': '-139.98', 'logps_train/chosen': '-171.62', 'loss/train': '0.64855', 'examples_per_second': '274.18', 'grad_norm': '42.388', 'counters/examples': 25536, 'counters/updates': 399}
skipping logging after 25600 examples to avoid logging too frequently
skipping logging after 25664 examples to avoid logging too frequently
skipping logging after 25728 examples to avoid logging too frequently
train stats after 25792 examples: {'rewards_train/chosen': '-0.071905', 'rewards_train/rejected': '-0.39761', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.32571', 'logps_train/rejected': '-166.56', 'logps_train/chosen': '-207.31', 'loss/train': '0.63282', 'examples_per_second': '267.51', 'grad_norm': '51.128', 'counters/examples': 25792, 'counters/updates': 403}
skipping logging after 25856 examples to avoid logging too frequently
skipping logging after 25920 examples to avoid logging too frequently
skipping logging after 25984 examples to avoid logging too frequently
train stats after 26048 examples: {'rewards_train/chosen': '-0.079499', 'rewards_train/rejected': '-0.34896', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.26946', 'logps_train/rejected': '-154.85', 'logps_train/chosen': '-207.31', 'loss/train': '0.63414', 'examples_per_second': '260.9', 'grad_norm': '46.868', 'counters/examples': 26048, 'counters/updates': 407}
skipping logging after 26112 examples to avoid logging too frequently
skipping logging after 26176 examples to avoid logging too frequently
skipping logging after 26240 examples to avoid logging too frequently
train stats after 26304 examples: {'rewards_train/chosen': '-0.11379', 'rewards_train/rejected': '-0.35852', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.24473', 'logps_train/rejected': '-142.66', 'logps_train/chosen': '-195.68', 'loss/train': '0.65738', 'examples_per_second': '287.63', 'grad_norm': '43.997', 'counters/examples': 26304, 'counters/updates': 411}
skipping logging after 26368 examples to avoid logging too frequently
skipping logging after 26432 examples to avoid logging too frequently
skipping logging after 26496 examples to avoid logging too frequently
train stats after 26560 examples: {'rewards_train/chosen': '-0.10688', 'rewards_train/rejected': '-0.19157', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.08469', 'logps_train/rejected': '-153.37', 'logps_train/chosen': '-157.27', 'loss/train': '0.70924', 'examples_per_second': '284.79', 'grad_norm': '45.462', 'counters/examples': 26560, 'counters/updates': 415}
skipping logging after 26624 examples to avoid logging too frequently
skipping logging after 26688 examples to avoid logging too frequently
skipping logging after 26752 examples to avoid logging too frequently
train stats after 26816 examples: {'rewards_train/chosen': '-0.012782', 'rewards_train/rejected': '-0.38304', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.37026', 'logps_train/rejected': '-144.94', 'logps_train/chosen': '-198.35', 'loss/train': '0.58242', 'examples_per_second': '273.48', 'grad_norm': '40.057', 'counters/examples': 26816, 'counters/updates': 419}
skipping logging after 26880 examples to avoid logging too frequently
skipping logging after 26944 examples to avoid logging too frequently
skipping logging after 27008 examples to avoid logging too frequently
train stats after 27072 examples: {'rewards_train/chosen': '-0.12721', 'rewards_train/rejected': '-0.29491', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1677', 'logps_train/rejected': '-139.01', 'logps_train/chosen': '-179.64', 'loss/train': '0.67034', 'examples_per_second': '270.01', 'grad_norm': '43.667', 'counters/examples': 27072, 'counters/updates': 423}
skipping logging after 27136 examples to avoid logging too frequently
skipping logging after 27200 examples to avoid logging too frequently
skipping logging after 27264 examples to avoid logging too frequently
train stats after 27328 examples: {'rewards_train/chosen': '0.077574', 'rewards_train/rejected': '-0.16486', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.24244', 'logps_train/rejected': '-187.71', 'logps_train/chosen': '-161.17', 'loss/train': '0.6301', 'examples_per_second': '270.96', 'grad_norm': '44.715', 'counters/examples': 27328, 'counters/updates': 427}
skipping logging after 27392 examples to avoid logging too frequently
skipping logging after 27456 examples to avoid logging too frequently
skipping logging after 27520 examples to avoid logging too frequently
train stats after 27584 examples: {'rewards_train/chosen': '-0.052415', 'rewards_train/rejected': '-0.30523', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25282', 'logps_train/rejected': '-154.67', 'logps_train/chosen': '-178.62', 'loss/train': '0.63537', 'examples_per_second': '267.19', 'grad_norm': '40.591', 'counters/examples': 27584, 'counters/updates': 431}
skipping logging after 27648 examples to avoid logging too frequently
skipping logging after 27712 examples to avoid logging too frequently
skipping logging after 27776 examples to avoid logging too frequently
train stats after 27840 examples: {'rewards_train/chosen': '-0.10282', 'rewards_train/rejected': '-0.38216', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.27934', 'logps_train/rejected': '-149.46', 'logps_train/chosen': '-167.64', 'loss/train': '0.61607', 'examples_per_second': '273.99', 'grad_norm': '38.257', 'counters/examples': 27840, 'counters/updates': 435}
skipping logging after 27904 examples to avoid logging too frequently
skipping logging after 27968 examples to avoid logging too frequently
skipping logging after 28032 examples to avoid logging too frequently
train stats after 28096 examples: {'rewards_train/chosen': '-0.045899', 'rewards_train/rejected': '-0.34551', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.29961', 'logps_train/rejected': '-144.85', 'logps_train/chosen': '-207.57', 'loss/train': '0.62987', 'examples_per_second': '274.54', 'grad_norm': '44.978', 'counters/examples': 28096, 'counters/updates': 439}
skipping logging after 28160 examples to avoid logging too frequently
skipping logging after 28224 examples to avoid logging too frequently
skipping logging after 28288 examples to avoid logging too frequently
train stats after 28352 examples: {'rewards_train/chosen': '-0.031583', 'rewards_train/rejected': '-0.22326', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19168', 'logps_train/rejected': '-170.82', 'logps_train/chosen': '-166.32', 'loss/train': '0.66271', 'examples_per_second': '290.96', 'grad_norm': '43.083', 'counters/examples': 28352, 'counters/updates': 443}
skipping logging after 28416 examples to avoid logging too frequently
skipping logging after 28480 examples to avoid logging too frequently
skipping logging after 28544 examples to avoid logging too frequently
train stats after 28608 examples: {'rewards_train/chosen': '0.025124', 'rewards_train/rejected': '-0.25501', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.28013', 'logps_train/rejected': '-152.42', 'logps_train/chosen': '-204.38', 'loss/train': '0.63495', 'examples_per_second': '291.64', 'grad_norm': '47.563', 'counters/examples': 28608, 'counters/updates': 447}
skipping logging after 28672 examples to avoid logging too frequently
skipping logging after 28736 examples to avoid logging too frequently
skipping logging after 28800 examples to avoid logging too frequently
train stats after 28864 examples: {'rewards_train/chosen': '-0.0054319', 'rewards_train/rejected': '-0.41538', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.40995', 'logps_train/rejected': '-136.03', 'logps_train/chosen': '-157.26', 'loss/train': '0.59012', 'examples_per_second': '273.09', 'grad_norm': '45.455', 'counters/examples': 28864, 'counters/updates': 451}
skipping logging after 28928 examples to avoid logging too frequently
skipping logging after 28992 examples to avoid logging too frequently
skipping logging after 29056 examples to avoid logging too frequently
train stats after 29120 examples: {'rewards_train/chosen': '-0.014904', 'rewards_train/rejected': '-0.25071', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.2358', 'logps_train/rejected': '-147.48', 'logps_train/chosen': '-197.24', 'loss/train': '0.63568', 'examples_per_second': '263.65', 'grad_norm': '45.888', 'counters/examples': 29120, 'counters/updates': 455}
skipping logging after 29184 examples to avoid logging too frequently
skipping logging after 29248 examples to avoid logging too frequently
skipping logging after 29312 examples to avoid logging too frequently
train stats after 29376 examples: {'rewards_train/chosen': '-0.11776', 'rewards_train/rejected': '-0.46187', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.34411', 'logps_train/rejected': '-149.11', 'logps_train/chosen': '-193.01', 'loss/train': '0.58208', 'examples_per_second': '265.07', 'grad_norm': '43.791', 'counters/examples': 29376, 'counters/updates': 459}
skipping logging after 29440 examples to avoid logging too frequently
skipping logging after 29504 examples to avoid logging too frequently
skipping logging after 29568 examples to avoid logging too frequently
train stats after 29632 examples: {'rewards_train/chosen': '-0.1051', 'rewards_train/rejected': '-0.37798', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.27288', 'logps_train/rejected': '-140.99', 'logps_train/chosen': '-162.41', 'loss/train': '0.61959', 'examples_per_second': '274.11', 'grad_norm': '38.928', 'counters/examples': 29632, 'counters/updates': 463}
skipping logging after 29696 examples to avoid logging too frequently
skipping logging after 29760 examples to avoid logging too frequently
skipping logging after 29824 examples to avoid logging too frequently
train stats after 29888 examples: {'rewards_train/chosen': '-0.19768', 'rewards_train/rejected': '-0.33833', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14065', 'logps_train/rejected': '-143.03', 'logps_train/chosen': '-159.91', 'loss/train': '0.6713', 'examples_per_second': '301.89', 'grad_norm': '40.98', 'counters/examples': 29888, 'counters/updates': 467}
skipping logging after 29952 examples to avoid logging too frequently
skipping logging after 30016 examples to avoid logging too frequently
skipping logging after 30080 examples to avoid logging too frequently
train stats after 30144 examples: {'rewards_train/chosen': '-0.34861', 'rewards_train/rejected': '-0.45921', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1106', 'logps_train/rejected': '-163.04', 'logps_train/chosen': '-169.41', 'loss/train': '0.71615', 'examples_per_second': '270.94', 'grad_norm': '48.025', 'counters/examples': 30144, 'counters/updates': 471}
skipping logging after 30208 examples to avoid logging too frequently
skipping logging after 30272 examples to avoid logging too frequently
skipping logging after 30336 examples to avoid logging too frequently
train stats after 30400 examples: {'rewards_train/chosen': '0.027142', 'rewards_train/rejected': '-0.21927', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.24642', 'logps_train/rejected': '-178.25', 'logps_train/chosen': '-178.64', 'loss/train': '0.65776', 'examples_per_second': '276.93', 'grad_norm': '44.251', 'counters/examples': 30400, 'counters/updates': 475}
skipping logging after 30464 examples to avoid logging too frequently
skipping logging after 30528 examples to avoid logging too frequently
skipping logging after 30592 examples to avoid logging too frequently
train stats after 30656 examples: {'rewards_train/chosen': '-0.078068', 'rewards_train/rejected': '-0.48668', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.40861', 'logps_train/rejected': '-177.54', 'logps_train/chosen': '-176.84', 'loss/train': '0.58262', 'examples_per_second': '265.54', 'grad_norm': '43.04', 'counters/examples': 30656, 'counters/updates': 479}
skipping logging after 30720 examples to avoid logging too frequently
skipping logging after 30784 examples to avoid logging too frequently
skipping logging after 30848 examples to avoid logging too frequently
train stats after 30912 examples: {'rewards_train/chosen': '-0.13853', 'rewards_train/rejected': '-0.39275', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.25422', 'logps_train/rejected': '-149.83', 'logps_train/chosen': '-197.19', 'loss/train': '0.64982', 'examples_per_second': '274.21', 'grad_norm': '47.377', 'counters/examples': 30912, 'counters/updates': 483}
skipping logging after 30976 examples to avoid logging too frequently
skipping logging after 31040 examples to avoid logging too frequently
skipping logging after 31104 examples to avoid logging too frequently
train stats after 31168 examples: {'rewards_train/chosen': '0.057933', 'rewards_train/rejected': '-0.18021', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.23815', 'logps_train/rejected': '-181.1', 'logps_train/chosen': '-183.62', 'loss/train': '0.64863', 'examples_per_second': '273.15', 'grad_norm': '50.703', 'counters/examples': 31168, 'counters/updates': 487}
skipping logging after 31232 examples to avoid logging too frequently
skipping logging after 31296 examples to avoid logging too frequently
skipping logging after 31360 examples to avoid logging too frequently
train stats after 31424 examples: {'rewards_train/chosen': '-0.016514', 'rewards_train/rejected': '-0.49249', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.47597', 'logps_train/rejected': '-148.04', 'logps_train/chosen': '-187.77', 'loss/train': '0.55323', 'examples_per_second': '265.19', 'grad_norm': '38.24', 'counters/examples': 31424, 'counters/updates': 491}
skipping logging after 31488 examples to avoid logging too frequently
skipping logging after 31552 examples to avoid logging too frequently
skipping logging after 31616 examples to avoid logging too frequently
train stats after 31680 examples: {'rewards_train/chosen': '-0.093584', 'rewards_train/rejected': '-0.20243', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10885', 'logps_train/rejected': '-163.4', 'logps_train/chosen': '-193.08', 'loss/train': '0.71493', 'examples_per_second': '274.47', 'grad_norm': '50.34', 'counters/examples': 31680, 'counters/updates': 495}
skipping logging after 31744 examples to avoid logging too frequently
skipping logging after 31808 examples to avoid logging too frequently
skipping logging after 31872 examples to avoid logging too frequently
train stats after 31936 examples: {'rewards_train/chosen': '-0.12762', 'rewards_train/rejected': '-0.40794', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.28032', 'logps_train/rejected': '-177.64', 'logps_train/chosen': '-171.13', 'loss/train': '0.66122', 'examples_per_second': '264.97', 'grad_norm': '54.582', 'counters/examples': 31936, 'counters/updates': 499}
skipping logging after 32000 examples to avoid logging too frequently
skipping logging after 32064 examples to avoid logging too frequently
skipping logging after 32128 examples to avoid logging too frequently
train stats after 32192 examples: {'rewards_train/chosen': '-0.11579', 'rewards_train/rejected': '-0.46241', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.34662', 'logps_train/rejected': '-165.86', 'logps_train/chosen': '-170.15', 'loss/train': '0.60056', 'examples_per_second': '264.13', 'grad_norm': '44.618', 'counters/examples': 32192, 'counters/updates': 503}
skipping logging after 32256 examples to avoid logging too frequently
skipping logging after 32320 examples to avoid logging too frequently
skipping logging after 32384 examples to avoid logging too frequently
train stats after 32448 examples: {'rewards_train/chosen': '-0.10583', 'rewards_train/rejected': '-0.44103', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.3352', 'logps_train/rejected': '-174.28', 'logps_train/chosen': '-189.63', 'loss/train': '0.60513', 'examples_per_second': '274.78', 'grad_norm': '49.355', 'counters/examples': 32448, 'counters/updates': 507}
skipping logging after 32512 examples to avoid logging too frequently
skipping logging after 32576 examples to avoid logging too frequently
skipping logging after 32640 examples to avoid logging too frequently
train stats after 32704 examples: {'rewards_train/chosen': '-0.059834', 'rewards_train/rejected': '-0.222', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.16217', 'logps_train/rejected': '-162.37', 'logps_train/chosen': '-208.77', 'loss/train': '0.65532', 'examples_per_second': '273.74', 'grad_norm': '49.126', 'counters/examples': 32704, 'counters/updates': 511}
skipping logging after 32768 examples to avoid logging too frequently
skipping logging after 32832 examples to avoid logging too frequently
skipping logging after 32896 examples to avoid logging too frequently
train stats after 32960 examples: {'rewards_train/chosen': '-0.12359', 'rewards_train/rejected': '-0.3833', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.2597', 'logps_train/rejected': '-182.64', 'logps_train/chosen': '-190.54', 'loss/train': '0.63328', 'examples_per_second': '261.98', 'grad_norm': '52.213', 'counters/examples': 32960, 'counters/updates': 515}
skipping logging after 33024 examples to avoid logging too frequently
skipping logging after 33088 examples to avoid logging too frequently
skipping logging after 33152 examples to avoid logging too frequently
train stats after 33216 examples: {'rewards_train/chosen': '-0.12759', 'rewards_train/rejected': '-0.39889', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.2713', 'logps_train/rejected': '-169.95', 'logps_train/chosen': '-174.38', 'loss/train': '0.65805', 'examples_per_second': '267.77', 'grad_norm': '45.783', 'counters/examples': 33216, 'counters/updates': 519}
skipping logging after 33280 examples to avoid logging too frequently
skipping logging after 33344 examples to avoid logging too frequently
skipping logging after 33408 examples to avoid logging too frequently
train stats after 33472 examples: {'rewards_train/chosen': '-0.0080107', 'rewards_train/rejected': '-0.40242', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.39441', 'logps_train/rejected': '-163.87', 'logps_train/chosen': '-192.02', 'loss/train': '0.58009', 'examples_per_second': '274.53', 'grad_norm': '47.775', 'counters/examples': 33472, 'counters/updates': 523}
skipping logging after 33536 examples to avoid logging too frequently
skipping logging after 33600 examples to avoid logging too frequently
skipping logging after 33664 examples to avoid logging too frequently
train stats after 33728 examples: {'rewards_train/chosen': '0.039171', 'rewards_train/rejected': '-0.25318', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.29235', 'logps_train/rejected': '-164.45', 'logps_train/chosen': '-178.94', 'loss/train': '0.6224', 'examples_per_second': '262.96', 'grad_norm': '46.556', 'counters/examples': 33728, 'counters/updates': 527}
skipping logging after 33792 examples to avoid logging too frequently
skipping logging after 33856 examples to avoid logging too frequently
skipping logging after 33920 examples to avoid logging too frequently
train stats after 33984 examples: {'rewards_train/chosen': '-0.0033725', 'rewards_train/rejected': '-0.3071', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.30373', 'logps_train/rejected': '-144.23', 'logps_train/chosen': '-184.54', 'loss/train': '0.59171', 'examples_per_second': '273.96', 'grad_norm': '44.612', 'counters/examples': 33984, 'counters/updates': 531}
skipping logging after 34048 examples to avoid logging too frequently
skipping logging after 34112 examples to avoid logging too frequently
skipping logging after 34176 examples to avoid logging too frequently
train stats after 34240 examples: {'rewards_train/chosen': '-0.06332', 'rewards_train/rejected': '-0.62631', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.56299', 'logps_train/rejected': '-150.65', 'logps_train/chosen': '-174.26', 'loss/train': '0.52391', 'examples_per_second': '286.89', 'grad_norm': '36.675', 'counters/examples': 34240, 'counters/updates': 535}
skipping logging after 34304 examples to avoid logging too frequently
skipping logging after 34368 examples to avoid logging too frequently
skipping logging after 34432 examples to avoid logging too frequently
train stats after 34496 examples: {'rewards_train/chosen': '-0.25632', 'rewards_train/rejected': '-0.45186', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.19554', 'logps_train/rejected': '-165.06', 'logps_train/chosen': '-170.6', 'loss/train': '0.64647', 'examples_per_second': '274.83', 'grad_norm': '41.316', 'counters/examples': 34496, 'counters/updates': 539}
skipping logging after 34560 examples to avoid logging too frequently
skipping logging after 34624 examples to avoid logging too frequently
skipping logging after 34688 examples to avoid logging too frequently
train stats after 34752 examples: {'rewards_train/chosen': '-0.03876', 'rewards_train/rejected': '-0.35102', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.31226', 'logps_train/rejected': '-146.52', 'logps_train/chosen': '-162.56', 'loss/train': '0.61277', 'examples_per_second': '278.33', 'grad_norm': '41.195', 'counters/examples': 34752, 'counters/updates': 543}
skipping logging after 34816 examples to avoid logging too frequently
skipping logging after 34880 examples to avoid logging too frequently
skipping logging after 34944 examples to avoid logging too frequently
train stats after 35008 examples: {'rewards_train/chosen': '-0.087337', 'rewards_train/rejected': '-0.51875', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.43141', 'logps_train/rejected': '-149.65', 'logps_train/chosen': '-180.95', 'loss/train': '0.57845', 'examples_per_second': '283.67', 'grad_norm': '38.302', 'counters/examples': 35008, 'counters/updates': 547}
skipping logging after 35072 examples to avoid logging too frequently
skipping logging after 35136 examples to avoid logging too frequently
skipping logging after 35200 examples to avoid logging too frequently
train stats after 35264 examples: {'rewards_train/chosen': '-0.17365', 'rewards_train/rejected': '-0.56794', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.39428', 'logps_train/rejected': '-147.15', 'logps_train/chosen': '-169.31', 'loss/train': '0.58275', 'examples_per_second': '274.19', 'grad_norm': '39.973', 'counters/examples': 35264, 'counters/updates': 551}
skipping logging after 35328 examples to avoid logging too frequently
skipping logging after 35392 examples to avoid logging too frequently
skipping logging after 35456 examples to avoid logging too frequently
train stats after 35520 examples: {'rewards_train/chosen': '-0.21957', 'rewards_train/rejected': '-0.60669', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.38712', 'logps_train/rejected': '-148.87', 'logps_train/chosen': '-191.69', 'loss/train': '0.5936', 'examples_per_second': '274.04', 'grad_norm': '41.922', 'counters/examples': 35520, 'counters/updates': 555}
skipping logging after 35584 examples to avoid logging too frequently
skipping logging after 35648 examples to avoid logging too frequently
skipping logging after 35712 examples to avoid logging too frequently
train stats after 35776 examples: {'rewards_train/chosen': '-0.012684', 'rewards_train/rejected': '-0.30256', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.28987', 'logps_train/rejected': '-195.27', 'logps_train/chosen': '-184.58', 'loss/train': '0.6187', 'examples_per_second': '263.53', 'grad_norm': '47.943', 'counters/examples': 35776, 'counters/updates': 559}
skipping logging after 35840 examples to avoid logging too frequently
skipping logging after 35904 examples to avoid logging too frequently
Running evaluation after 35904 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:00, 17.26it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 17.46it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:00, 17.57it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 17.49it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:00<00:00, 17.47it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 17.46it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:00<00:00, 17.36it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.34it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.40it/s]
eval after 35904: {'rewards_eval/chosen': '-0.023198', 'rewards_eval/rejected': '-0.31273', 'rewards_eval/accuracies': '0.61719', 'rewards_eval/margins': '0.28953', 'logps_eval/rejected': '-152.99', 'logps_eval/chosen': '-178.1', 'loss/eval': '0.63339'}
creating checkpoint to write to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-35904...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-35904/policy.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-35904/optimizer.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-35904/scheduler.pt...
train stats after 35968 examples: {'rewards_train/chosen': '-0.03753', 'rewards_train/rejected': '-0.36837', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.33085', 'logps_train/rejected': '-133.52', 'logps_train/chosen': '-153.94', 'loss/train': '0.59922', 'examples_per_second': '216.56', 'grad_norm': '41.309', 'counters/examples': 35968, 'counters/updates': 562}
skipping logging after 36032 examples to avoid logging too frequently
skipping logging after 36096 examples to avoid logging too frequently
skipping logging after 36160 examples to avoid logging too frequently
train stats after 36224 examples: {'rewards_train/chosen': '0.098814', 'rewards_train/rejected': '-0.26192', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.36073', 'logps_train/rejected': '-184.44', 'logps_train/chosen': '-182.67', 'loss/train': '0.59149', 'examples_per_second': '275.21', 'grad_norm': '46.158', 'counters/examples': 36224, 'counters/updates': 566}
skipping logging after 36288 examples to avoid logging too frequently
skipping logging after 36352 examples to avoid logging too frequently
skipping logging after 36416 examples to avoid logging too frequently
train stats after 36480 examples: {'rewards_train/chosen': '0.083391', 'rewards_train/rejected': '-0.26662', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.35001', 'logps_train/rejected': '-150.39', 'logps_train/chosen': '-174.77', 'loss/train': '0.58703', 'examples_per_second': '284.01', 'grad_norm': '39.564', 'counters/examples': 36480, 'counters/updates': 570}
skipping logging after 36544 examples to avoid logging too frequently
skipping logging after 36608 examples to avoid logging too frequently
skipping logging after 36672 examples to avoid logging too frequently
train stats after 36736 examples: {'rewards_train/chosen': '-0.1394', 'rewards_train/rejected': '-0.41428', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.27489', 'logps_train/rejected': '-126.05', 'logps_train/chosen': '-188.37', 'loss/train': '0.64989', 'examples_per_second': '273.73', 'grad_norm': '42.863', 'counters/examples': 36736, 'counters/updates': 574}
skipping logging after 36800 examples to avoid logging too frequently
skipping logging after 36864 examples to avoid logging too frequently
skipping logging after 36928 examples to avoid logging too frequently
train stats after 36992 examples: {'rewards_train/chosen': '-0.13374', 'rewards_train/rejected': '-0.41159', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.27785', 'logps_train/rejected': '-180.08', 'logps_train/chosen': '-172.05', 'loss/train': '0.64703', 'examples_per_second': '272.41', 'grad_norm': '47.353', 'counters/examples': 36992, 'counters/updates': 578}
skipping logging after 37056 examples to avoid logging too frequently
skipping logging after 37120 examples to avoid logging too frequently
skipping logging after 37184 examples to avoid logging too frequently
train stats after 37248 examples: {'rewards_train/chosen': '-0.18148', 'rewards_train/rejected': '-0.59824', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.41677', 'logps_train/rejected': '-144.21', 'logps_train/chosen': '-171.6', 'loss/train': '0.58311', 'examples_per_second': '275.84', 'grad_norm': '37.889', 'counters/examples': 37248, 'counters/updates': 582}
skipping logging after 37312 examples to avoid logging too frequently
skipping logging after 37376 examples to avoid logging too frequently
skipping logging after 37440 examples to avoid logging too frequently
train stats after 37504 examples: {'rewards_train/chosen': '-0.21316', 'rewards_train/rejected': '-0.43136', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.2182', 'logps_train/rejected': '-161.84', 'logps_train/chosen': '-171.08', 'loss/train': '0.63898', 'examples_per_second': '266.03', 'grad_norm': '47.133', 'counters/examples': 37504, 'counters/updates': 586}
skipping logging after 37568 examples to avoid logging too frequently
skipping logging after 37632 examples to avoid logging too frequently
skipping logging after 37696 examples to avoid logging too frequently
train stats after 37760 examples: {'rewards_train/chosen': '-0.020983', 'rewards_train/rejected': '-0.47221', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.45123', 'logps_train/rejected': '-146.6', 'logps_train/chosen': '-190.01', 'loss/train': '0.56994', 'examples_per_second': '273.72', 'grad_norm': '38.98', 'counters/examples': 37760, 'counters/updates': 590}
skipping logging after 37824 examples to avoid logging too frequently
skipping logging after 37888 examples to avoid logging too frequently
skipping logging after 37952 examples to avoid logging too frequently
train stats after 38016 examples: {'rewards_train/chosen': '-0.04663', 'rewards_train/rejected': '-0.29311', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.24648', 'logps_train/rejected': '-164.71', 'logps_train/chosen': '-197.69', 'loss/train': '0.64805', 'examples_per_second': '274.55', 'grad_norm': '46.66', 'counters/examples': 38016, 'counters/updates': 594}
skipping logging after 38080 examples to avoid logging too frequently
skipping logging after 38144 examples to avoid logging too frequently
skipping logging after 38208 examples to avoid logging too frequently
train stats after 38272 examples: {'rewards_train/chosen': '0.017273', 'rewards_train/rejected': '-0.26993', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.2872', 'logps_train/rejected': '-153.96', 'logps_train/chosen': '-180.46', 'loss/train': '0.62418', 'examples_per_second': '263.64', 'grad_norm': '42.339', 'counters/examples': 38272, 'counters/updates': 598}
skipping logging after 38336 examples to avoid logging too frequently
skipping logging after 38400 examples to avoid logging too frequently
skipping logging after 38464 examples to avoid logging too frequently
train stats after 38528 examples: {'rewards_train/chosen': '-0.084805', 'rewards_train/rejected': '-0.35513', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.27033', 'logps_train/rejected': '-170.6', 'logps_train/chosen': '-190.92', 'loss/train': '0.64718', 'examples_per_second': '264.24', 'grad_norm': '50.91', 'counters/examples': 38528, 'counters/updates': 602}
skipping logging after 38592 examples to avoid logging too frequently
skipping logging after 38656 examples to avoid logging too frequently
skipping logging after 38720 examples to avoid logging too frequently
train stats after 38784 examples: {'rewards_train/chosen': '-0.093145', 'rewards_train/rejected': '-0.41192', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.31877', 'logps_train/rejected': '-178.32', 'logps_train/chosen': '-190.34', 'loss/train': '0.58971', 'examples_per_second': '262.81', 'grad_norm': '48.342', 'counters/examples': 38784, 'counters/updates': 606}
skipping logging after 38848 examples to avoid logging too frequently
skipping logging after 38912 examples to avoid logging too frequently
skipping logging after 38976 examples to avoid logging too frequently
train stats after 39040 examples: {'rewards_train/chosen': '-0.2323', 'rewards_train/rejected': '-0.65226', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.41996', 'logps_train/rejected': '-172.1', 'logps_train/chosen': '-169.64', 'loss/train': '0.59546', 'examples_per_second': '269.5', 'grad_norm': '41.474', 'counters/examples': 39040, 'counters/updates': 610}
skipping logging after 39104 examples to avoid logging too frequently
skipping logging after 39168 examples to avoid logging too frequently
skipping logging after 39232 examples to avoid logging too frequently
train stats after 39296 examples: {'rewards_train/chosen': '-0.2007', 'rewards_train/rejected': '-0.42428', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.22358', 'logps_train/rejected': '-156.38', 'logps_train/chosen': '-176.92', 'loss/train': '0.68813', 'examples_per_second': '283.14', 'grad_norm': '47.509', 'counters/examples': 39296, 'counters/updates': 614}
skipping logging after 39360 examples to avoid logging too frequently
skipping logging after 39424 examples to avoid logging too frequently
skipping logging after 39488 examples to avoid logging too frequently
train stats after 39552 examples: {'rewards_train/chosen': '-0.13715', 'rewards_train/rejected': '-0.38613', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.24898', 'logps_train/rejected': '-157.73', 'logps_train/chosen': '-166.64', 'loss/train': '0.65807', 'examples_per_second': '263.31', 'grad_norm': '51.326', 'counters/examples': 39552, 'counters/updates': 618}
skipping logging after 39616 examples to avoid logging too frequently
skipping logging after 39680 examples to avoid logging too frequently
skipping logging after 39744 examples to avoid logging too frequently
train stats after 39808 examples: {'rewards_train/chosen': '-0.1169', 'rewards_train/rejected': '-0.31262', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19572', 'logps_train/rejected': '-163.59', 'logps_train/chosen': '-176.76', 'loss/train': '0.66983', 'examples_per_second': '281.78', 'grad_norm': '49.243', 'counters/examples': 39808, 'counters/updates': 622}
skipping logging after 39872 examples to avoid logging too frequently
skipping logging after 39936 examples to avoid logging too frequently
skipping logging after 40000 examples to avoid logging too frequently
train stats after 40064 examples: {'rewards_train/chosen': '-0.077948', 'rewards_train/rejected': '-0.45902', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.38108', 'logps_train/rejected': '-143.51', 'logps_train/chosen': '-185.77', 'loss/train': '0.60863', 'examples_per_second': '262.79', 'grad_norm': '44.259', 'counters/examples': 40064, 'counters/updates': 626}
skipping logging after 40128 examples to avoid logging too frequently
skipping logging after 40192 examples to avoid logging too frequently
skipping logging after 40256 examples to avoid logging too frequently
train stats after 40320 examples: {'rewards_train/chosen': '-0.089086', 'rewards_train/rejected': '-0.46747', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.37838', 'logps_train/rejected': '-163.46', 'logps_train/chosen': '-172.65', 'loss/train': '0.61858', 'examples_per_second': '274.06', 'grad_norm': '46.511', 'counters/examples': 40320, 'counters/updates': 630}
skipping logging after 40384 examples to avoid logging too frequently
skipping logging after 40448 examples to avoid logging too frequently
skipping logging after 40512 examples to avoid logging too frequently
train stats after 40576 examples: {'rewards_train/chosen': '-0.19973', 'rewards_train/rejected': '-0.44167', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.24194', 'logps_train/rejected': '-159.32', 'logps_train/chosen': '-186.44', 'loss/train': '0.65045', 'examples_per_second': '275.04', 'grad_norm': '55.082', 'counters/examples': 40576, 'counters/updates': 634}
skipping logging after 40640 examples to avoid logging too frequently
skipping logging after 40704 examples to avoid logging too frequently
skipping logging after 40768 examples to avoid logging too frequently
train stats after 40832 examples: {'rewards_train/chosen': '-0.25672', 'rewards_train/rejected': '-0.46154', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.20482', 'logps_train/rejected': '-150.2', 'logps_train/chosen': '-165.22', 'loss/train': '0.66395', 'examples_per_second': '319.39', 'grad_norm': '46.202', 'counters/examples': 40832, 'counters/updates': 638}
skipping logging after 40896 examples to avoid logging too frequently
skipping logging after 40960 examples to avoid logging too frequently
skipping logging after 41024 examples to avoid logging too frequently
train stats after 41088 examples: {'rewards_train/chosen': '-0.164', 'rewards_train/rejected': '-0.34983', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.18583', 'logps_train/rejected': '-177.84', 'logps_train/chosen': '-201.64', 'loss/train': '0.69487', 'examples_per_second': '273.77', 'grad_norm': '51.923', 'counters/examples': 41088, 'counters/updates': 642}
skipping logging after 41152 examples to avoid logging too frequently
skipping logging after 41216 examples to avoid logging too frequently
skipping logging after 41280 examples to avoid logging too frequently
train stats after 41344 examples: {'rewards_train/chosen': '-0.29344', 'rewards_train/rejected': '-0.46255', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16911', 'logps_train/rejected': '-140.48', 'logps_train/chosen': '-160.74', 'loss/train': '0.71382', 'examples_per_second': '286.23', 'grad_norm': '47.407', 'counters/examples': 41344, 'counters/updates': 646}
skipping logging after 41408 examples to avoid logging too frequently
skipping logging after 41472 examples to avoid logging too frequently
skipping logging after 41536 examples to avoid logging too frequently
train stats after 41600 examples: {'rewards_train/chosen': '-0.19898', 'rewards_train/rejected': '-0.38074', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.18176', 'logps_train/rejected': '-178', 'logps_train/chosen': '-160.89', 'loss/train': '0.67658', 'examples_per_second': '265.05', 'grad_norm': '50.409', 'counters/examples': 41600, 'counters/updates': 650}
skipping logging after 41664 examples to avoid logging too frequently
skipping logging after 41728 examples to avoid logging too frequently
skipping logging after 41792 examples to avoid logging too frequently
train stats after 41856 examples: {'rewards_train/chosen': '-0.16944', 'rewards_train/rejected': '-0.5108', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.34136', 'logps_train/rejected': '-148.36', 'logps_train/chosen': '-176.09', 'loss/train': '0.64084', 'examples_per_second': '273.8', 'grad_norm': '43.598', 'counters/examples': 41856, 'counters/updates': 654}
skipping logging after 41920 examples to avoid logging too frequently
skipping logging after 41984 examples to avoid logging too frequently
skipping logging after 42048 examples to avoid logging too frequently
train stats after 42112 examples: {'rewards_train/chosen': '-0.049353', 'rewards_train/rejected': '-0.48852', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.43917', 'logps_train/rejected': '-164.18', 'logps_train/chosen': '-152.01', 'loss/train': '0.56587', 'examples_per_second': '272.16', 'grad_norm': '45.964', 'counters/examples': 42112, 'counters/updates': 658}
skipping logging after 42176 examples to avoid logging too frequently
skipping logging after 42240 examples to avoid logging too frequently
skipping logging after 42304 examples to avoid logging too frequently
train stats after 42368 examples: {'rewards_train/chosen': '-0.25535', 'rewards_train/rejected': '-0.64201', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.38666', 'logps_train/rejected': '-147.59', 'logps_train/chosen': '-156.95', 'loss/train': '0.59256', 'examples_per_second': '305.74', 'grad_norm': '37.78', 'counters/examples': 42368, 'counters/updates': 662}
skipping logging after 42432 examples to avoid logging too frequently
skipping logging after 42496 examples to avoid logging too frequently
skipping logging after 42560 examples to avoid logging too frequently
train stats after 42624 examples: {'rewards_train/chosen': '-0.21503', 'rewards_train/rejected': '-0.59115', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.37612', 'logps_train/rejected': '-145.5', 'logps_train/chosen': '-175.67', 'loss/train': '0.61433', 'examples_per_second': '266.24', 'grad_norm': '39.253', 'counters/examples': 42624, 'counters/updates': 666}
skipping logging after 42688 examples to avoid logging too frequently
skipping logging after 42752 examples to avoid logging too frequently
skipping logging after 42816 examples to avoid logging too frequently
train stats after 42880 examples: {'rewards_train/chosen': '-0.086308', 'rewards_train/rejected': '-0.40331', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.31701', 'logps_train/rejected': '-162.73', 'logps_train/chosen': '-142.18', 'loss/train': '0.62207', 'examples_per_second': '286.52', 'grad_norm': '40.561', 'counters/examples': 42880, 'counters/updates': 670}
skipping logging after 42944 examples to avoid logging too frequently
skipping logging after 43008 examples to avoid logging too frequently
skipping logging after 43072 examples to avoid logging too frequently
train stats after 43136 examples: {'rewards_train/chosen': '-0.20164', 'rewards_train/rejected': '-0.37491', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.17327', 'logps_train/rejected': '-162.5', 'logps_train/chosen': '-179.66', 'loss/train': '0.66878', 'examples_per_second': '275.49', 'grad_norm': '46.505', 'counters/examples': 43136, 'counters/updates': 674}
skipping logging after 43200 examples to avoid logging too frequently
skipping logging after 43264 examples to avoid logging too frequently
skipping logging after 43328 examples to avoid logging too frequently
train stats after 43392 examples: {'rewards_train/chosen': '-0.0061563', 'rewards_train/rejected': '-0.24561', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.23946', 'logps_train/rejected': '-156.19', 'logps_train/chosen': '-177.7', 'loss/train': '0.63293', 'examples_per_second': '267.71', 'grad_norm': '47.723', 'counters/examples': 43392, 'counters/updates': 678}
skipping logging after 43456 examples to avoid logging too frequently
skipping logging after 43520 examples to avoid logging too frequently
skipping logging after 43584 examples to avoid logging too frequently
train stats after 43648 examples: {'rewards_train/chosen': '-0.14937', 'rewards_train/rejected': '-0.52015', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.37078', 'logps_train/rejected': '-112.29', 'logps_train/chosen': '-163.94', 'loss/train': '0.5974', 'examples_per_second': '272.33', 'grad_norm': '39.751', 'counters/examples': 43648, 'counters/updates': 682}
skipping logging after 43712 examples to avoid logging too frequently
skipping logging after 43776 examples to avoid logging too frequently
skipping logging after 43840 examples to avoid logging too frequently
train stats after 43904 examples: {'rewards_train/chosen': '-0.23373', 'rewards_train/rejected': '-0.55571', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.32198', 'logps_train/rejected': '-138.01', 'logps_train/chosen': '-175.17', 'loss/train': '0.64273', 'examples_per_second': '304.67', 'grad_norm': '36.72', 'counters/examples': 43904, 'counters/updates': 686}
skipping logging after 43968 examples to avoid logging too frequently
skipping logging after 44032 examples to avoid logging too frequently
skipping logging after 44096 examples to avoid logging too frequently
train stats after 44160 examples: {'rewards_train/chosen': '-0.1534', 'rewards_train/rejected': '-0.39491', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.24151', 'logps_train/rejected': '-160.45', 'logps_train/chosen': '-194.9', 'loss/train': '0.66607', 'examples_per_second': '273.77', 'grad_norm': '44.247', 'counters/examples': 44160, 'counters/updates': 690}
skipping logging after 44224 examples to avoid logging too frequently
skipping logging after 44288 examples to avoid logging too frequently
skipping logging after 44352 examples to avoid logging too frequently
train stats after 44416 examples: {'rewards_train/chosen': '-0.070377', 'rewards_train/rejected': '-0.37114', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.30077', 'logps_train/rejected': '-150.58', 'logps_train/chosen': '-176.5', 'loss/train': '0.63876', 'examples_per_second': '274.86', 'grad_norm': '41.166', 'counters/examples': 44416, 'counters/updates': 694}
skipping logging after 44480 examples to avoid logging too frequently
skipping logging after 44544 examples to avoid logging too frequently
skipping logging after 44608 examples to avoid logging too frequently
train stats after 44672 examples: {'rewards_train/chosen': '-0.144', 'rewards_train/rejected': '-0.28375', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13974', 'logps_train/rejected': '-144.04', 'logps_train/chosen': '-173.93', 'loss/train': '0.68124', 'examples_per_second': '274.55', 'grad_norm': '45.857', 'counters/examples': 44672, 'counters/updates': 698}
skipping logging after 44736 examples to avoid logging too frequently
skipping logging after 44800 examples to avoid logging too frequently
skipping logging after 44864 examples to avoid logging too frequently
train stats after 44928 examples: {'rewards_train/chosen': '-0.088938', 'rewards_train/rejected': '-0.26315', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.17421', 'logps_train/rejected': '-180.02', 'logps_train/chosen': '-186.56', 'loss/train': '0.67383', 'examples_per_second': '273.76', 'grad_norm': '56.648', 'counters/examples': 44928, 'counters/updates': 702}
skipping logging after 44992 examples to avoid logging too frequently
skipping logging after 45056 examples to avoid logging too frequently
skipping logging after 45120 examples to avoid logging too frequently
train stats after 45184 examples: {'rewards_train/chosen': '-0.261', 'rewards_train/rejected': '-0.55728', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.29627', 'logps_train/rejected': '-138.73', 'logps_train/chosen': '-162.8', 'loss/train': '0.61423', 'examples_per_second': '271.97', 'grad_norm': '38.718', 'counters/examples': 45184, 'counters/updates': 706}
skipping logging after 45248 examples to avoid logging too frequently
skipping logging after 45312 examples to avoid logging too frequently
skipping logging after 45376 examples to avoid logging too frequently
train stats after 45440 examples: {'rewards_train/chosen': '-0.17187', 'rewards_train/rejected': '-0.34274', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17088', 'logps_train/rejected': '-149.11', 'logps_train/chosen': '-161.29', 'loss/train': '0.68555', 'examples_per_second': '272.5', 'grad_norm': '42.375', 'counters/examples': 45440, 'counters/updates': 710}
skipping logging after 45504 examples to avoid logging too frequently
skipping logging after 45568 examples to avoid logging too frequently
skipping logging after 45632 examples to avoid logging too frequently
train stats after 45696 examples: {'rewards_train/chosen': '-0.29003', 'rewards_train/rejected': '-0.60447', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.31444', 'logps_train/rejected': '-163.91', 'logps_train/chosen': '-168.35', 'loss/train': '0.6262', 'examples_per_second': '273.75', 'grad_norm': '52.68', 'counters/examples': 45696, 'counters/updates': 714}
skipping logging after 45760 examples to avoid logging too frequently
skipping logging after 45824 examples to avoid logging too frequently
skipping logging after 45888 examples to avoid logging too frequently
train stats after 45952 examples: {'rewards_train/chosen': '-0.26086', 'rewards_train/rejected': '-0.54161', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.28075', 'logps_train/rejected': '-144.5', 'logps_train/chosen': '-180.36', 'loss/train': '0.65322', 'examples_per_second': '280.52', 'grad_norm': '45.928', 'counters/examples': 45952, 'counters/updates': 718}
skipping logging after 46016 examples to avoid logging too frequently
skipping logging after 46080 examples to avoid logging too frequently
skipping logging after 46144 examples to avoid logging too frequently
train stats after 46208 examples: {'rewards_train/chosen': '-0.073442', 'rewards_train/rejected': '-0.58071', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.50727', 'logps_train/rejected': '-148.95', 'logps_train/chosen': '-188.55', 'loss/train': '0.5547', 'examples_per_second': '273.06', 'grad_norm': '41.456', 'counters/examples': 46208, 'counters/updates': 722}
skipping logging after 46272 examples to avoid logging too frequently
skipping logging after 46336 examples to avoid logging too frequently
skipping logging after 46400 examples to avoid logging too frequently
train stats after 46464 examples: {'rewards_train/chosen': '-0.28969', 'rewards_train/rejected': '-0.49869', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.209', 'logps_train/rejected': '-157.79', 'logps_train/chosen': '-150.38', 'loss/train': '0.63896', 'examples_per_second': '274.09', 'grad_norm': '49.28', 'counters/examples': 46464, 'counters/updates': 726}
skipping logging after 46528 examples to avoid logging too frequently
skipping logging after 46592 examples to avoid logging too frequently
skipping logging after 46656 examples to avoid logging too frequently
train stats after 46720 examples: {'rewards_train/chosen': '-0.011354', 'rewards_train/rejected': '-0.24921', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.23785', 'logps_train/rejected': '-174.23', 'logps_train/chosen': '-200.33', 'loss/train': '0.64711', 'examples_per_second': '268.9', 'grad_norm': '50.99', 'counters/examples': 46720, 'counters/updates': 730}
skipping logging after 46784 examples to avoid logging too frequently
skipping logging after 46848 examples to avoid logging too frequently
skipping logging after 46912 examples to avoid logging too frequently
train stats after 46976 examples: {'rewards_train/chosen': '-0.16743', 'rewards_train/rejected': '-0.51523', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.34779', 'logps_train/rejected': '-141.71', 'logps_train/chosen': '-186.85', 'loss/train': '0.64378', 'examples_per_second': '265.3', 'grad_norm': '47.392', 'counters/examples': 46976, 'counters/updates': 734}
skipping logging after 47040 examples to avoid logging too frequently
skipping logging after 47104 examples to avoid logging too frequently
skipping logging after 47168 examples to avoid logging too frequently
train stats after 47232 examples: {'rewards_train/chosen': '-0.011163', 'rewards_train/rejected': '-0.52954', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.51838', 'logps_train/rejected': '-140.91', 'logps_train/chosen': '-154.81', 'loss/train': '0.55226', 'examples_per_second': '272.84', 'grad_norm': '42.673', 'counters/examples': 47232, 'counters/updates': 738}
skipping logging after 47296 examples to avoid logging too frequently
skipping logging after 47360 examples to avoid logging too frequently
skipping logging after 47424 examples to avoid logging too frequently
train stats after 47488 examples: {'rewards_train/chosen': '-0.25264', 'rewards_train/rejected': '-0.54191', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.28926', 'logps_train/rejected': '-170.63', 'logps_train/chosen': '-197.02', 'loss/train': '0.65141', 'examples_per_second': '273.81', 'grad_norm': '45.015', 'counters/examples': 47488, 'counters/updates': 742}
skipping logging after 47552 examples to avoid logging too frequently
skipping logging after 47616 examples to avoid logging too frequently
skipping logging after 47680 examples to avoid logging too frequently
train stats after 47744 examples: {'rewards_train/chosen': '-0.066844', 'rewards_train/rejected': '-0.34769', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.28085', 'logps_train/rejected': '-152.97', 'logps_train/chosen': '-161.52', 'loss/train': '0.62138', 'examples_per_second': '279.66', 'grad_norm': '42.768', 'counters/examples': 47744, 'counters/updates': 746}
skipping logging after 47808 examples to avoid logging too frequently
skipping logging after 47872 examples to avoid logging too frequently
Running evaluation after 47872 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:00, 17.32it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 17.42it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:00, 17.56it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 17.46it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:00<00:00, 17.45it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 17.45it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:00<00:00, 17.32it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.33it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.38it/s]
eval after 47872: {'rewards_eval/chosen': '-0.034091', 'rewards_eval/rejected': '-0.33892', 'rewards_eval/accuracies': '0.64062', 'rewards_eval/margins': '0.30483', 'logps_eval/rejected': '-153.26', 'logps_eval/chosen': '-178.2', 'loss/eval': '0.62969'}
creating checkpoint to write to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-47872...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-47872/policy.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-47872/optimizer.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-47872/scheduler.pt...
train stats after 47936 examples: {'rewards_train/chosen': '-0.13307', 'rewards_train/rejected': '-0.32608', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.19302', 'logps_train/rejected': '-163.52', 'logps_train/chosen': '-190.26', 'loss/train': '0.66777', 'examples_per_second': '212.18', 'grad_norm': '46.246', 'counters/examples': 47936, 'counters/updates': 749}
skipping logging after 48000 examples to avoid logging too frequently
skipping logging after 48064 examples to avoid logging too frequently
skipping logging after 48128 examples to avoid logging too frequently
train stats after 48192 examples: {'rewards_train/chosen': '-0.13083', 'rewards_train/rejected': '-0.47133', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.3405', 'logps_train/rejected': '-131.4', 'logps_train/chosen': '-158.92', 'loss/train': '0.60819', 'examples_per_second': '274.28', 'grad_norm': '46.101', 'counters/examples': 48192, 'counters/updates': 753}
skipping logging after 48256 examples to avoid logging too frequently
skipping logging after 48320 examples to avoid logging too frequently
skipping logging after 48384 examples to avoid logging too frequently
train stats after 48448 examples: {'rewards_train/chosen': '-0.061438', 'rewards_train/rejected': '-0.31892', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.25748', 'logps_train/rejected': '-156.06', 'logps_train/chosen': '-179.04', 'loss/train': '0.63494', 'examples_per_second': '273.78', 'grad_norm': '68.159', 'counters/examples': 48448, 'counters/updates': 757}
skipping logging after 48512 examples to avoid logging too frequently
skipping logging after 48576 examples to avoid logging too frequently
skipping logging after 48640 examples to avoid logging too frequently
train stats after 48704 examples: {'rewards_train/chosen': '-0.10904', 'rewards_train/rejected': '-0.49985', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.39081', 'logps_train/rejected': '-145.01', 'logps_train/chosen': '-170.41', 'loss/train': '0.5921', 'examples_per_second': '274.07', 'grad_norm': '42.362', 'counters/examples': 48704, 'counters/updates': 761}
skipping logging after 48768 examples to avoid logging too frequently
skipping logging after 48832 examples to avoid logging too frequently
skipping logging after 48896 examples to avoid logging too frequently
train stats after 48960 examples: {'rewards_train/chosen': '-0.034291', 'rewards_train/rejected': '-0.44743', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.41314', 'logps_train/rejected': '-142.27', 'logps_train/chosen': '-205.06', 'loss/train': '0.56776', 'examples_per_second': '273.85', 'grad_norm': '44.424', 'counters/examples': 48960, 'counters/updates': 765}
skipping logging after 49024 examples to avoid logging too frequently
skipping logging after 49088 examples to avoid logging too frequently
skipping logging after 49152 examples to avoid logging too frequently
train stats after 49216 examples: {'rewards_train/chosen': '-0.068616', 'rewards_train/rejected': '-0.39455', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.32594', 'logps_train/rejected': '-184.06', 'logps_train/chosen': '-224.23', 'loss/train': '0.61909', 'examples_per_second': '272.68', 'grad_norm': '45.945', 'counters/examples': 49216, 'counters/updates': 769}
skipping logging after 49280 examples to avoid logging too frequently
skipping logging after 49344 examples to avoid logging too frequently
skipping logging after 49408 examples to avoid logging too frequently
train stats after 49472 examples: {'rewards_train/chosen': '-0.19373', 'rewards_train/rejected': '-0.47596', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.28222', 'logps_train/rejected': '-150.25', 'logps_train/chosen': '-193.6', 'loss/train': '0.63488', 'examples_per_second': '291.2', 'grad_norm': '49.056', 'counters/examples': 49472, 'counters/updates': 773}
skipping logging after 49536 examples to avoid logging too frequently
skipping logging after 49600 examples to avoid logging too frequently
skipping logging after 49664 examples to avoid logging too frequently
train stats after 49728 examples: {'rewards_train/chosen': '-0.17024', 'rewards_train/rejected': '-0.39439', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.22415', 'logps_train/rejected': '-166.95', 'logps_train/chosen': '-170.25', 'loss/train': '0.66891', 'examples_per_second': '265.75', 'grad_norm': '55.315', 'counters/examples': 49728, 'counters/updates': 777}
skipping logging after 49792 examples to avoid logging too frequently
skipping logging after 49856 examples to avoid logging too frequently
skipping logging after 49920 examples to avoid logging too frequently
train stats after 49984 examples: {'rewards_train/chosen': '-0.17995', 'rewards_train/rejected': '-0.64238', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.46243', 'logps_train/rejected': '-150.37', 'logps_train/chosen': '-168.78', 'loss/train': '0.56833', 'examples_per_second': '273.57', 'grad_norm': '46.105', 'counters/examples': 49984, 'counters/updates': 781}
skipping logging after 50048 examples to avoid logging too frequently
skipping logging after 50112 examples to avoid logging too frequently
skipping logging after 50176 examples to avoid logging too frequently
train stats after 50240 examples: {'rewards_train/chosen': '-0.28812', 'rewards_train/rejected': '-0.47824', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19012', 'logps_train/rejected': '-154.82', 'logps_train/chosen': '-166.62', 'loss/train': '0.65907', 'examples_per_second': '284.15', 'grad_norm': '45.774', 'counters/examples': 50240, 'counters/updates': 785}
skipping logging after 50304 examples to avoid logging too frequently
skipping logging after 50368 examples to avoid logging too frequently
skipping logging after 50432 examples to avoid logging too frequently
train stats after 50496 examples: {'rewards_train/chosen': '-0.17163', 'rewards_train/rejected': '-0.42555', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.25393', 'logps_train/rejected': '-195.45', 'logps_train/chosen': '-191.45', 'loss/train': '0.63732', 'examples_per_second': '274.81', 'grad_norm': '44.386', 'counters/examples': 50496, 'counters/updates': 789}
skipping logging after 50560 examples to avoid logging too frequently
skipping logging after 50624 examples to avoid logging too frequently
skipping logging after 50688 examples to avoid logging too frequently
train stats after 50752 examples: {'rewards_train/chosen': '-0.044162', 'rewards_train/rejected': '-0.40492', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.36076', 'logps_train/rejected': '-183.55', 'logps_train/chosen': '-173.17', 'loss/train': '0.61729', 'examples_per_second': '273.22', 'grad_norm': '46.53', 'counters/examples': 50752, 'counters/updates': 793}
skipping logging after 50816 examples to avoid logging too frequently
skipping logging after 50880 examples to avoid logging too frequently
skipping logging after 50944 examples to avoid logging too frequently
train stats after 51008 examples: {'rewards_train/chosen': '-0.36552', 'rewards_train/rejected': '-0.51249', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14697', 'logps_train/rejected': '-167.11', 'logps_train/chosen': '-193.61', 'loss/train': '0.70725', 'examples_per_second': '280.29', 'grad_norm': '50.109', 'counters/examples': 51008, 'counters/updates': 797}
skipping logging after 51072 examples to avoid logging too frequently
skipping logging after 51136 examples to avoid logging too frequently
skipping logging after 51200 examples to avoid logging too frequently
train stats after 51264 examples: {'rewards_train/chosen': '-0.12331', 'rewards_train/rejected': '-0.67617', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.55286', 'logps_train/rejected': '-147.74', 'logps_train/chosen': '-205.11', 'loss/train': '0.53916', 'examples_per_second': '274.37', 'grad_norm': '42.289', 'counters/examples': 51264, 'counters/updates': 801}
skipping logging after 51328 examples to avoid logging too frequently
skipping logging after 51392 examples to avoid logging too frequently
skipping logging after 51456 examples to avoid logging too frequently
train stats after 51520 examples: {'rewards_train/chosen': '-0.14993', 'rewards_train/rejected': '-0.46137', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.31143', 'logps_train/rejected': '-149.22', 'logps_train/chosen': '-185.82', 'loss/train': '0.62797', 'examples_per_second': '274.86', 'grad_norm': '43.153', 'counters/examples': 51520, 'counters/updates': 805}
skipping logging after 51584 examples to avoid logging too frequently
skipping logging after 51648 examples to avoid logging too frequently
skipping logging after 51712 examples to avoid logging too frequently
train stats after 51776 examples: {'rewards_train/chosen': '-0.084148', 'rewards_train/rejected': '-0.46805', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.3839', 'logps_train/rejected': '-167.16', 'logps_train/chosen': '-158.39', 'loss/train': '0.61117', 'examples_per_second': '274.52', 'grad_norm': '43.642', 'counters/examples': 51776, 'counters/updates': 809}
skipping logging after 51840 examples to avoid logging too frequently
skipping logging after 51904 examples to avoid logging too frequently
skipping logging after 51968 examples to avoid logging too frequently
train stats after 52032 examples: {'rewards_train/chosen': '-0.13461', 'rewards_train/rejected': '-0.4758', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.34119', 'logps_train/rejected': '-160.11', 'logps_train/chosen': '-196.44', 'loss/train': '0.64175', 'examples_per_second': '297.27', 'grad_norm': '49.725', 'counters/examples': 52032, 'counters/updates': 813}
skipping logging after 52096 examples to avoid logging too frequently
skipping logging after 52160 examples to avoid logging too frequently
skipping logging after 52224 examples to avoid logging too frequently
train stats after 52288 examples: {'rewards_train/chosen': '-0.13877', 'rewards_train/rejected': '-0.58594', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.44717', 'logps_train/rejected': '-181.15', 'logps_train/chosen': '-217.05', 'loss/train': '0.58493', 'examples_per_second': '274.61', 'grad_norm': '48.202', 'counters/examples': 52288, 'counters/updates': 817}
skipping logging after 52352 examples to avoid logging too frequently
skipping logging after 52416 examples to avoid logging too frequently
skipping logging after 52480 examples to avoid logging too frequently
train stats after 52544 examples: {'rewards_train/chosen': '-0.1204', 'rewards_train/rejected': '-0.55693', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.43654', 'logps_train/rejected': '-154.44', 'logps_train/chosen': '-156.84', 'loss/train': '0.56701', 'examples_per_second': '266.7', 'grad_norm': '50.784', 'counters/examples': 52544, 'counters/updates': 821}
skipping logging after 52608 examples to avoid logging too frequently
skipping logging after 52672 examples to avoid logging too frequently
skipping logging after 52736 examples to avoid logging too frequently
train stats after 52800 examples: {'rewards_train/chosen': '0.071886', 'rewards_train/rejected': '-0.30513', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.37702', 'logps_train/rejected': '-173.01', 'logps_train/chosen': '-198.28', 'loss/train': '0.58084', 'examples_per_second': '273.11', 'grad_norm': '43.886', 'counters/examples': 52800, 'counters/updates': 825}
skipping logging after 52864 examples to avoid logging too frequently
skipping logging after 52928 examples to avoid logging too frequently
skipping logging after 52992 examples to avoid logging too frequently
train stats after 53056 examples: {'rewards_train/chosen': '-0.067318', 'rewards_train/rejected': '-0.50375', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.43643', 'logps_train/rejected': '-153.36', 'logps_train/chosen': '-166.74', 'loss/train': '0.58136', 'examples_per_second': '261.27', 'grad_norm': '42.66', 'counters/examples': 53056, 'counters/updates': 829}
skipping logging after 53120 examples to avoid logging too frequently
skipping logging after 53184 examples to avoid logging too frequently
skipping logging after 53248 examples to avoid logging too frequently
train stats after 53312 examples: {'rewards_train/chosen': '-0.30479', 'rewards_train/rejected': '-0.63999', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.33521', 'logps_train/rejected': '-170.38', 'logps_train/chosen': '-181.41', 'loss/train': '0.63745', 'examples_per_second': '274.98', 'grad_norm': '50.488', 'counters/examples': 53312, 'counters/updates': 833}
skipping logging after 53376 examples to avoid logging too frequently
skipping logging after 53440 examples to avoid logging too frequently
skipping logging after 53504 examples to avoid logging too frequently
train stats after 53568 examples: {'rewards_train/chosen': '-0.22601', 'rewards_train/rejected': '-0.58686', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.36085', 'logps_train/rejected': '-165.78', 'logps_train/chosen': '-175.5', 'loss/train': '0.6002', 'examples_per_second': '302.82', 'grad_norm': '46.753', 'counters/examples': 53568, 'counters/updates': 837}
skipping logging after 53632 examples to avoid logging too frequently
skipping logging after 53696 examples to avoid logging too frequently
skipping logging after 53760 examples to avoid logging too frequently
train stats after 53824 examples: {'rewards_train/chosen': '-0.24383', 'rewards_train/rejected': '-0.66986', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.42603', 'logps_train/rejected': '-210.66', 'logps_train/chosen': '-235.67', 'loss/train': '0.59936', 'examples_per_second': '274.26', 'grad_norm': '50.962', 'counters/examples': 53824, 'counters/updates': 841}
skipping logging after 53888 examples to avoid logging too frequently
skipping logging after 53952 examples to avoid logging too frequently
skipping logging after 54016 examples to avoid logging too frequently
train stats after 54080 examples: {'rewards_train/chosen': '-0.201', 'rewards_train/rejected': '-0.30981', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.10881', 'logps_train/rejected': '-183.29', 'logps_train/chosen': '-186.56', 'loss/train': '0.71413', 'examples_per_second': '273.85', 'grad_norm': '51.431', 'counters/examples': 54080, 'counters/updates': 845}
skipping logging after 54144 examples to avoid logging too frequently
skipping logging after 54208 examples to avoid logging too frequently
skipping logging after 54272 examples to avoid logging too frequently
train stats after 54336 examples: {'rewards_train/chosen': '-0.18159', 'rewards_train/rejected': '-0.3507', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16911', 'logps_train/rejected': '-164.92', 'logps_train/chosen': '-187.44', 'loss/train': '0.72508', 'examples_per_second': '273.28', 'grad_norm': '57.605', 'counters/examples': 54336, 'counters/updates': 849}
skipping logging after 54400 examples to avoid logging too frequently
skipping logging after 54464 examples to avoid logging too frequently
skipping logging after 54528 examples to avoid logging too frequently
train stats after 54592 examples: {'rewards_train/chosen': '-0.070619', 'rewards_train/rejected': '-0.46918', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.39856', 'logps_train/rejected': '-143.57', 'logps_train/chosen': '-229.09', 'loss/train': '0.60972', 'examples_per_second': '272.74', 'grad_norm': '48.018', 'counters/examples': 54592, 'counters/updates': 853}
skipping logging after 54656 examples to avoid logging too frequently
skipping logging after 54720 examples to avoid logging too frequently
skipping logging after 54784 examples to avoid logging too frequently
train stats after 54848 examples: {'rewards_train/chosen': '-0.10597', 'rewards_train/rejected': '-0.38475', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.27879', 'logps_train/rejected': '-191.43', 'logps_train/chosen': '-182.06', 'loss/train': '0.65149', 'examples_per_second': '268.05', 'grad_norm': '51.399', 'counters/examples': 54848, 'counters/updates': 857}
skipping logging after 54912 examples to avoid logging too frequently
skipping logging after 54976 examples to avoid logging too frequently
skipping logging after 55040 examples to avoid logging too frequently
train stats after 55104 examples: {'rewards_train/chosen': '-0.13466', 'rewards_train/rejected': '-0.5723', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.43764', 'logps_train/rejected': '-126.55', 'logps_train/chosen': '-136.22', 'loss/train': '0.56988', 'examples_per_second': '273.89', 'grad_norm': '37.987', 'counters/examples': 55104, 'counters/updates': 861}
skipping logging after 55168 examples to avoid logging too frequently
skipping logging after 55232 examples to avoid logging too frequently
skipping logging after 55296 examples to avoid logging too frequently
train stats after 55360 examples: {'rewards_train/chosen': '-0.10578', 'rewards_train/rejected': '-0.47609', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.37031', 'logps_train/rejected': '-168.58', 'logps_train/chosen': '-166.03', 'loss/train': '0.60079', 'examples_per_second': '257.94', 'grad_norm': '44.317', 'counters/examples': 55360, 'counters/updates': 865}
skipping logging after 55424 examples to avoid logging too frequently
skipping logging after 55488 examples to avoid logging too frequently
skipping logging after 55552 examples to avoid logging too frequently
train stats after 55616 examples: {'rewards_train/chosen': '-0.11747', 'rewards_train/rejected': '-0.49991', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.38244', 'logps_train/rejected': '-170.06', 'logps_train/chosen': '-187.04', 'loss/train': '0.59047', 'examples_per_second': '263.66', 'grad_norm': '48.491', 'counters/examples': 55616, 'counters/updates': 869}
skipping logging after 55680 examples to avoid logging too frequently
skipping logging after 55744 examples to avoid logging too frequently
skipping logging after 55808 examples to avoid logging too frequently
train stats after 55872 examples: {'rewards_train/chosen': '-0.14304', 'rewards_train/rejected': '-0.39176', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.24872', 'logps_train/rejected': '-168.48', 'logps_train/chosen': '-186.05', 'loss/train': '0.64691', 'examples_per_second': '263.52', 'grad_norm': '45.446', 'counters/examples': 55872, 'counters/updates': 873}
skipping logging after 55936 examples to avoid logging too frequently
skipping logging after 56000 examples to avoid logging too frequently
skipping logging after 56064 examples to avoid logging too frequently
train stats after 56128 examples: {'rewards_train/chosen': '-0.21557', 'rewards_train/rejected': '-0.29574', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.080171', 'logps_train/rejected': '-159.57', 'logps_train/chosen': '-195.64', 'loss/train': '0.73586', 'examples_per_second': '268.62', 'grad_norm': '49.354', 'counters/examples': 56128, 'counters/updates': 877}
skipping logging after 56192 examples to avoid logging too frequently
skipping logging after 56256 examples to avoid logging too frequently
skipping logging after 56320 examples to avoid logging too frequently
train stats after 56384 examples: {'rewards_train/chosen': '-0.16433', 'rewards_train/rejected': '-0.35915', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.19482', 'logps_train/rejected': '-159.52', 'logps_train/chosen': '-199.47', 'loss/train': '0.66499', 'examples_per_second': '273.43', 'grad_norm': '47.134', 'counters/examples': 56384, 'counters/updates': 881}
skipping logging after 56448 examples to avoid logging too frequently
skipping logging after 56512 examples to avoid logging too frequently
skipping logging after 56576 examples to avoid logging too frequently
train stats after 56640 examples: {'rewards_train/chosen': '-0.20405', 'rewards_train/rejected': '-0.42972', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.22567', 'logps_train/rejected': '-132.15', 'logps_train/chosen': '-155.5', 'loss/train': '0.66054', 'examples_per_second': '293.32', 'grad_norm': '41.498', 'counters/examples': 56640, 'counters/updates': 885}
skipping logging after 56704 examples to avoid logging too frequently
skipping logging after 56768 examples to avoid logging too frequently
skipping logging after 56832 examples to avoid logging too frequently
train stats after 56896 examples: {'rewards_train/chosen': '-0.013899', 'rewards_train/rejected': '-0.44331', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.42941', 'logps_train/rejected': '-147.88', 'logps_train/chosen': '-168.38', 'loss/train': '0.57392', 'examples_per_second': '312.61', 'grad_norm': '38.374', 'counters/examples': 56896, 'counters/updates': 889}
skipping logging after 56960 examples to avoid logging too frequently
skipping logging after 57024 examples to avoid logging too frequently
skipping logging after 57088 examples to avoid logging too frequently
train stats after 57152 examples: {'rewards_train/chosen': '-0.16029', 'rewards_train/rejected': '-0.6334', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.47312', 'logps_train/rejected': '-180.68', 'logps_train/chosen': '-161.84', 'loss/train': '0.58892', 'examples_per_second': '273.36', 'grad_norm': '43.128', 'counters/examples': 57152, 'counters/updates': 893}
skipping logging after 57216 examples to avoid logging too frequently
skipping logging after 57280 examples to avoid logging too frequently
skipping logging after 57344 examples to avoid logging too frequently
train stats after 57408 examples: {'rewards_train/chosen': '-0.047976', 'rewards_train/rejected': '-0.51976', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.47178', 'logps_train/rejected': '-189.21', 'logps_train/chosen': '-204.08', 'loss/train': '0.59821', 'examples_per_second': '274.69', 'grad_norm': '46.18', 'counters/examples': 57408, 'counters/updates': 897}
skipping logging after 57472 examples to avoid logging too frequently
skipping logging after 57536 examples to avoid logging too frequently
skipping logging after 57600 examples to avoid logging too frequently
train stats after 57664 examples: {'rewards_train/chosen': '-0.0010752', 'rewards_train/rejected': '-0.25098', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.24991', 'logps_train/rejected': '-167.74', 'logps_train/chosen': '-172.35', 'loss/train': '0.65743', 'examples_per_second': '268.47', 'grad_norm': '45.562', 'counters/examples': 57664, 'counters/updates': 901}
skipping logging after 57728 examples to avoid logging too frequently
skipping logging after 57792 examples to avoid logging too frequently
skipping logging after 57856 examples to avoid logging too frequently
train stats after 57920 examples: {'rewards_train/chosen': '-0.077361', 'rewards_train/rejected': '-0.43877', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.36141', 'logps_train/rejected': '-137.54', 'logps_train/chosen': '-165.98', 'loss/train': '0.59277', 'examples_per_second': '274.44', 'grad_norm': '41.601', 'counters/examples': 57920, 'counters/updates': 905}
skipping logging after 57984 examples to avoid logging too frequently
skipping logging after 58048 examples to avoid logging too frequently
skipping logging after 58112 examples to avoid logging too frequently
train stats after 58176 examples: {'rewards_train/chosen': '-0.07941', 'rewards_train/rejected': '-0.48683', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.40742', 'logps_train/rejected': '-134.21', 'logps_train/chosen': '-188.16', 'loss/train': '0.57334', 'examples_per_second': '262.88', 'grad_norm': '40.402', 'counters/examples': 58176, 'counters/updates': 909}
skipping logging after 58240 examples to avoid logging too frequently
skipping logging after 58304 examples to avoid logging too frequently
skipping logging after 58368 examples to avoid logging too frequently
train stats after 58432 examples: {'rewards_train/chosen': '-0.29013', 'rewards_train/rejected': '-0.65707', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.36694', 'logps_train/rejected': '-154.21', 'logps_train/chosen': '-158.08', 'loss/train': '0.60689', 'examples_per_second': '292.66', 'grad_norm': '41.861', 'counters/examples': 58432, 'counters/updates': 913}
skipping logging after 58496 examples to avoid logging too frequently
skipping logging after 58560 examples to avoid logging too frequently
skipping logging after 58624 examples to avoid logging too frequently
train stats after 58688 examples: {'rewards_train/chosen': '-0.32733', 'rewards_train/rejected': '-0.50242', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.17509', 'logps_train/rejected': '-175.94', 'logps_train/chosen': '-164.95', 'loss/train': '0.67964', 'examples_per_second': '263.23', 'grad_norm': '51.152', 'counters/examples': 58688, 'counters/updates': 917}
skipping logging after 58752 examples to avoid logging too frequently
skipping logging after 58816 examples to avoid logging too frequently
skipping logging after 58880 examples to avoid logging too frequently
train stats after 58944 examples: {'rewards_train/chosen': '-0.099955', 'rewards_train/rejected': '-0.71494', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '0.61499', 'logps_train/rejected': '-144.75', 'logps_train/chosen': '-176.3', 'loss/train': '0.52443', 'examples_per_second': '280.59', 'grad_norm': '38.599', 'counters/examples': 58944, 'counters/updates': 921}
skipping logging after 59008 examples to avoid logging too frequently
skipping logging after 59072 examples to avoid logging too frequently
skipping logging after 59136 examples to avoid logging too frequently
train stats after 59200 examples: {'rewards_train/chosen': '-0.17557', 'rewards_train/rejected': '-0.51108', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.3355', 'logps_train/rejected': '-173.18', 'logps_train/chosen': '-176.12', 'loss/train': '0.59531', 'examples_per_second': '273.53', 'grad_norm': '46.627', 'counters/examples': 59200, 'counters/updates': 925}
skipping logging after 59264 examples to avoid logging too frequently
skipping logging after 59328 examples to avoid logging too frequently
skipping logging after 59392 examples to avoid logging too frequently
train stats after 59456 examples: {'rewards_train/chosen': '-0.13487', 'rewards_train/rejected': '-0.33265', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19778', 'logps_train/rejected': '-177.7', 'logps_train/chosen': '-193.11', 'loss/train': '0.66786', 'examples_per_second': '271.57', 'grad_norm': '51.697', 'counters/examples': 59456, 'counters/updates': 929}
skipping logging after 59520 examples to avoid logging too frequently
skipping logging after 59584 examples to avoid logging too frequently
skipping logging after 59648 examples to avoid logging too frequently
train stats after 59712 examples: {'rewards_train/chosen': '-0.16295', 'rewards_train/rejected': '-0.55224', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.38928', 'logps_train/rejected': '-152.86', 'logps_train/chosen': '-192', 'loss/train': '0.57473', 'examples_per_second': '277.11', 'grad_norm': '42.248', 'counters/examples': 59712, 'counters/updates': 933}
skipping logging after 59776 examples to avoid logging too frequently
skipping logging after 59840 examples to avoid logging too frequently
Running evaluation after 59840 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:00, 16.99it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 17.30it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:00, 17.47it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 17.37it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:00<00:00, 17.39it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 17.40it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:00<00:00, 17.34it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.37it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.35it/s]
eval after 59840: {'rewards_eval/chosen': '-0.053628', 'rewards_eval/rejected': '-0.39347', 'rewards_eval/accuracies': '0.66406', 'rewards_eval/margins': '0.33984', 'logps_eval/rejected': '-153.8', 'logps_eval/chosen': '-178.4', 'loss/eval': '0.61615'}
creating checkpoint to write to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-59840...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-59840/policy.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-59840/optimizer.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-59840/scheduler.pt...
train stats after 59904 examples: {'rewards_train/chosen': '-0.25261', 'rewards_train/rejected': '-0.60223', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.34962', 'logps_train/rejected': '-150.99', 'logps_train/chosen': '-165.69', 'loss/train': '0.62689', 'examples_per_second': '210.75', 'grad_norm': '41.78', 'counters/examples': 59904, 'counters/updates': 936}
skipping logging after 59968 examples to avoid logging too frequently
skipping logging after 60032 examples to avoid logging too frequently
skipping logging after 60096 examples to avoid logging too frequently
train stats after 60160 examples: {'rewards_train/chosen': '0.018512', 'rewards_train/rejected': '-0.40336', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.42187', 'logps_train/rejected': '-156.29', 'logps_train/chosen': '-199.12', 'loss/train': '0.56451', 'examples_per_second': '273.13', 'grad_norm': '43.895', 'counters/examples': 60160, 'counters/updates': 940}
skipping logging after 60224 examples to avoid logging too frequently
skipping logging after 60288 examples to avoid logging too frequently
skipping logging after 60352 examples to avoid logging too frequently
train stats after 60416 examples: {'rewards_train/chosen': '-0.25396', 'rewards_train/rejected': '-0.57711', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.32316', 'logps_train/rejected': '-156.11', 'logps_train/chosen': '-189.23', 'loss/train': '0.66802', 'examples_per_second': '272.2', 'grad_norm': '51.08', 'counters/examples': 60416, 'counters/updates': 944}
skipping logging after 60480 examples to avoid logging too frequently
skipping logging after 60544 examples to avoid logging too frequently
skipping logging after 60608 examples to avoid logging too frequently
train stats after 60672 examples: {'rewards_train/chosen': '-0.16074', 'rewards_train/rejected': '-0.39361', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.23287', 'logps_train/rejected': '-131.23', 'logps_train/chosen': '-178.33', 'loss/train': '0.64978', 'examples_per_second': '265.01', 'grad_norm': '43.568', 'counters/examples': 60672, 'counters/updates': 948}
skipping logging after 60736 examples to avoid logging too frequently
skipping logging after 60800 examples to avoid logging too frequently
skipping logging after 60864 examples to avoid logging too frequently
train stats after 60928 examples: {'rewards_train/chosen': '-0.31822', 'rewards_train/rejected': '-0.38998', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.071766', 'logps_train/rejected': '-160.14', 'logps_train/chosen': '-188.39', 'loss/train': '0.73329', 'examples_per_second': '273.3', 'grad_norm': '51.309', 'counters/examples': 60928, 'counters/updates': 952}
skipping logging after 60992 examples to avoid logging too frequently
skipping logging after 61056 examples to avoid logging too frequently
skipping logging after 61120 examples to avoid logging too frequently
train stats after 61184 examples: {'rewards_train/chosen': '-0.097107', 'rewards_train/rejected': '-0.45582', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.35872', 'logps_train/rejected': '-182.01', 'logps_train/chosen': '-194.98', 'loss/train': '0.62291', 'examples_per_second': '261.21', 'grad_norm': '43.827', 'counters/examples': 61184, 'counters/updates': 956}
skipping logging after 61248 examples to avoid logging too frequently
skipping logging after 61312 examples to avoid logging too frequently
skipping logging after 61376 examples to avoid logging too frequently
train stats after 61440 examples: {'rewards_train/chosen': '-0.17544', 'rewards_train/rejected': '-0.44629', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.27085', 'logps_train/rejected': '-163.78', 'logps_train/chosen': '-162.69', 'loss/train': '0.64013', 'examples_per_second': '272.08', 'grad_norm': '44.339', 'counters/examples': 61440, 'counters/updates': 960}
skipping logging after 61504 examples to avoid logging too frequently
skipping logging after 61568 examples to avoid logging too frequently
skipping logging after 61632 examples to avoid logging too frequently
train stats after 61696 examples: {'rewards_train/chosen': '-0.0016824', 'rewards_train/rejected': '-0.31249', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.3108', 'logps_train/rejected': '-144.3', 'logps_train/chosen': '-137.9', 'loss/train': '0.62686', 'examples_per_second': '273.74', 'grad_norm': '48.137', 'counters/examples': 61696, 'counters/updates': 964}
skipping logging after 61760 examples to avoid logging too frequently
skipping logging after 61824 examples to avoid logging too frequently
skipping logging after 61888 examples to avoid logging too frequently
train stats after 61952 examples: {'rewards_train/chosen': '-0.016533', 'rewards_train/rejected': '-0.40185', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.38531', 'logps_train/rejected': '-154.7', 'logps_train/chosen': '-193.84', 'loss/train': '0.5709', 'examples_per_second': '271.24', 'grad_norm': '43.493', 'counters/examples': 61952, 'counters/updates': 968}
skipping logging after 62016 examples to avoid logging too frequently
skipping logging after 62080 examples to avoid logging too frequently
skipping logging after 62144 examples to avoid logging too frequently
train stats after 62208 examples: {'rewards_train/chosen': '-0.14246', 'rewards_train/rejected': '-0.25705', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11459', 'logps_train/rejected': '-175.01', 'logps_train/chosen': '-179.37', 'loss/train': '0.71261', 'examples_per_second': '263.44', 'grad_norm': '53.911', 'counters/examples': 62208, 'counters/updates': 972}
skipping logging after 62272 examples to avoid logging too frequently
skipping logging after 62336 examples to avoid logging too frequently
skipping logging after 62400 examples to avoid logging too frequently
train stats after 62464 examples: {'rewards_train/chosen': '-0.019933', 'rewards_train/rejected': '-0.29796', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.27803', 'logps_train/rejected': '-176.51', 'logps_train/chosen': '-202.85', 'loss/train': '0.6187', 'examples_per_second': '273.52', 'grad_norm': '46.237', 'counters/examples': 62464, 'counters/updates': 976}
skipping logging after 62528 examples to avoid logging too frequently
skipping logging after 62592 examples to avoid logging too frequently
skipping logging after 62656 examples to avoid logging too frequently
train stats after 62720 examples: {'rewards_train/chosen': '-0.070684', 'rewards_train/rejected': '-0.47286', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.40217', 'logps_train/rejected': '-154.91', 'logps_train/chosen': '-162.94', 'loss/train': '0.59172', 'examples_per_second': '270.3', 'grad_norm': '46.126', 'counters/examples': 62720, 'counters/updates': 980}
skipping logging after 62784 examples to avoid logging too frequently
skipping logging after 62848 examples to avoid logging too frequently
skipping logging after 62912 examples to avoid logging too frequently
train stats after 62976 examples: {'rewards_train/chosen': '-0.13518', 'rewards_train/rejected': '-0.55142', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.41624', 'logps_train/rejected': '-169.28', 'logps_train/chosen': '-194.42', 'loss/train': '0.59338', 'examples_per_second': '272.69', 'grad_norm': '42.732', 'counters/examples': 62976, 'counters/updates': 984}
skipping logging after 63040 examples to avoid logging too frequently
skipping logging after 63104 examples to avoid logging too frequently
skipping logging after 63168 examples to avoid logging too frequently
train stats after 63232 examples: {'rewards_train/chosen': '-0.044157', 'rewards_train/rejected': '-0.37861', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.33445', 'logps_train/rejected': '-157.74', 'logps_train/chosen': '-169.1', 'loss/train': '0.61281', 'examples_per_second': '272.36', 'grad_norm': '38.778', 'counters/examples': 63232, 'counters/updates': 988}
skipping logging after 63296 examples to avoid logging too frequently
skipping logging after 63360 examples to avoid logging too frequently
skipping logging after 63424 examples to avoid logging too frequently
train stats after 63488 examples: {'rewards_train/chosen': '-0.12494', 'rewards_train/rejected': '-0.31425', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18931', 'logps_train/rejected': '-151.48', 'logps_train/chosen': '-169.75', 'loss/train': '0.66025', 'examples_per_second': '272.8', 'grad_norm': '43.064', 'counters/examples': 63488, 'counters/updates': 992}
skipping logging after 63552 examples to avoid logging too frequently
skipping logging after 63616 examples to avoid logging too frequently
skipping logging after 63680 examples to avoid logging too frequently
train stats after 63744 examples: {'rewards_train/chosen': '-0.07214', 'rewards_train/rejected': '-0.51348', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '0.44134', 'logps_train/rejected': '-157.78', 'logps_train/chosen': '-218.53', 'loss/train': '0.55554', 'examples_per_second': '291.35', 'grad_norm': '42.936', 'counters/examples': 63744, 'counters/updates': 996}
skipping logging after 63808 examples to avoid logging too frequently
skipping logging after 63872 examples to avoid logging too frequently
skipping logging after 63936 examples to avoid logging too frequently
train stats after 64000 examples: {'rewards_train/chosen': '-0.071782', 'rewards_train/rejected': '-0.41023', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.33845', 'logps_train/rejected': '-153.57', 'logps_train/chosen': '-203.96', 'loss/train': '0.62827', 'examples_per_second': '273.33', 'grad_norm': '47.115', 'counters/examples': 64000, 'counters/updates': 1000}
skipping logging after 64064 examples to avoid logging too frequently
skipping logging after 64128 examples to avoid logging too frequently
skipping logging after 64192 examples to avoid logging too frequently
train stats after 64256 examples: {'rewards_train/chosen': '-0.047963', 'rewards_train/rejected': '-0.38795', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.33999', 'logps_train/rejected': '-153.22', 'logps_train/chosen': '-163.31', 'loss/train': '0.59128', 'examples_per_second': '279.14', 'grad_norm': '43.252', 'counters/examples': 64256, 'counters/updates': 1004}
skipping logging after 64320 examples to avoid logging too frequently
skipping logging after 64384 examples to avoid logging too frequently
skipping logging after 64448 examples to avoid logging too frequently
train stats after 64512 examples: {'rewards_train/chosen': '0.025917', 'rewards_train/rejected': '-0.34578', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.3717', 'logps_train/rejected': '-131.28', 'logps_train/chosen': '-144.74', 'loss/train': '0.58373', 'examples_per_second': '270.42', 'grad_norm': '41.53', 'counters/examples': 64512, 'counters/updates': 1008}
skipping logging after 64576 examples to avoid logging too frequently
skipping logging after 64640 examples to avoid logging too frequently
skipping logging after 64704 examples to avoid logging too frequently
train stats after 64768 examples: {'rewards_train/chosen': '-0.16312', 'rewards_train/rejected': '-0.65696', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.49385', 'logps_train/rejected': '-159.91', 'logps_train/chosen': '-164.24', 'loss/train': '0.54904', 'examples_per_second': '263.32', 'grad_norm': '41.354', 'counters/examples': 64768, 'counters/updates': 1012}
skipping logging after 64832 examples to avoid logging too frequently
skipping logging after 64896 examples to avoid logging too frequently
skipping logging after 64960 examples to avoid logging too frequently
train stats after 65024 examples: {'rewards_train/chosen': '-0.23496', 'rewards_train/rejected': '-0.54447', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.30951', 'logps_train/rejected': '-140.97', 'logps_train/chosen': '-157.98', 'loss/train': '0.65199', 'examples_per_second': '265.21', 'grad_norm': '45.331', 'counters/examples': 65024, 'counters/updates': 1016}
skipping logging after 65088 examples to avoid logging too frequently
skipping logging after 65152 examples to avoid logging too frequently
skipping logging after 65216 examples to avoid logging too frequently
train stats after 65280 examples: {'rewards_train/chosen': '-0.18959', 'rewards_train/rejected': '-0.77329', 'rewards_train/accuracies': '0.8125', 'rewards_train/margins': '0.58369', 'logps_train/rejected': '-147.94', 'logps_train/chosen': '-179.17', 'loss/train': '0.53475', 'examples_per_second': '272.72', 'grad_norm': '45.089', 'counters/examples': 65280, 'counters/updates': 1020}
skipping logging after 65344 examples to avoid logging too frequently
skipping logging after 65408 examples to avoid logging too frequently
skipping logging after 65472 examples to avoid logging too frequently
train stats after 65536 examples: {'rewards_train/chosen': '-0.1985', 'rewards_train/rejected': '-0.55053', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.35202', 'logps_train/rejected': '-165.15', 'logps_train/chosen': '-178.42', 'loss/train': '0.61183', 'examples_per_second': '280.81', 'grad_norm': '40.105', 'counters/examples': 65536, 'counters/updates': 1024}
skipping logging after 65600 examples to avoid logging too frequently
skipping logging after 65664 examples to avoid logging too frequently
skipping logging after 65728 examples to avoid logging too frequently
train stats after 65792 examples: {'rewards_train/chosen': '-0.23763', 'rewards_train/rejected': '-0.44137', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20374', 'logps_train/rejected': '-156.4', 'logps_train/chosen': '-150.27', 'loss/train': '0.68198', 'examples_per_second': '274.8', 'grad_norm': '46.144', 'counters/examples': 65792, 'counters/updates': 1028}
skipping logging after 65856 examples to avoid logging too frequently
skipping logging after 65920 examples to avoid logging too frequently
skipping logging after 65984 examples to avoid logging too frequently
train stats after 66048 examples: {'rewards_train/chosen': '-0.24132', 'rewards_train/rejected': '-0.6953', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.45398', 'logps_train/rejected': '-162.16', 'logps_train/chosen': '-197.78', 'loss/train': '0.57688', 'examples_per_second': '272.07', 'grad_norm': '44.669', 'counters/examples': 66048, 'counters/updates': 1032}
skipping logging after 66112 examples to avoid logging too frequently
skipping logging after 66176 examples to avoid logging too frequently
skipping logging after 66240 examples to avoid logging too frequently
train stats after 66304 examples: {'rewards_train/chosen': '-0.16177', 'rewards_train/rejected': '-0.49759', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.33583', 'logps_train/rejected': '-163.35', 'logps_train/chosen': '-186.51', 'loss/train': '0.63333', 'examples_per_second': '257.87', 'grad_norm': '46.728', 'counters/examples': 66304, 'counters/updates': 1036}
skipping logging after 66368 examples to avoid logging too frequently
skipping logging after 66432 examples to avoid logging too frequently
skipping logging after 66496 examples to avoid logging too frequently
train stats after 66560 examples: {'rewards_train/chosen': '-0.057632', 'rewards_train/rejected': '-0.57691', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.51927', 'logps_train/rejected': '-147.6', 'logps_train/chosen': '-190.39', 'loss/train': '0.55631', 'examples_per_second': '265.14', 'grad_norm': '39.601', 'counters/examples': 66560, 'counters/updates': 1040}
skipping logging after 66624 examples to avoid logging too frequently
skipping logging after 66688 examples to avoid logging too frequently
skipping logging after 66752 examples to avoid logging too frequently
train stats after 66816 examples: {'rewards_train/chosen': '-0.09876', 'rewards_train/rejected': '-0.53764', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.43888', 'logps_train/rejected': '-212.35', 'logps_train/chosen': '-186.14', 'loss/train': '0.58039', 'examples_per_second': '273.22', 'grad_norm': '44.966', 'counters/examples': 66816, 'counters/updates': 1044}
skipping logging after 66880 examples to avoid logging too frequently
skipping logging after 66944 examples to avoid logging too frequently
skipping logging after 67008 examples to avoid logging too frequently
train stats after 67072 examples: {'rewards_train/chosen': '-0.046916', 'rewards_train/rejected': '-0.31559', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.26868', 'logps_train/rejected': '-161.85', 'logps_train/chosen': '-160.97', 'loss/train': '0.64998', 'examples_per_second': '274.96', 'grad_norm': '43.733', 'counters/examples': 67072, 'counters/updates': 1048}
skipping logging after 67136 examples to avoid logging too frequently
skipping logging after 67200 examples to avoid logging too frequently
skipping logging after 67264 examples to avoid logging too frequently
train stats after 67328 examples: {'rewards_train/chosen': '-0.13754', 'rewards_train/rejected': '-0.31296', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.17542', 'logps_train/rejected': '-167.19', 'logps_train/chosen': '-143.4', 'loss/train': '0.70086', 'examples_per_second': '280.63', 'grad_norm': '42.857', 'counters/examples': 67328, 'counters/updates': 1052}
skipping logging after 67392 examples to avoid logging too frequently
skipping logging after 67456 examples to avoid logging too frequently
skipping logging after 67520 examples to avoid logging too frequently
train stats after 67584 examples: {'rewards_train/chosen': '-0.13036', 'rewards_train/rejected': '-0.40593', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.27557', 'logps_train/rejected': '-139.95', 'logps_train/chosen': '-174.99', 'loss/train': '0.64104', 'examples_per_second': '269.32', 'grad_norm': '42.052', 'counters/examples': 67584, 'counters/updates': 1056}
skipping logging after 67648 examples to avoid logging too frequently
skipping logging after 67712 examples to avoid logging too frequently
skipping logging after 67776 examples to avoid logging too frequently
train stats after 67840 examples: {'rewards_train/chosen': '-0.25125', 'rewards_train/rejected': '-0.30223', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.050986', 'logps_train/rejected': '-179.05', 'logps_train/chosen': '-171.5', 'loss/train': '0.75919', 'examples_per_second': '272.36', 'grad_norm': '49.704', 'counters/examples': 67840, 'counters/updates': 1060}
skipping logging after 67904 examples to avoid logging too frequently
skipping logging after 67968 examples to avoid logging too frequently
skipping logging after 68032 examples to avoid logging too frequently
train stats after 68096 examples: {'rewards_train/chosen': '0.029751', 'rewards_train/rejected': '-0.3987', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.42845', 'logps_train/rejected': '-171.89', 'logps_train/chosen': '-196.82', 'loss/train': '0.57384', 'examples_per_second': '262.41', 'grad_norm': '40.863', 'counters/examples': 68096, 'counters/updates': 1064}
skipping logging after 68160 examples to avoid logging too frequently
skipping logging after 68224 examples to avoid logging too frequently
skipping logging after 68288 examples to avoid logging too frequently
train stats after 68352 examples: {'rewards_train/chosen': '-0.113', 'rewards_train/rejected': '-0.37143', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.25843', 'logps_train/rejected': '-195.4', 'logps_train/chosen': '-193.96', 'loss/train': '0.66395', 'examples_per_second': '271.81', 'grad_norm': '49.697', 'counters/examples': 68352, 'counters/updates': 1068}
skipping logging after 68416 examples to avoid logging too frequently
skipping logging after 68480 examples to avoid logging too frequently
skipping logging after 68544 examples to avoid logging too frequently
train stats after 68608 examples: {'rewards_train/chosen': '-0.069083', 'rewards_train/rejected': '-0.31107', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.24199', 'logps_train/rejected': '-173.59', 'logps_train/chosen': '-190.24', 'loss/train': '0.65627', 'examples_per_second': '271.13', 'grad_norm': '48.123', 'counters/examples': 68608, 'counters/updates': 1072}
skipping logging after 68672 examples to avoid logging too frequently
skipping logging after 68736 examples to avoid logging too frequently
skipping logging after 68800 examples to avoid logging too frequently
train stats after 68864 examples: {'rewards_train/chosen': '0.0038902', 'rewards_train/rejected': '-0.33535', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.33924', 'logps_train/rejected': '-165.32', 'logps_train/chosen': '-178.58', 'loss/train': '0.61269', 'examples_per_second': '264.41', 'grad_norm': '40.444', 'counters/examples': 68864, 'counters/updates': 1076}
skipping logging after 68928 examples to avoid logging too frequently
skipping logging after 68992 examples to avoid logging too frequently
skipping logging after 69056 examples to avoid logging too frequently
train stats after 69120 examples: {'rewards_train/chosen': '-0.057802', 'rewards_train/rejected': '-0.3521', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.2943', 'logps_train/rejected': '-180.04', 'logps_train/chosen': '-170.25', 'loss/train': '0.62611', 'examples_per_second': '262.04', 'grad_norm': '50.059', 'counters/examples': 69120, 'counters/updates': 1080}
skipping logging after 69184 examples to avoid logging too frequently
skipping logging after 69248 examples to avoid logging too frequently
skipping logging after 69312 examples to avoid logging too frequently
train stats after 69376 examples: {'rewards_train/chosen': '-0.032617', 'rewards_train/rejected': '-0.454', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.42139', 'logps_train/rejected': '-155.52', 'logps_train/chosen': '-166.68', 'loss/train': '0.58907', 'examples_per_second': '256.37', 'grad_norm': '40.541', 'counters/examples': 69376, 'counters/updates': 1084}
skipping logging after 69440 examples to avoid logging too frequently
skipping logging after 69504 examples to avoid logging too frequently
skipping logging after 69568 examples to avoid logging too frequently
train stats after 69632 examples: {'rewards_train/chosen': '0.051172', 'rewards_train/rejected': '-0.3385', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.38967', 'logps_train/rejected': '-153.18', 'logps_train/chosen': '-178.14', 'loss/train': '0.58006', 'examples_per_second': '289.43', 'grad_norm': '43.857', 'counters/examples': 69632, 'counters/updates': 1088}
skipping logging after 69696 examples to avoid logging too frequently
skipping logging after 69760 examples to avoid logging too frequently
skipping logging after 69824 examples to avoid logging too frequently
train stats after 69888 examples: {'rewards_train/chosen': '-0.057039', 'rewards_train/rejected': '-0.33855', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.28151', 'logps_train/rejected': '-169.51', 'logps_train/chosen': '-176.5', 'loss/train': '0.64644', 'examples_per_second': '270.65', 'grad_norm': '49.095', 'counters/examples': 69888, 'counters/updates': 1092}
skipping logging after 69952 examples to avoid logging too frequently
skipping logging after 70016 examples to avoid logging too frequently
skipping logging after 70080 examples to avoid logging too frequently
train stats after 70144 examples: {'rewards_train/chosen': '-0.016979', 'rewards_train/rejected': '-0.4182', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.40122', 'logps_train/rejected': '-138.07', 'logps_train/chosen': '-182.57', 'loss/train': '0.5968', 'examples_per_second': '261.75', 'grad_norm': '41.744', 'counters/examples': 70144, 'counters/updates': 1096}
skipping logging after 70208 examples to avoid logging too frequently
skipping logging after 70272 examples to avoid logging too frequently
skipping logging after 70336 examples to avoid logging too frequently
train stats after 70400 examples: {'rewards_train/chosen': '0.067926', 'rewards_train/rejected': '-0.38004', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.44797', 'logps_train/rejected': '-144.2', 'logps_train/chosen': '-175.38', 'loss/train': '0.57251', 'examples_per_second': '265.31', 'grad_norm': '41.773', 'counters/examples': 70400, 'counters/updates': 1100}
skipping logging after 70464 examples to avoid logging too frequently
skipping logging after 70528 examples to avoid logging too frequently
skipping logging after 70592 examples to avoid logging too frequently
train stats after 70656 examples: {'rewards_train/chosen': '-0.167', 'rewards_train/rejected': '-0.4535', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.2865', 'logps_train/rejected': '-166.46', 'logps_train/chosen': '-202.31', 'loss/train': '0.64311', 'examples_per_second': '272.76', 'grad_norm': '53.079', 'counters/examples': 70656, 'counters/updates': 1104}
skipping logging after 70720 examples to avoid logging too frequently
skipping logging after 70784 examples to avoid logging too frequently
skipping logging after 70848 examples to avoid logging too frequently
train stats after 70912 examples: {'rewards_train/chosen': '-0.21792', 'rewards_train/rejected': '-0.50773', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.28981', 'logps_train/rejected': '-155.72', 'logps_train/chosen': '-200.43', 'loss/train': '0.6355', 'examples_per_second': '272.99', 'grad_norm': '47.719', 'counters/examples': 70912, 'counters/updates': 1108}
skipping logging after 70976 examples to avoid logging too frequently
skipping logging after 71040 examples to avoid logging too frequently
skipping logging after 71104 examples to avoid logging too frequently
train stats after 71168 examples: {'rewards_train/chosen': '-0.20513', 'rewards_train/rejected': '-0.53225', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.32712', 'logps_train/rejected': '-167.94', 'logps_train/chosen': '-187.11', 'loss/train': '0.62523', 'examples_per_second': '308.61', 'grad_norm': '38.936', 'counters/examples': 71168, 'counters/updates': 1112}
skipping logging after 71232 examples to avoid logging too frequently
skipping logging after 71296 examples to avoid logging too frequently
skipping logging after 71360 examples to avoid logging too frequently
train stats after 71424 examples: {'rewards_train/chosen': '-0.15054', 'rewards_train/rejected': '-0.34702', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.19648', 'logps_train/rejected': '-174.99', 'logps_train/chosen': '-152.58', 'loss/train': '0.70498', 'examples_per_second': '261.4', 'grad_norm': '49.548', 'counters/examples': 71424, 'counters/updates': 1116}
skipping logging after 71488 examples to avoid logging too frequently
skipping logging after 71552 examples to avoid logging too frequently
skipping logging after 71616 examples to avoid logging too frequently
train stats after 71680 examples: {'rewards_train/chosen': '-0.40325', 'rewards_train/rejected': '-0.75809', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.35484', 'logps_train/rejected': '-150.74', 'logps_train/chosen': '-184.83', 'loss/train': '0.64892', 'examples_per_second': '273.3', 'grad_norm': '45.675', 'counters/examples': 71680, 'counters/updates': 1120}
skipping logging after 71744 examples to avoid logging too frequently
skipping logging after 71808 examples to avoid logging too frequently
Running evaluation after 71808 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:00, 17.26it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 17.39it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:00, 17.54it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 17.45it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:00<00:00, 17.43it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 17.30it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:00<00:00, 17.24it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.26it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.32it/s]
eval after 71808: {'rewards_eval/chosen': '-0.14474', 'rewards_eval/rejected': '-0.50841', 'rewards_eval/accuracies': '0.65234', 'rewards_eval/margins': '0.36367', 'logps_eval/rejected': '-154.95', 'logps_eval/chosen': '-179.31', 'loss/eval': '0.61295'}
creating checkpoint to write to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-71808...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-71808/policy.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-71808/optimizer.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-71808/scheduler.pt...
train stats after 71872 examples: {'rewards_train/chosen': '-0.18875', 'rewards_train/rejected': '-0.56197', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.37322', 'logps_train/rejected': '-147.28', 'logps_train/chosen': '-226.64', 'loss/train': '0.61278', 'examples_per_second': '208.75', 'grad_norm': '46.064', 'counters/examples': 71872, 'counters/updates': 1123}
skipping logging after 71936 examples to avoid logging too frequently
skipping logging after 72000 examples to avoid logging too frequently
skipping logging after 72064 examples to avoid logging too frequently
train stats after 72128 examples: {'rewards_train/chosen': '-0.21307', 'rewards_train/rejected': '-0.37865', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16558', 'logps_train/rejected': '-170.85', 'logps_train/chosen': '-209.25', 'loss/train': '0.7159', 'examples_per_second': '289.55', 'grad_norm': '50.369', 'counters/examples': 72128, 'counters/updates': 1127}
skipping logging after 72192 examples to avoid logging too frequently
skipping logging after 72256 examples to avoid logging too frequently
skipping logging after 72320 examples to avoid logging too frequently
train stats after 72384 examples: {'rewards_train/chosen': '-0.21283', 'rewards_train/rejected': '-0.55155', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.33872', 'logps_train/rejected': '-192.17', 'logps_train/chosen': '-173.38', 'loss/train': '0.62073', 'examples_per_second': '286.41', 'grad_norm': '46.493', 'counters/examples': 72384, 'counters/updates': 1131}
skipping logging after 72448 examples to avoid logging too frequently
skipping logging after 72512 examples to avoid logging too frequently
skipping logging after 72576 examples to avoid logging too frequently
train stats after 72640 examples: {'rewards_train/chosen': '-0.24154', 'rewards_train/rejected': '-0.56421', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.32267', 'logps_train/rejected': '-159.08', 'logps_train/chosen': '-167.24', 'loss/train': '0.61851', 'examples_per_second': '286.95', 'grad_norm': '42.881', 'counters/examples': 72640, 'counters/updates': 1135}
skipping logging after 72704 examples to avoid logging too frequently
skipping logging after 72768 examples to avoid logging too frequently
skipping logging after 72832 examples to avoid logging too frequently
train stats after 72896 examples: {'rewards_train/chosen': '-0.24105', 'rewards_train/rejected': '-0.38943', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.14838', 'logps_train/rejected': '-182.91', 'logps_train/chosen': '-201.86', 'loss/train': '0.68301', 'examples_per_second': '282.72', 'grad_norm': '51.513', 'counters/examples': 72896, 'counters/updates': 1139}
skipping logging after 72960 examples to avoid logging too frequently
skipping logging after 73024 examples to avoid logging too frequently
skipping logging after 73088 examples to avoid logging too frequently
train stats after 73152 examples: {'rewards_train/chosen': '-0.13135', 'rewards_train/rejected': '-0.51857', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.38722', 'logps_train/rejected': '-188.73', 'logps_train/chosen': '-192.9', 'loss/train': '0.60837', 'examples_per_second': '272.03', 'grad_norm': '49.525', 'counters/examples': 73152, 'counters/updates': 1143}
skipping logging after 73216 examples to avoid logging too frequently
skipping logging after 73280 examples to avoid logging too frequently
skipping logging after 73344 examples to avoid logging too frequently
train stats after 73408 examples: {'rewards_train/chosen': '-0.21295', 'rewards_train/rejected': '-0.42963', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.21668', 'logps_train/rejected': '-163.87', 'logps_train/chosen': '-177.5', 'loss/train': '0.64617', 'examples_per_second': '269.2', 'grad_norm': '47.847', 'counters/examples': 73408, 'counters/updates': 1147}
skipping logging after 73472 examples to avoid logging too frequently
skipping logging after 73536 examples to avoid logging too frequently
skipping logging after 73600 examples to avoid logging too frequently
train stats after 73664 examples: {'rewards_train/chosen': '-0.12344', 'rewards_train/rejected': '-0.44088', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.31744', 'logps_train/rejected': '-183.93', 'logps_train/chosen': '-185.94', 'loss/train': '0.65143', 'examples_per_second': '272.96', 'grad_norm': '47.775', 'counters/examples': 73664, 'counters/updates': 1151}
skipping logging after 73728 examples to avoid logging too frequently
skipping logging after 73792 examples to avoid logging too frequently
skipping logging after 73856 examples to avoid logging too frequently
train stats after 73920 examples: {'rewards_train/chosen': '-0.027125', 'rewards_train/rejected': '-0.36879', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.34166', 'logps_train/rejected': '-161.94', 'logps_train/chosen': '-185.62', 'loss/train': '0.60869', 'examples_per_second': '267.66', 'grad_norm': '47.673', 'counters/examples': 73920, 'counters/updates': 1155}
skipping logging after 73984 examples to avoid logging too frequently
skipping logging after 74048 examples to avoid logging too frequently
skipping logging after 74112 examples to avoid logging too frequently
train stats after 74176 examples: {'rewards_train/chosen': '-0.088668', 'rewards_train/rejected': '-0.40284', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.31418', 'logps_train/rejected': '-125.45', 'logps_train/chosen': '-169.47', 'loss/train': '0.61854', 'examples_per_second': '270.25', 'grad_norm': '41.591', 'counters/examples': 74176, 'counters/updates': 1159}
skipping logging after 74240 examples to avoid logging too frequently
skipping logging after 74304 examples to avoid logging too frequently
skipping logging after 74368 examples to avoid logging too frequently
train stats after 74432 examples: {'rewards_train/chosen': '-0.068295', 'rewards_train/rejected': '-0.4068', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.33851', 'logps_train/rejected': '-160.52', 'logps_train/chosen': '-175.24', 'loss/train': '0.61549', 'examples_per_second': '264.65', 'grad_norm': '43.797', 'counters/examples': 74432, 'counters/updates': 1163}
skipping logging after 74496 examples to avoid logging too frequently
skipping logging after 74560 examples to avoid logging too frequently
skipping logging after 74624 examples to avoid logging too frequently
train stats after 74688 examples: {'rewards_train/chosen': '-0.20122', 'rewards_train/rejected': '-0.58755', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.38633', 'logps_train/rejected': '-160.89', 'logps_train/chosen': '-169.65', 'loss/train': '0.62025', 'examples_per_second': '273.79', 'grad_norm': '45.325', 'counters/examples': 74688, 'counters/updates': 1167}
skipping logging after 74752 examples to avoid logging too frequently
skipping logging after 74816 examples to avoid logging too frequently
skipping logging after 74880 examples to avoid logging too frequently
train stats after 74944 examples: {'rewards_train/chosen': '-0.069556', 'rewards_train/rejected': '-0.4717', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.40214', 'logps_train/rejected': '-187.45', 'logps_train/chosen': '-166.72', 'loss/train': '0.59761', 'examples_per_second': '273.41', 'grad_norm': '42.515', 'counters/examples': 74944, 'counters/updates': 1171}
skipping logging after 75008 examples to avoid logging too frequently
skipping logging after 75072 examples to avoid logging too frequently
skipping logging after 75136 examples to avoid logging too frequently
train stats after 75200 examples: {'rewards_train/chosen': '0.039436', 'rewards_train/rejected': '-0.28395', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.32339', 'logps_train/rejected': '-160.78', 'logps_train/chosen': '-180.76', 'loss/train': '0.61633', 'examples_per_second': '264.21', 'grad_norm': '47.549', 'counters/examples': 75200, 'counters/updates': 1175}
skipping logging after 75264 examples to avoid logging too frequently
skipping logging after 75328 examples to avoid logging too frequently
skipping logging after 75392 examples to avoid logging too frequently
train stats after 75456 examples: {'rewards_train/chosen': '-0.044506', 'rewards_train/rejected': '-0.57373', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.52922', 'logps_train/rejected': '-151.87', 'logps_train/chosen': '-193.48', 'loss/train': '0.55384', 'examples_per_second': '326.93', 'grad_norm': '36.485', 'counters/examples': 75456, 'counters/updates': 1179}
skipping logging after 75520 examples to avoid logging too frequently
skipping logging after 75584 examples to avoid logging too frequently
skipping logging after 75648 examples to avoid logging too frequently
train stats after 75712 examples: {'rewards_train/chosen': '-0.31791', 'rewards_train/rejected': '-0.49645', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.17854', 'logps_train/rejected': '-147.99', 'logps_train/chosen': '-145.51', 'loss/train': '0.73435', 'examples_per_second': '273.74', 'grad_norm': '46.053', 'counters/examples': 75712, 'counters/updates': 1183}
skipping logging after 75776 examples to avoid logging too frequently
skipping logging after 75840 examples to avoid logging too frequently
skipping logging after 75904 examples to avoid logging too frequently
train stats after 75968 examples: {'rewards_train/chosen': '-0.031021', 'rewards_train/rejected': '-0.4177', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.38668', 'logps_train/rejected': '-153.82', 'logps_train/chosen': '-172.3', 'loss/train': '0.60708', 'examples_per_second': '273.45', 'grad_norm': '42.221', 'counters/examples': 75968, 'counters/updates': 1187}
skipping logging after 76032 examples to avoid logging too frequently
skipping logging after 76096 examples to avoid logging too frequently
skipping logging after 76160 examples to avoid logging too frequently
train stats after 76224 examples: {'rewards_train/chosen': '-0.066369', 'rewards_train/rejected': '-0.34033', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.27396', 'logps_train/rejected': '-210.67', 'logps_train/chosen': '-210.49', 'loss/train': '0.63794', 'examples_per_second': '272.29', 'grad_norm': '50.4', 'counters/examples': 76224, 'counters/updates': 1191}
skipping logging after 76288 examples to avoid logging too frequently
skipping logging after 76352 examples to avoid logging too frequently
skipping logging after 76416 examples to avoid logging too frequently
train stats after 76480 examples: {'rewards_train/chosen': '-0.084246', 'rewards_train/rejected': '-0.39193', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.30769', 'logps_train/rejected': '-158.54', 'logps_train/chosen': '-179.18', 'loss/train': '0.63328', 'examples_per_second': '263.74', 'grad_norm': '42.888', 'counters/examples': 76480, 'counters/updates': 1195}
skipping logging after 76544 examples to avoid logging too frequently
skipping logging after 76608 examples to avoid logging too frequently
skipping logging after 76672 examples to avoid logging too frequently
train stats after 76736 examples: {'rewards_train/chosen': '-0.0061793', 'rewards_train/rejected': '-0.53358', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.5274', 'logps_train/rejected': '-146.01', 'logps_train/chosen': '-167.92', 'loss/train': '0.54501', 'examples_per_second': '273.97', 'grad_norm': '37.177', 'counters/examples': 76736, 'counters/updates': 1199}
skipping logging after 76800 examples to avoid logging too frequently
skipping logging after 76864 examples to avoid logging too frequently
skipping logging after 76928 examples to avoid logging too frequently
train stats after 76992 examples: {'rewards_train/chosen': '-0.18266', 'rewards_train/rejected': '-0.72675', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.54409', 'logps_train/rejected': '-162.07', 'logps_train/chosen': '-186.5', 'loss/train': '0.5714', 'examples_per_second': '263.17', 'grad_norm': '45.512', 'counters/examples': 76992, 'counters/updates': 1203}
skipping logging after 77056 examples to avoid logging too frequently
skipping logging after 77120 examples to avoid logging too frequently
skipping logging after 77184 examples to avoid logging too frequently
train stats after 77248 examples: {'rewards_train/chosen': '0.037075', 'rewards_train/rejected': '-0.66402', 'rewards_train/accuracies': '0.78125', 'rewards_train/margins': '0.7011', 'logps_train/rejected': '-173.13', 'logps_train/chosen': '-194.87', 'loss/train': '0.47495', 'examples_per_second': '262.41', 'grad_norm': '40.405', 'counters/examples': 77248, 'counters/updates': 1207}
skipping logging after 77312 examples to avoid logging too frequently
skipping logging after 77376 examples to avoid logging too frequently
skipping logging after 77440 examples to avoid logging too frequently
train stats after 77504 examples: {'rewards_train/chosen': '-0.3657', 'rewards_train/rejected': '-0.53716', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17146', 'logps_train/rejected': '-154.14', 'logps_train/chosen': '-148.49', 'loss/train': '0.69169', 'examples_per_second': '273.42', 'grad_norm': '49.988', 'counters/examples': 77504, 'counters/updates': 1211}
skipping logging after 77568 examples to avoid logging too frequently
skipping logging after 77632 examples to avoid logging too frequently
skipping logging after 77696 examples to avoid logging too frequently
train stats after 77760 examples: {'rewards_train/chosen': '-0.18692', 'rewards_train/rejected': '-0.4503', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.26338', 'logps_train/rejected': '-177.42', 'logps_train/chosen': '-186.94', 'loss/train': '0.66623', 'examples_per_second': '274.54', 'grad_norm': '54.808', 'counters/examples': 77760, 'counters/updates': 1215}
skipping logging after 77824 examples to avoid logging too frequently
skipping logging after 77888 examples to avoid logging too frequently
skipping logging after 77952 examples to avoid logging too frequently
train stats after 78016 examples: {'rewards_train/chosen': '-0.23961', 'rewards_train/rejected': '-0.50792', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.26831', 'logps_train/rejected': '-151.11', 'logps_train/chosen': '-172.27', 'loss/train': '0.66466', 'examples_per_second': '264.38', 'grad_norm': '49.281', 'counters/examples': 78016, 'counters/updates': 1219}
skipping logging after 78080 examples to avoid logging too frequently
skipping logging after 78144 examples to avoid logging too frequently
skipping logging after 78208 examples to avoid logging too frequently
train stats after 78272 examples: {'rewards_train/chosen': '-0.2097', 'rewards_train/rejected': '-0.62231', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.41261', 'logps_train/rejected': '-142.82', 'logps_train/chosen': '-185.14', 'loss/train': '0.6368', 'examples_per_second': '263.35', 'grad_norm': '45.583', 'counters/examples': 78272, 'counters/updates': 1223}
skipping logging after 78336 examples to avoid logging too frequently
skipping logging after 78400 examples to avoid logging too frequently
skipping logging after 78464 examples to avoid logging too frequently
train stats after 78528 examples: {'rewards_train/chosen': '-0.30759', 'rewards_train/rejected': '-0.83731', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.52971', 'logps_train/rejected': '-139.92', 'logps_train/chosen': '-178.32', 'loss/train': '0.60997', 'examples_per_second': '279.12', 'grad_norm': '46.271', 'counters/examples': 78528, 'counters/updates': 1227}
skipping logging after 78592 examples to avoid logging too frequently
skipping logging after 78656 examples to avoid logging too frequently
skipping logging after 78720 examples to avoid logging too frequently
train stats after 78784 examples: {'rewards_train/chosen': '-0.10181', 'rewards_train/rejected': '-0.80063', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.69882', 'logps_train/rejected': '-141.8', 'logps_train/chosen': '-189.79', 'loss/train': '0.52075', 'examples_per_second': '272.7', 'grad_norm': '37.777', 'counters/examples': 78784, 'counters/updates': 1231}
skipping logging after 78848 examples to avoid logging too frequently
skipping logging after 78912 examples to avoid logging too frequently
skipping logging after 78976 examples to avoid logging too frequently
train stats after 79040 examples: {'rewards_train/chosen': '-0.18729', 'rewards_train/rejected': '-0.31335', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.12606', 'logps_train/rejected': '-139.19', 'logps_train/chosen': '-166.69', 'loss/train': '0.71176', 'examples_per_second': '265.64', 'grad_norm': '51.811', 'counters/examples': 79040, 'counters/updates': 1235}
skipping logging after 79104 examples to avoid logging too frequently
skipping logging after 79168 examples to avoid logging too frequently
skipping logging after 79232 examples to avoid logging too frequently
train stats after 79296 examples: {'rewards_train/chosen': '-0.27266', 'rewards_train/rejected': '-0.45772', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18506', 'logps_train/rejected': '-171.12', 'logps_train/chosen': '-179.52', 'loss/train': '0.67704', 'examples_per_second': '273.22', 'grad_norm': '50.342', 'counters/examples': 79296, 'counters/updates': 1239}
skipping logging after 79360 examples to avoid logging too frequently
skipping logging after 79424 examples to avoid logging too frequently
skipping logging after 79488 examples to avoid logging too frequently
train stats after 79552 examples: {'rewards_train/chosen': '-0.10492', 'rewards_train/rejected': '-0.40073', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.29581', 'logps_train/rejected': '-171.77', 'logps_train/chosen': '-146.18', 'loss/train': '0.64578', 'examples_per_second': '273.67', 'grad_norm': '40.997', 'counters/examples': 79552, 'counters/updates': 1243}
skipping logging after 79616 examples to avoid logging too frequently
skipping logging after 79680 examples to avoid logging too frequently
skipping logging after 79744 examples to avoid logging too frequently
train stats after 79808 examples: {'rewards_train/chosen': '-0.15835', 'rewards_train/rejected': '-0.25773', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.099382', 'logps_train/rejected': '-189.12', 'logps_train/chosen': '-193.35', 'loss/train': '0.72164', 'examples_per_second': '246.56', 'grad_norm': '51.598', 'counters/examples': 79808, 'counters/updates': 1247}
skipping logging after 79872 examples to avoid logging too frequently
skipping logging after 79936 examples to avoid logging too frequently
skipping logging after 80000 examples to avoid logging too frequently
train stats after 80064 examples: {'rewards_train/chosen': '-0.049579', 'rewards_train/rejected': '-0.32064', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.27106', 'logps_train/rejected': '-156.5', 'logps_train/chosen': '-181.39', 'loss/train': '0.6411', 'examples_per_second': '267.34', 'grad_norm': '45.934', 'counters/examples': 80064, 'counters/updates': 1251}
skipping logging after 80128 examples to avoid logging too frequently
skipping logging after 80192 examples to avoid logging too frequently
skipping logging after 80256 examples to avoid logging too frequently
train stats after 80320 examples: {'rewards_train/chosen': '-0.12338', 'rewards_train/rejected': '-0.5123', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.38893', 'logps_train/rejected': '-177.58', 'logps_train/chosen': '-163.53', 'loss/train': '0.60738', 'examples_per_second': '264.03', 'grad_norm': '42.765', 'counters/examples': 80320, 'counters/updates': 1255}
skipping logging after 80384 examples to avoid logging too frequently
skipping logging after 80448 examples to avoid logging too frequently
skipping logging after 80512 examples to avoid logging too frequently
train stats after 80576 examples: {'rewards_train/chosen': '-0.054328', 'rewards_train/rejected': '-0.43063', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.37631', 'logps_train/rejected': '-130.4', 'logps_train/chosen': '-142.53', 'loss/train': '0.60238', 'examples_per_second': '264.65', 'grad_norm': '38.756', 'counters/examples': 80576, 'counters/updates': 1259}
skipping logging after 80640 examples to avoid logging too frequently
skipping logging after 80704 examples to avoid logging too frequently
skipping logging after 80768 examples to avoid logging too frequently
train stats after 80832 examples: {'rewards_train/chosen': '0.0020071', 'rewards_train/rejected': '-0.65582', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.65782', 'logps_train/rejected': '-162.14', 'logps_train/chosen': '-184.53', 'loss/train': '0.51504', 'examples_per_second': '273.25', 'grad_norm': '41.741', 'counters/examples': 80832, 'counters/updates': 1263}
skipping logging after 80896 examples to avoid logging too frequently
skipping logging after 80960 examples to avoid logging too frequently
skipping logging after 81024 examples to avoid logging too frequently
train stats after 81088 examples: {'rewards_train/chosen': '-0.066162', 'rewards_train/rejected': '-0.48654', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.42038', 'logps_train/rejected': '-168.52', 'logps_train/chosen': '-182.94', 'loss/train': '0.58531', 'examples_per_second': '273.86', 'grad_norm': '41.554', 'counters/examples': 81088, 'counters/updates': 1267}
skipping logging after 81152 examples to avoid logging too frequently
skipping logging after 81216 examples to avoid logging too frequently
skipping logging after 81280 examples to avoid logging too frequently
train stats after 81344 examples: {'rewards_train/chosen': '-0.15062', 'rewards_train/rejected': '-0.50414', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.35352', 'logps_train/rejected': '-152.95', 'logps_train/chosen': '-182.83', 'loss/train': '0.62251', 'examples_per_second': '263.94', 'grad_norm': '37.174', 'counters/examples': 81344, 'counters/updates': 1271}
skipping logging after 81408 examples to avoid logging too frequently
skipping logging after 81472 examples to avoid logging too frequently
skipping logging after 81536 examples to avoid logging too frequently
train stats after 81600 examples: {'rewards_train/chosen': '-0.19784', 'rewards_train/rejected': '-0.28727', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.089431', 'logps_train/rejected': '-165.5', 'logps_train/chosen': '-137.95', 'loss/train': '0.74315', 'examples_per_second': '263.74', 'grad_norm': '51.006', 'counters/examples': 81600, 'counters/updates': 1275}
skipping logging after 81664 examples to avoid logging too frequently
skipping logging after 81728 examples to avoid logging too frequently
skipping logging after 81792 examples to avoid logging too frequently
train stats after 81856 examples: {'rewards_train/chosen': '-0.11958', 'rewards_train/rejected': '-0.43794', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.31835', 'logps_train/rejected': '-143.91', 'logps_train/chosen': '-161.42', 'loss/train': '0.66243', 'examples_per_second': '271.52', 'grad_norm': '46.568', 'counters/examples': 81856, 'counters/updates': 1279}
skipping logging after 81920 examples to avoid logging too frequently
skipping logging after 81984 examples to avoid logging too frequently
skipping logging after 82048 examples to avoid logging too frequently
train stats after 82112 examples: {'rewards_train/chosen': '-0.23902', 'rewards_train/rejected': '-0.49244', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.25342', 'logps_train/rejected': '-127.63', 'logps_train/chosen': '-159.22', 'loss/train': '0.66191', 'examples_per_second': '282.4', 'grad_norm': '41.102', 'counters/examples': 82112, 'counters/updates': 1283}
skipping logging after 82176 examples to avoid logging too frequently
skipping logging after 82240 examples to avoid logging too frequently
skipping logging after 82304 examples to avoid logging too frequently
train stats after 82368 examples: {'rewards_train/chosen': '-0.1389', 'rewards_train/rejected': '-0.603', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.4641', 'logps_train/rejected': '-149.57', 'logps_train/chosen': '-188.29', 'loss/train': '0.58212', 'examples_per_second': '298.48', 'grad_norm': '40.727', 'counters/examples': 82368, 'counters/updates': 1287}
skipping logging after 82432 examples to avoid logging too frequently
skipping logging after 82496 examples to avoid logging too frequently
skipping logging after 82560 examples to avoid logging too frequently
train stats after 82624 examples: {'rewards_train/chosen': '-0.030102', 'rewards_train/rejected': '-0.56303', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.53293', 'logps_train/rejected': '-146.6', 'logps_train/chosen': '-178.51', 'loss/train': '0.53449', 'examples_per_second': '273.43', 'grad_norm': '43.392', 'counters/examples': 82624, 'counters/updates': 1291}
skipping logging after 82688 examples to avoid logging too frequently
skipping logging after 82752 examples to avoid logging too frequently
skipping logging after 82816 examples to avoid logging too frequently
train stats after 82880 examples: {'rewards_train/chosen': '-0.2887', 'rewards_train/rejected': '-0.48344', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.19474', 'logps_train/rejected': '-149.25', 'logps_train/chosen': '-182.82', 'loss/train': '0.69394', 'examples_per_second': '272.5', 'grad_norm': '46.637', 'counters/examples': 82880, 'counters/updates': 1295}
skipping logging after 82944 examples to avoid logging too frequently
skipping logging after 83008 examples to avoid logging too frequently
skipping logging after 83072 examples to avoid logging too frequently
train stats after 83136 examples: {'rewards_train/chosen': '-0.23421', 'rewards_train/rejected': '-0.45958', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.22537', 'logps_train/rejected': '-167.27', 'logps_train/chosen': '-159.66', 'loss/train': '0.64781', 'examples_per_second': '263.56', 'grad_norm': '42.616', 'counters/examples': 83136, 'counters/updates': 1299}
skipping logging after 83200 examples to avoid logging too frequently
skipping logging after 83264 examples to avoid logging too frequently
skipping logging after 83328 examples to avoid logging too frequently
train stats after 83392 examples: {'rewards_train/chosen': '-0.093854', 'rewards_train/rejected': '-0.27749', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.18363', 'logps_train/rejected': '-108.67', 'logps_train/chosen': '-170.1', 'loss/train': '0.67323', 'examples_per_second': '273.55', 'grad_norm': '41.78', 'counters/examples': 83392, 'counters/updates': 1303}
skipping logging after 83456 examples to avoid logging too frequently
skipping logging after 83520 examples to avoid logging too frequently
skipping logging after 83584 examples to avoid logging too frequently
train stats after 83648 examples: {'rewards_train/chosen': '-0.20457', 'rewards_train/rejected': '-0.56024', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.35567', 'logps_train/rejected': '-177.86', 'logps_train/chosen': '-176.83', 'loss/train': '0.64293', 'examples_per_second': '301.07', 'grad_norm': '45.039', 'counters/examples': 83648, 'counters/updates': 1307}
skipping logging after 83712 examples to avoid logging too frequently
skipping logging after 83776 examples to avoid logging too frequently
Running evaluation after 83776 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:00, 17.17it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 17.36it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:00, 17.51it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 17.41it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:00<00:00, 17.41it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 17.36it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:00<00:00, 17.35it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.33it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.35it/s]
eval after 83776: {'rewards_eval/chosen': '-0.071098', 'rewards_eval/rejected': '-0.3778', 'rewards_eval/accuracies': '0.625', 'rewards_eval/margins': '0.30671', 'logps_eval/rejected': '-153.65', 'logps_eval/chosen': '-178.57', 'loss/eval': '0.6353'}
creating checkpoint to write to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-83776...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-83776/policy.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-83776/optimizer.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-83776/scheduler.pt...
train stats after 83840 examples: {'rewards_train/chosen': '-0.18195', 'rewards_train/rejected': '-0.46839', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.28645', 'logps_train/rejected': '-132.65', 'logps_train/chosen': '-135.52', 'loss/train': '0.6199', 'examples_per_second': '219.55', 'grad_norm': '34.482', 'counters/examples': 83840, 'counters/updates': 1310}
skipping logging after 83904 examples to avoid logging too frequently
skipping logging after 83968 examples to avoid logging too frequently
skipping logging after 84032 examples to avoid logging too frequently
train stats after 84096 examples: {'rewards_train/chosen': '-0.064317', 'rewards_train/rejected': '-0.43993', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.37561', 'logps_train/rejected': '-189.89', 'logps_train/chosen': '-198.7', 'loss/train': '0.63952', 'examples_per_second': '263.9', 'grad_norm': '51.86', 'counters/examples': 84096, 'counters/updates': 1314}
skipping logging after 84160 examples to avoid logging too frequently
skipping logging after 84224 examples to avoid logging too frequently
skipping logging after 84288 examples to avoid logging too frequently
train stats after 84352 examples: {'rewards_train/chosen': '-0.073709', 'rewards_train/rejected': '-0.37733', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.30362', 'logps_train/rejected': '-146.83', 'logps_train/chosen': '-183.24', 'loss/train': '0.61179', 'examples_per_second': '273.78', 'grad_norm': '42.698', 'counters/examples': 84352, 'counters/updates': 1318}
skipping logging after 84416 examples to avoid logging too frequently
skipping logging after 84480 examples to avoid logging too frequently
skipping logging after 84544 examples to avoid logging too frequently
train stats after 84608 examples: {'rewards_train/chosen': '-0.050758', 'rewards_train/rejected': '-0.35773', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.30697', 'logps_train/rejected': '-146.8', 'logps_train/chosen': '-156.7', 'loss/train': '0.63185', 'examples_per_second': '273.63', 'grad_norm': '44.605', 'counters/examples': 84608, 'counters/updates': 1322}
skipping logging after 84672 examples to avoid logging too frequently
skipping logging after 84736 examples to avoid logging too frequently
skipping logging after 84800 examples to avoid logging too frequently
train stats after 84864 examples: {'rewards_train/chosen': '0.047779', 'rewards_train/rejected': '-0.39958', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.44736', 'logps_train/rejected': '-152.48', 'logps_train/chosen': '-159.04', 'loss/train': '0.57033', 'examples_per_second': '263.76', 'grad_norm': '38.885', 'counters/examples': 84864, 'counters/updates': 1326}
skipping logging after 84928 examples to avoid logging too frequently
skipping logging after 84992 examples to avoid logging too frequently
skipping logging after 85056 examples to avoid logging too frequently
train stats after 85120 examples: {'rewards_train/chosen': '0.02018', 'rewards_train/rejected': '-0.36254', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.38272', 'logps_train/rejected': '-157.91', 'logps_train/chosen': '-176.4', 'loss/train': '0.60253', 'examples_per_second': '272.3', 'grad_norm': '49.105', 'counters/examples': 85120, 'counters/updates': 1330}
skipping logging after 85184 examples to avoid logging too frequently
skipping logging after 85248 examples to avoid logging too frequently
skipping logging after 85312 examples to avoid logging too frequently
train stats after 85376 examples: {'rewards_train/chosen': '-0.20564', 'rewards_train/rejected': '-0.58165', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.376', 'logps_train/rejected': '-160.06', 'logps_train/chosen': '-173.33', 'loss/train': '0.61851', 'examples_per_second': '286.52', 'grad_norm': '38.932', 'counters/examples': 85376, 'counters/updates': 1334}
skipping logging after 85440 examples to avoid logging too frequently
skipping logging after 85504 examples to avoid logging too frequently
skipping logging after 85568 examples to avoid logging too frequently
train stats after 85632 examples: {'rewards_train/chosen': '0.011099', 'rewards_train/rejected': '-0.37691', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.388', 'logps_train/rejected': '-166.41', 'logps_train/chosen': '-180.89', 'loss/train': '0.62125', 'examples_per_second': '272.55', 'grad_norm': '41.515', 'counters/examples': 85632, 'counters/updates': 1338}
skipping logging after 85696 examples to avoid logging too frequently
skipping logging after 85760 examples to avoid logging too frequently
skipping logging after 85824 examples to avoid logging too frequently
train stats after 85888 examples: {'rewards_train/chosen': '-0.071347', 'rewards_train/rejected': '-0.49004', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.41869', 'logps_train/rejected': '-160.5', 'logps_train/chosen': '-199.72', 'loss/train': '0.59151', 'examples_per_second': '256.08', 'grad_norm': '49.154', 'counters/examples': 85888, 'counters/updates': 1342}
skipping logging after 85952 examples to avoid logging too frequently
skipping logging after 86016 examples to avoid logging too frequently
skipping logging after 86080 examples to avoid logging too frequently
train stats after 86144 examples: {'rewards_train/chosen': '-0.12392', 'rewards_train/rejected': '-0.35182', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.2279', 'logps_train/rejected': '-164.67', 'logps_train/chosen': '-172.73', 'loss/train': '0.67151', 'examples_per_second': '273.48', 'grad_norm': '46.411', 'counters/examples': 86144, 'counters/updates': 1346}
skipping logging after 86208 examples to avoid logging too frequently
skipping logging after 86272 examples to avoid logging too frequently
skipping logging after 86336 examples to avoid logging too frequently
train stats after 86400 examples: {'rewards_train/chosen': '-0.031259', 'rewards_train/rejected': '-0.30763', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.27638', 'logps_train/rejected': '-166.94', 'logps_train/chosen': '-182.79', 'loss/train': '0.61746', 'examples_per_second': '272.05', 'grad_norm': '47.45', 'counters/examples': 86400, 'counters/updates': 1350}
skipping logging after 86464 examples to avoid logging too frequently
skipping logging after 86528 examples to avoid logging too frequently
skipping logging after 86592 examples to avoid logging too frequently
train stats after 86656 examples: {'rewards_train/chosen': '-0.089893', 'rewards_train/rejected': '-0.38322', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.29333', 'logps_train/rejected': '-185.77', 'logps_train/chosen': '-215.99', 'loss/train': '0.63171', 'examples_per_second': '268.76', 'grad_norm': '52.956', 'counters/examples': 86656, 'counters/updates': 1354}
skipping logging after 86720 examples to avoid logging too frequently
skipping logging after 86784 examples to avoid logging too frequently
skipping logging after 86848 examples to avoid logging too frequently
train stats after 86912 examples: {'rewards_train/chosen': '-0.18044', 'rewards_train/rejected': '-0.52958', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.34914', 'logps_train/rejected': '-194.16', 'logps_train/chosen': '-202.84', 'loss/train': '0.60846', 'examples_per_second': '271.56', 'grad_norm': '47.79', 'counters/examples': 86912, 'counters/updates': 1358}
skipping logging after 86976 examples to avoid logging too frequently
skipping logging after 87040 examples to avoid logging too frequently
skipping logging after 87104 examples to avoid logging too frequently
train stats after 87168 examples: {'rewards_train/chosen': '-0.15399', 'rewards_train/rejected': '-0.27767', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12367', 'logps_train/rejected': '-192.05', 'logps_train/chosen': '-162.13', 'loss/train': '0.70649', 'examples_per_second': '262.22', 'grad_norm': '58.503', 'counters/examples': 87168, 'counters/updates': 1362}
skipping logging after 87232 examples to avoid logging too frequently
skipping logging after 87296 examples to avoid logging too frequently
skipping logging after 87360 examples to avoid logging too frequently
train stats after 87424 examples: {'rewards_train/chosen': '-0.34912', 'rewards_train/rejected': '-0.56991', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.22079', 'logps_train/rejected': '-161.36', 'logps_train/chosen': '-163.6', 'loss/train': '0.69902', 'examples_per_second': '282.72', 'grad_norm': '44.338', 'counters/examples': 87424, 'counters/updates': 1366}
skipping logging after 87488 examples to avoid logging too frequently
skipping logging after 87552 examples to avoid logging too frequently
skipping logging after 87616 examples to avoid logging too frequently
train stats after 87680 examples: {'rewards_train/chosen': '-0.11688', 'rewards_train/rejected': '-0.57105', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.45417', 'logps_train/rejected': '-147.55', 'logps_train/chosen': '-165.78', 'loss/train': '0.59636', 'examples_per_second': '272.26', 'grad_norm': '44.892', 'counters/examples': 87680, 'counters/updates': 1370}
skipping logging after 87744 examples to avoid logging too frequently
skipping logging after 87808 examples to avoid logging too frequently
skipping logging after 87872 examples to avoid logging too frequently
train stats after 87936 examples: {'rewards_train/chosen': '0.041814', 'rewards_train/rejected': '-0.36881', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.41062', 'logps_train/rejected': '-147.4', 'logps_train/chosen': '-154.15', 'loss/train': '0.57426', 'examples_per_second': '272.57', 'grad_norm': '42.832', 'counters/examples': 87936, 'counters/updates': 1374}
skipping logging after 88000 examples to avoid logging too frequently
skipping logging after 88064 examples to avoid logging too frequently
skipping logging after 88128 examples to avoid logging too frequently
train stats after 88192 examples: {'rewards_train/chosen': '-0.13808', 'rewards_train/rejected': '-0.53857', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.40048', 'logps_train/rejected': '-158.78', 'logps_train/chosen': '-183.16', 'loss/train': '0.57169', 'examples_per_second': '273.57', 'grad_norm': '40.517', 'counters/examples': 88192, 'counters/updates': 1378}
skipping logging after 88256 examples to avoid logging too frequently
skipping logging after 88320 examples to avoid logging too frequently
skipping logging after 88384 examples to avoid logging too frequently
train stats after 88448 examples: {'rewards_train/chosen': '-0.17442', 'rewards_train/rejected': '-0.53798', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.36356', 'logps_train/rejected': '-155.67', 'logps_train/chosen': '-194.11', 'loss/train': '0.60235', 'examples_per_second': '273.39', 'grad_norm': '42.96', 'counters/examples': 88448, 'counters/updates': 1382}
skipping logging after 88512 examples to avoid logging too frequently
skipping logging after 88576 examples to avoid logging too frequently
skipping logging after 88640 examples to avoid logging too frequently
train stats after 88704 examples: {'rewards_train/chosen': '-0.38038', 'rewards_train/rejected': '-0.5137', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13332', 'logps_train/rejected': '-144.62', 'logps_train/chosen': '-153.36', 'loss/train': '0.72601', 'examples_per_second': '307.17', 'grad_norm': '44.483', 'counters/examples': 88704, 'counters/updates': 1386}
skipping logging after 88768 examples to avoid logging too frequently
skipping logging after 88832 examples to avoid logging too frequently
skipping logging after 88896 examples to avoid logging too frequently
train stats after 88960 examples: {'rewards_train/chosen': '-0.4087', 'rewards_train/rejected': '-0.69929', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.2906', 'logps_train/rejected': '-171.77', 'logps_train/chosen': '-177.57', 'loss/train': '0.68003', 'examples_per_second': '268.35', 'grad_norm': '45.054', 'counters/examples': 88960, 'counters/updates': 1390}
skipping logging after 89024 examples to avoid logging too frequently
skipping logging after 89088 examples to avoid logging too frequently
skipping logging after 89152 examples to avoid logging too frequently
train stats after 89216 examples: {'rewards_train/chosen': '-0.17809', 'rewards_train/rejected': '-0.42992', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.25183', 'logps_train/rejected': '-155.91', 'logps_train/chosen': '-217.45', 'loss/train': '0.6682', 'examples_per_second': '262.18', 'grad_norm': '49.632', 'counters/examples': 89216, 'counters/updates': 1394}
skipping logging after 89280 examples to avoid logging too frequently
skipping logging after 89344 examples to avoid logging too frequently
skipping logging after 89408 examples to avoid logging too frequently
train stats after 89472 examples: {'rewards_train/chosen': '-0.081135', 'rewards_train/rejected': '-0.64268', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.56154', 'logps_train/rejected': '-163.27', 'logps_train/chosen': '-184.03', 'loss/train': '0.52392', 'examples_per_second': '284', 'grad_norm': '40.497', 'counters/examples': 89472, 'counters/updates': 1398}
skipping logging after 89536 examples to avoid logging too frequently
skipping logging after 89600 examples to avoid logging too frequently
skipping logging after 89664 examples to avoid logging too frequently
train stats after 89728 examples: {'rewards_train/chosen': '-0.04864', 'rewards_train/rejected': '-0.44129', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.39265', 'logps_train/rejected': '-163.27', 'logps_train/chosen': '-195.3', 'loss/train': '0.62663', 'examples_per_second': '269.1', 'grad_norm': '50.021', 'counters/examples': 89728, 'counters/updates': 1402}
skipping logging after 89792 examples to avoid logging too frequently
skipping logging after 89856 examples to avoid logging too frequently
skipping logging after 89920 examples to avoid logging too frequently
train stats after 89984 examples: {'rewards_train/chosen': '-0.25582', 'rewards_train/rejected': '-0.61369', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.35787', 'logps_train/rejected': '-167.27', 'logps_train/chosen': '-219.78', 'loss/train': '0.61519', 'examples_per_second': '274.09', 'grad_norm': '43.998', 'counters/examples': 89984, 'counters/updates': 1406}
skipping logging after 90048 examples to avoid logging too frequently
skipping logging after 90112 examples to avoid logging too frequently
skipping logging after 90176 examples to avoid logging too frequently
train stats after 90240 examples: {'rewards_train/chosen': '-0.16025', 'rewards_train/rejected': '-0.52858', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.36833', 'logps_train/rejected': '-144.05', 'logps_train/chosen': '-207.33', 'loss/train': '0.6414', 'examples_per_second': '268.5', 'grad_norm': '43.604', 'counters/examples': 90240, 'counters/updates': 1410}
skipping logging after 90304 examples to avoid logging too frequently
skipping logging after 90368 examples to avoid logging too frequently
skipping logging after 90432 examples to avoid logging too frequently
train stats after 90496 examples: {'rewards_train/chosen': '-0.13963', 'rewards_train/rejected': '-0.62833', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.48869', 'logps_train/rejected': '-155.69', 'logps_train/chosen': '-162.23', 'loss/train': '0.58905', 'examples_per_second': '262.24', 'grad_norm': '38.421', 'counters/examples': 90496, 'counters/updates': 1414}
skipping logging after 90560 examples to avoid logging too frequently
skipping logging after 90624 examples to avoid logging too frequently
skipping logging after 90688 examples to avoid logging too frequently
train stats after 90752 examples: {'rewards_train/chosen': '-0.14457', 'rewards_train/rejected': '-0.51796', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.37339', 'logps_train/rejected': '-149.49', 'logps_train/chosen': '-173.36', 'loss/train': '0.60802', 'examples_per_second': '271.01', 'grad_norm': '42.79', 'counters/examples': 90752, 'counters/updates': 1418}
skipping logging after 90816 examples to avoid logging too frequently
skipping logging after 90880 examples to avoid logging too frequently
skipping logging after 90944 examples to avoid logging too frequently
train stats after 91008 examples: {'rewards_train/chosen': '-0.28043', 'rewards_train/rejected': '-0.44602', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.16559', 'logps_train/rejected': '-163.78', 'logps_train/chosen': '-166.42', 'loss/train': '0.7066', 'examples_per_second': '270.9', 'grad_norm': '42.868', 'counters/examples': 91008, 'counters/updates': 1422}
skipping logging after 91072 examples to avoid logging too frequently
skipping logging after 91136 examples to avoid logging too frequently
skipping logging after 91200 examples to avoid logging too frequently
train stats after 91264 examples: {'rewards_train/chosen': '-0.31832', 'rewards_train/rejected': '-0.73766', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.41933', 'logps_train/rejected': '-180.5', 'logps_train/chosen': '-178.81', 'loss/train': '0.60891', 'examples_per_second': '269.14', 'grad_norm': '43.251', 'counters/examples': 91264, 'counters/updates': 1426}
skipping logging after 91328 examples to avoid logging too frequently
skipping logging after 91392 examples to avoid logging too frequently
skipping logging after 91456 examples to avoid logging too frequently
train stats after 91520 examples: {'rewards_train/chosen': '-0.17466', 'rewards_train/rejected': '-0.63211', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.45746', 'logps_train/rejected': '-159.62', 'logps_train/chosen': '-156.02', 'loss/train': '0.5738', 'examples_per_second': '289.94', 'grad_norm': '37.221', 'counters/examples': 91520, 'counters/updates': 1430}
skipping logging after 91584 examples to avoid logging too frequently
skipping logging after 91648 examples to avoid logging too frequently
skipping logging after 91712 examples to avoid logging too frequently
train stats after 91776 examples: {'rewards_train/chosen': '-0.22556', 'rewards_train/rejected': '-0.62983', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.40427', 'logps_train/rejected': '-135.98', 'logps_train/chosen': '-172', 'loss/train': '0.59188', 'examples_per_second': '269.38', 'grad_norm': '41.518', 'counters/examples': 91776, 'counters/updates': 1434}
skipping logging after 91840 examples to avoid logging too frequently
skipping logging after 91904 examples to avoid logging too frequently
skipping logging after 91968 examples to avoid logging too frequently
train stats after 92032 examples: {'rewards_train/chosen': '-0.11524', 'rewards_train/rejected': '-0.61562', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.50038', 'logps_train/rejected': '-170.61', 'logps_train/chosen': '-183.46', 'loss/train': '0.59598', 'examples_per_second': '260.14', 'grad_norm': '41.164', 'counters/examples': 92032, 'counters/updates': 1438}
skipping logging after 92096 examples to avoid logging too frequently
skipping logging after 92160 examples to avoid logging too frequently
skipping logging after 92224 examples to avoid logging too frequently
train stats after 92288 examples: {'rewards_train/chosen': '-0.11254', 'rewards_train/rejected': '-0.66739', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.55485', 'logps_train/rejected': '-137.46', 'logps_train/chosen': '-173.63', 'loss/train': '0.53357', 'examples_per_second': '272.37', 'grad_norm': '36.669', 'counters/examples': 92288, 'counters/updates': 1442}
skipping logging after 92352 examples to avoid logging too frequently
skipping logging after 92416 examples to avoid logging too frequently
skipping logging after 92480 examples to avoid logging too frequently
train stats after 92544 examples: {'rewards_train/chosen': '-0.31108', 'rewards_train/rejected': '-0.77271', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.46163', 'logps_train/rejected': '-158.65', 'logps_train/chosen': '-166.49', 'loss/train': '0.5834', 'examples_per_second': '284.5', 'grad_norm': '40.242', 'counters/examples': 92544, 'counters/updates': 1446}
skipping logging after 92608 examples to avoid logging too frequently
skipping logging after 92672 examples to avoid logging too frequently
skipping logging after 92736 examples to avoid logging too frequently
train stats after 92800 examples: {'rewards_train/chosen': '-0.25064', 'rewards_train/rejected': '-0.69646', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.44582', 'logps_train/rejected': '-150.89', 'logps_train/chosen': '-145.69', 'loss/train': '0.59548', 'examples_per_second': '128.1', 'grad_norm': '35.941', 'counters/examples': 92800, 'counters/updates': 1450}
skipping logging after 92864 examples to avoid logging too frequently
skipping logging after 92928 examples to avoid logging too frequently
skipping logging after 92992 examples to avoid logging too frequently
train stats after 93056 examples: {'rewards_train/chosen': '-0.36364', 'rewards_train/rejected': '-0.76067', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.39702', 'logps_train/rejected': '-158.14', 'logps_train/chosen': '-197.89', 'loss/train': '0.62095', 'examples_per_second': '267.39', 'grad_norm': '47.206', 'counters/examples': 93056, 'counters/updates': 1454}
skipping logging after 93120 examples to avoid logging too frequently
skipping logging after 93184 examples to avoid logging too frequently
skipping logging after 93248 examples to avoid logging too frequently
train stats after 93312 examples: {'rewards_train/chosen': '-0.26816', 'rewards_train/rejected': '-0.62095', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.35279', 'logps_train/rejected': '-152.96', 'logps_train/chosen': '-168.38', 'loss/train': '0.61582', 'examples_per_second': '278.83', 'grad_norm': '41.297', 'counters/examples': 93312, 'counters/updates': 1458}
skipping logging after 93376 examples to avoid logging too frequently
skipping logging after 93440 examples to avoid logging too frequently
skipping logging after 93504 examples to avoid logging too frequently
train stats after 93568 examples: {'rewards_train/chosen': '-0.38436', 'rewards_train/rejected': '-0.79281', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.40845', 'logps_train/rejected': '-194.58', 'logps_train/chosen': '-220.84', 'loss/train': '0.6073', 'examples_per_second': '266.8', 'grad_norm': '46.627', 'counters/examples': 93568, 'counters/updates': 1462}
skipping logging after 93632 examples to avoid logging too frequently
skipping logging after 93696 examples to avoid logging too frequently
skipping logging after 93760 examples to avoid logging too frequently
train stats after 93824 examples: {'rewards_train/chosen': '-0.37784', 'rewards_train/rejected': '-0.77405', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.39621', 'logps_train/rejected': '-159.86', 'logps_train/chosen': '-171.09', 'loss/train': '0.59451', 'examples_per_second': '272.05', 'grad_norm': '42.92', 'counters/examples': 93824, 'counters/updates': 1466}
skipping logging after 93888 examples to avoid logging too frequently
skipping logging after 93952 examples to avoid logging too frequently
skipping logging after 94016 examples to avoid logging too frequently
train stats after 94080 examples: {'rewards_train/chosen': '-0.39436', 'rewards_train/rejected': '-0.65307', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25872', 'logps_train/rejected': '-168.84', 'logps_train/chosen': '-193.72', 'loss/train': '0.67848', 'examples_per_second': '268.2', 'grad_norm': '49.215', 'counters/examples': 94080, 'counters/updates': 1470}
skipping logging after 94144 examples to avoid logging too frequently
skipping logging after 94208 examples to avoid logging too frequently
skipping logging after 94272 examples to avoid logging too frequently
train stats after 94336 examples: {'rewards_train/chosen': '-0.33087', 'rewards_train/rejected': '-0.57891', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.24803', 'logps_train/rejected': '-141.47', 'logps_train/chosen': '-169.31', 'loss/train': '0.68664', 'examples_per_second': '263.33', 'grad_norm': '51.444', 'counters/examples': 94336, 'counters/updates': 1474}
skipping logging after 94400 examples to avoid logging too frequently
skipping logging after 94464 examples to avoid logging too frequently
skipping logging after 94528 examples to avoid logging too frequently
train stats after 94592 examples: {'rewards_train/chosen': '-0.14871', 'rewards_train/rejected': '-0.49804', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.34934', 'logps_train/rejected': '-161.73', 'logps_train/chosen': '-183.39', 'loss/train': '0.62533', 'examples_per_second': '271.51', 'grad_norm': '45.412', 'counters/examples': 94592, 'counters/updates': 1478}
skipping logging after 94656 examples to avoid logging too frequently
skipping logging after 94720 examples to avoid logging too frequently
skipping logging after 94784 examples to avoid logging too frequently
train stats after 94848 examples: {'rewards_train/chosen': '-0.45723', 'rewards_train/rejected': '-0.84706', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.38983', 'logps_train/rejected': '-143.37', 'logps_train/chosen': '-165.88', 'loss/train': '0.61653', 'examples_per_second': '280.84', 'grad_norm': '43.656', 'counters/examples': 94848, 'counters/updates': 1482}
skipping logging after 94912 examples to avoid logging too frequently
skipping logging after 94976 examples to avoid logging too frequently
skipping logging after 95040 examples to avoid logging too frequently
train stats after 95104 examples: {'rewards_train/chosen': '-0.091314', 'rewards_train/rejected': '-0.41319', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.32188', 'logps_train/rejected': '-143.69', 'logps_train/chosen': '-198.64', 'loss/train': '0.61739', 'examples_per_second': '272.36', 'grad_norm': '45.734', 'counters/examples': 95104, 'counters/updates': 1486}
skipping logging after 95168 examples to avoid logging too frequently
skipping logging after 95232 examples to avoid logging too frequently
skipping logging after 95296 examples to avoid logging too frequently
train stats after 95360 examples: {'rewards_train/chosen': '-0.3441', 'rewards_train/rejected': '-0.45122', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10712', 'logps_train/rejected': '-189.01', 'logps_train/chosen': '-175.19', 'loss/train': '0.74953', 'examples_per_second': '272.11', 'grad_norm': '56.932', 'counters/examples': 95360, 'counters/updates': 1490}
skipping logging after 95424 examples to avoid logging too frequently
skipping logging after 95488 examples to avoid logging too frequently
skipping logging after 95552 examples to avoid logging too frequently
train stats after 95616 examples: {'rewards_train/chosen': '-0.16795', 'rewards_train/rejected': '-0.42622', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.25828', 'logps_train/rejected': '-165.27', 'logps_train/chosen': '-201.07', 'loss/train': '0.6432', 'examples_per_second': '272.75', 'grad_norm': '42.49', 'counters/examples': 95616, 'counters/updates': 1494}
skipping logging after 95680 examples to avoid logging too frequently
skipping logging after 95744 examples to avoid logging too frequently
Running evaluation after 95744 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:00, 17.23it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:00, 17.37it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:00, 17.45it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00, 17.41it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:00<00:00, 17.40it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:00<00:00, 17.37it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:00<00:00, 17.31it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.29it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 17.33it/s]
eval after 95744: {'rewards_eval/chosen': '-0.15671', 'rewards_eval/rejected': '-0.51577', 'rewards_eval/accuracies': '0.65234', 'rewards_eval/margins': '0.35906', 'logps_eval/rejected': '-155.03', 'logps_eval/chosen': '-179.43', 'loss/eval': '0.61913'}
creating checkpoint to write to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-95744...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-95744/policy.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-95744/optimizer.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/step-95744/scheduler.pt...
train stats after 95808 examples: {'rewards_train/chosen': '-0.24006', 'rewards_train/rejected': '-0.59379', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.35373', 'logps_train/rejected': '-171.54', 'logps_train/chosen': '-176.31', 'loss/train': '0.61259', 'examples_per_second': '204.22', 'grad_norm': '42.355', 'counters/examples': 95808, 'counters/updates': 1497}
skipping logging after 95872 examples to avoid logging too frequently
skipping logging after 95936 examples to avoid logging too frequently
skipping logging after 96000 examples to avoid logging too frequently
train stats after 96064 examples: {'rewards_train/chosen': '-0.14765', 'rewards_train/rejected': '-0.64987', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.50223', 'logps_train/rejected': '-141.9', 'logps_train/chosen': '-207.24', 'loss/train': '0.57284', 'examples_per_second': '266.25', 'grad_norm': '44.917', 'counters/examples': 96064, 'counters/updates': 1501}
skipping logging after 96128 examples to avoid logging too frequently
skipping logging after 96192 examples to avoid logging too frequently
skipping logging after 96256 examples to avoid logging too frequently
Finished generating 1 epochs on train split
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/LATEST/policy.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/LATEST/optimizer.pt...
writing checkpoint to .cache/laura/pythia160m_dpo_seed0_2024-01-12_14-47-57_115351/LATEST/scheduler.pt...
4 initializing distributed
Creating trainer on process 4 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 4
Loading HH static dataset (train split) from Huggingface...
done
5 initializing distributed
Creating trainer on process 5 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 5
Loading HH static dataset (train split) from Huggingface...
done
1 initializing distributed
Creating trainer on process 1 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 1
Loading HH static dataset (train split) from Huggingface...
done
7 initializing distributed
Creating trainer on process 7 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 7
Loading HH static dataset (train split) from Huggingface...
done
6 initializing distributed
Creating trainer on process 6 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 6
Loading HH static dataset (train split) from Huggingface...
done
2 initializing distributed
Creating trainer on process 2 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 2
Loading HH static dataset (train split) from Huggingface...
done
3 initializing distributed
Creating trainer on process 3 with world size 8
Loading HH static dataset (test split) from Huggingface...
done
Loaded model on rank 3
Loading HH static dataset (train split) from Huggingface...
done
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: \ 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: | 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: / 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: - 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: \ 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: | 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:        counters/examples ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:         counters/updates ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      examples_per_second ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:                grad_norm ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÜ
wandb:        logps_eval/chosen ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÅ
wandb:      logps_eval/rejected ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÅ
wandb:       logps_train/chosen ‚ñá‚ñÖ‚ñà‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÅ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÇ‚ñÖ‚ñÖ
wandb:     logps_train/rejected ‚ñá‚ñÑ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñá‚ñÉ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÇ‚ñá‚ñá‚ñÉ
wandb:                loss/eval ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÇ
wandb:               loss/train ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÅ‚ñà
wandb:  rewards_eval/accuracies ‚ñÅ‚ñá‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá
wandb:      rewards_eval/chosen ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÅ
wandb:     rewards_eval/margins ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà
wandb:    rewards_eval/rejected ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÅ
wandb: rewards_train/accuracies ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñà‚ñÉ
wandb:     rewards_train/chosen ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñÜ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÅ
wandb:    rewards_train/margins ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñÇ
wandb:   rewards_train/rejected ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÉ
wandb: 
wandb: Run summary:
wandb:        counters/examples 96064
wandb:         counters/updates 1501
wandb:      examples_per_second 266.24664
wandb:                grad_norm 44.91736
wandb:        logps_eval/chosen -179.431
wandb:      logps_eval/rejected -155.02516
wandb:       logps_train/chosen -207.23589
wandb:     logps_train/rejected -141.89925
wandb:                loss/eval 0.61913
wandb:               loss/train 0.57284
wandb:  rewards_eval/accuracies 0.65234
wandb:      rewards_eval/chosen -0.15671
wandb:     rewards_eval/margins 0.35906
wandb:    rewards_eval/rejected -0.51577
wandb: rewards_train/accuracies 0.73438
wandb:     rewards_train/chosen -0.14765
wandb:    rewards_train/margins 0.50223
wandb:   rewards_train/rejected -0.64987
wandb: 
wandb: üöÄ View run pythia160m_dpo_seed0 at: https://wandb.ai/lauraomahony999/pythia-dpo/runs/3djpa41v
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: .cache/laura/wandb/run-20240112_144921-3djpa41v/logs
WARNING: eval_every must be divisible by batch_size
Setting eval_every to 11968
no FSDP port specified; using open port for FSDP: 44135
seed: 0
exp_name: pythia410m_dpo_seed0
batch_size: 64
eval_batch_size: 16
debug: false
fsdp_port: 44135
datasets:
- hh_static
wandb:
  enabled: true
  entity: lauraomahony999
  project: pythia-dpo
local_dirs:
- /scr-ssd
- /scr
- .cache
sample_during_eval: false
n_eval_model_samples: 16
do_first_eval: true
local_run_dir: .cache/laura/pythia410m_dpo_seed0_2024-01-12_14-58-09_986894
lr: 1.0e-06
gradient_accumulation_steps: 1
max_grad_norm: 10.0
max_length: 512
max_prompt_length: 256
n_epochs: 1
n_examples: null
n_eval_examples: 256
trainer: FSDPTrainer
optimizer: RMSprop
warmup_steps: 150
activation_checkpointing: false
eval_every: 11968
minimum_log_interval_secs: 1.0
model:
  name_or_path: lomahony/pythia-410m-helpful-sft
  tokenizer_name_or_path: null
  archive: null
  block_name: GPTNeoXLayer
  policy_dtype: float32
  fsdp_policy_mp: null
  reference_dtype: float16
loss:
  name: dpo
  beta: 0.1
  label_smoothing: 0
  reference_free: false

================================================================================
Writing to ip-10-0-222-166:.cache/laura/pythia410m_dpo_seed0_2024-01-12_14-58-09_986894
================================================================================
building policy
Some weights of GPTNeoXForCausalLM were not initialized from the model checkpoint at lomahony/pythia-410m-helpful-sft and are newly initialized: ['gpt_neox.layers.11.attention.bias', 'gpt_neox.layers.22.attention.bias', 'gpt_neox.layers.4.attention.masked_bias', 'gpt_neox.layers.22.attention.masked_bias', 'gpt_neox.layers.6.attention.bias', 'gpt_neox.layers.23.attention.masked_bias', 'gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.20.attention.masked_bias', 'gpt_neox.layers.13.attention.masked_bias', 'gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.14.attention.bias', 'gpt_neox.layers.9.attention.masked_bias', 'gpt_neox.layers.16.attention.bias', 'gpt_neox.layers.8.attention.bias', 'gpt_neox.layers.12.attention.masked_bias', 'gpt_neox.layers.23.attention.bias', 'gpt_neox.layers.19.attention.masked_bias', 'gpt_neox.layers.17.attention.masked_bias', 'gpt_neox.layers.1.attention.bias', 'gpt_neox.layers.5.attention.masked_bias', 'gpt_neox.layers.15.attention.bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.14.attention.masked_bias', 'gpt_neox.layers.7.attention.bias', 'gpt_neox.layers.5.attention.bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.7.attention.masked_bias', 'gpt_neox.layers.6.attention.masked_bias', 'gpt_neox.layers.18.attention.masked_bias', 'gpt_neox.layers.21.attention.masked_bias', 'gpt_neox.layers.8.attention.masked_bias', 'gpt_neox.layers.9.attention.bias', 'gpt_neox.layers.16.attention.masked_bias', 'gpt_neox.layers.10.attention.masked_bias', 'gpt_neox.layers.10.attention.bias', 'gpt_neox.layers.21.attention.bias', 'gpt_neox.layers.18.attention.bias', 'gpt_neox.layers.11.attention.masked_bias', 'gpt_neox.layers.19.attention.bias', 'gpt_neox.layers.12.attention.bias', 'gpt_neox.layers.15.attention.masked_bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.20.attention.bias', 'gpt_neox.layers.17.attention.bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.13.attention.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
building reference model
Some weights of GPTNeoXForCausalLM were not initialized from the model checkpoint at lomahony/pythia-410m-helpful-sft and are newly initialized: ['gpt_neox.layers.11.attention.bias', 'gpt_neox.layers.22.attention.bias', 'gpt_neox.layers.4.attention.masked_bias', 'gpt_neox.layers.22.attention.masked_bias', 'gpt_neox.layers.6.attention.bias', 'gpt_neox.layers.23.attention.masked_bias', 'gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.20.attention.masked_bias', 'gpt_neox.layers.13.attention.masked_bias', 'gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.14.attention.bias', 'gpt_neox.layers.9.attention.masked_bias', 'gpt_neox.layers.16.attention.bias', 'gpt_neox.layers.8.attention.bias', 'gpt_neox.layers.12.attention.masked_bias', 'gpt_neox.layers.23.attention.bias', 'gpt_neox.layers.19.attention.masked_bias', 'gpt_neox.layers.17.attention.masked_bias', 'gpt_neox.layers.1.attention.bias', 'gpt_neox.layers.5.attention.masked_bias', 'gpt_neox.layers.15.attention.bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.14.attention.masked_bias', 'gpt_neox.layers.7.attention.bias', 'gpt_neox.layers.5.attention.bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.7.attention.masked_bias', 'gpt_neox.layers.6.attention.masked_bias', 'gpt_neox.layers.18.attention.masked_bias', 'gpt_neox.layers.21.attention.masked_bias', 'gpt_neox.layers.8.attention.masked_bias', 'gpt_neox.layers.9.attention.bias', 'gpt_neox.layers.16.attention.masked_bias', 'gpt_neox.layers.10.attention.masked_bias', 'gpt_neox.layers.10.attention.bias', 'gpt_neox.layers.21.attention.bias', 'gpt_neox.layers.18.attention.bias', 'gpt_neox.layers.11.attention.masked_bias', 'gpt_neox.layers.19.attention.bias', 'gpt_neox.layers.12.attention.bias', 'gpt_neox.layers.15.attention.masked_bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.20.attention.bias', 'gpt_neox.layers.17.attention.bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.13.attention.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
starting 8 processes for FSDP training
setting RLIMIT_NOFILE soft limit to 131072 from 8192
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
wandb: Currently logged in as: lauraomahony999. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in .cache/laura/wandb/run-20240112_145939-ocfa6xx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pythia410m_dpo_seed0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lauraomahony999/pythia-dpo
wandb: üöÄ View run at https://wandb.ai/lauraomahony999/pythia-dpo/runs/ocfa6xx4
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
0 initializing distributed
Creating trainer on process 0 with world size 8
Loading tokenizer lomahony/pythia-410m-helpful-sft
Loaded train data iterator
Loading HH static dataset (test split) from Huggingface...
done
Processing HH static:   0%|          | 0/5103 [00:00<?, ?it/s]Processing HH static:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2834/5103 [00:00<00:00, 28327.33it/s]Processing HH static: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5103/5103 [00:00<00:00, 28491.62it/s]
FINISHED 256 EXAMPLES on test split
Loaded 16 eval batches of size 16
Sharding policy...
Sharding reference model...
Loaded model on rank 0
Using RMSprop optimizer
Loading HH static dataset (train split) from Huggingface...
done
Processing HH static:   0%|          | 0/96256 [00:00<?, ?it/s]Processing HH static:   0%|          | 117/96256 [00:00<01:24, 1131.05it/s]Processing HH static:   3%|‚ñé         | 2727/96256 [00:00<00:05, 15610.75it/s]Processing HH static:   4%|‚ñç         | 4309/96256 [00:00<00:09, 9482.23it/s] Processing HH static:   7%|‚ñã         | 7181/96256 [00:00<00:05, 14886.75it/s]Processing HH static:  10%|‚ñà         | 10093/96256 [00:00<00:04, 18962.65it/s]Processing HH static:  13%|‚ñà‚ñé        | 12989/96256 [00:00<00:03, 21863.45it/s]Processing HH static:  17%|‚ñà‚ñã        | 15927/96256 [00:00<00:03, 24064.86it/s]Processing HH static:  20%|‚ñà‚ñâ        | 18832/96256 [00:00<00:03, 25535.97it/s]Processing HH static:  23%|‚ñà‚ñà‚ñé       | 21675/96256 [00:01<00:02, 26392.89it/s]Processing HH static:  26%|‚ñà‚ñà‚ñå       | 24588/96256 [00:01<00:02, 27206.97it/s]Processing HH static:  28%|‚ñà‚ñà‚ñä       | 27387/96256 [00:01<00:02, 27403.88it/s]Processing HH static:  31%|‚ñà‚ñà‚ñà‚ñè      | 30278/96256 [00:01<00:02, 27852.47it/s]Processing HH static:  34%|‚ñà‚ñà‚ñà‚ñç      | 33184/96256 [00:01<00:02, 28211.11it/s]Processing HH static:  37%|‚ñà‚ñà‚ñà‚ñã      | 36033/96256 [00:01<00:03, 16815.82it/s]Processing HH static:  40%|‚ñà‚ñà‚ñà‚ñà      | 38887/96256 [00:01<00:02, 19190.82it/s]Processing HH static:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 41764/96256 [00:01<00:02, 21339.37it/s]Processing HH static:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 44578/96256 [00:02<00:02, 22989.92it/s]Processing HH static:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 47357/96256 [00:02<00:02, 24223.18it/s]Processing HH static:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 50130/96256 [00:02<00:01, 25138.81it/s]Processing HH static:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 52836/96256 [00:02<00:02, 14591.74it/s]Processing HH static:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 55608/96256 [00:02<00:02, 17003.68it/s]Processing HH static:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 58166/96256 [00:02<00:02, 18785.70it/s]Processing HH static:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 60934/96256 [00:02<00:01, 20822.10it/s]Processing HH static:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 63654/96256 [00:03<00:01, 22391.14it/s]Processing HH static:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 66434/96256 [00:03<00:01, 23798.26it/s]Processing HH static:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 69210/96256 [00:03<00:01, 24871.63it/s]Processing HH static:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 71972/96256 [00:03<00:00, 25636.37it/s]Processing HH static:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 74672/96256 [00:03<00:01, 11771.29it/s]Processing HH static:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 76716/96256 [00:04<00:03, 6032.37it/s] Processing HH static:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 78219/96256 [00:05<00:03, 4711.94it/s]Processing HH static:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 79347/96256 [00:05<00:04, 4119.38it/s]Processing HH static:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 80215/96256 [00:06<00:04, 3765.26it/s]Processing HH static:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 80901/96256 [00:06<00:04, 3515.74it/s]Processing HH static:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 81459/96256 [00:06<00:04, 3326.33it/s]Processing HH static:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 81927/96256 [00:06<00:04, 3100.76it/s]Processing HH static:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 82323/96256 [00:06<00:04, 2918.70it/s]Processing HH static:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 82667/96256 [00:07<00:04, 2748.50it/s]Processing HH static:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 82971/96256 [00:07<00:04, 2692.20it/s]Processing HH static:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 83258/96256 [00:07<00:04, 2689.29it/s]Processing HH static:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 83539/96256 [00:07<00:04, 2544.02it/s]Processing HH static:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 83799/96256 [00:07<00:05, 2447.00it/s]Processing HH static:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 84046/96256 [00:07<00:05, 2381.67it/s]Processing HH static:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 84284/96256 [00:07<00:05, 2321.62it/s]Processing HH static:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 84516/96256 [00:07<00:05, 2317.27it/s]Processing HH static:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 84747/96256 [00:08<00:04, 2314.33it/s]Processing HH static:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 84978/96256 [00:08<00:04, 2278.93it/s]Processing HH static:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 85206/96256 [00:08<00:04, 2224.62it/s]Processing HH static:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 85428/96256 [00:08<00:04, 2196.36it/s]Processing HH static:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 85648/96256 [00:08<00:04, 2181.07it/s]Processing HH static:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 85886/96256 [00:08<00:04, 2233.59it/s]Processing HH static:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 86110/96256 [00:08<00:04, 2227.29it/s]Processing HH static:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 86335/96256 [00:08<00:04, 2229.13it/s]Processing HH static:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 86568/96256 [00:08<00:04, 2256.16it/s]Processing HH static:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 86799/96256 [00:08<00:04, 2267.97it/s]Processing HH static:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 87026/96256 [00:09<00:04, 2233.80it/s]Processing HH static:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 87267/96256 [00:09<00:03, 2282.49it/s]Processing HH static:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 87496/96256 [00:09<00:03, 2254.95it/s]Processing HH static:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 87722/96256 [00:09<00:03, 2245.68it/s]Processing HH static:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 88060/96256 [00:09<00:03, 2580.15it/s]Processing HH static:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 88319/96256 [00:09<00:03, 2411.08it/s]Processing HH static:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 88563/96256 [00:09<00:03, 2412.43it/s]Processing HH static:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 88807/96256 [00:09<00:03, 2359.32it/s]Processing HH static:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 89045/96256 [00:09<00:03, 2297.34it/s]Processing HH static:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 89276/96256 [00:10<00:03, 2235.84it/s]Processing HH static:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 89501/96256 [00:10<00:03, 2239.36it/s]Processing HH static:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 89746/96256 [00:10<00:02, 2297.51it/s]Processing HH static:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 89977/96256 [00:10<00:02, 2269.16it/s]Processing HH static:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 90212/96256 [00:10<00:02, 2292.52it/s]Processing HH static:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 90442/96256 [00:10<00:02, 2259.64it/s]Processing HH static:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 90669/96256 [00:10<00:02, 2224.14it/s]Processing HH static:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 90895/96256 [00:10<00:02, 2234.24it/s]Processing HH static:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 91119/96256 [00:10<00:02, 2173.64it/s]Processing HH static:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 91339/96256 [00:10<00:02, 2180.29it/s]Processing HH static:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 91576/96256 [00:11<00:02, 2230.90it/s]Processing HH static:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 91818/96256 [00:11<00:01, 2284.98it/s]Processing HH static:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 92047/96256 [00:11<00:01, 2273.65it/s]Processing HH static:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 92275/96256 [00:11<00:01, 2235.95it/s]Processing HH static:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 92590/96256 [00:11<00:01, 2504.12it/s]Processing HH static:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 92935/96256 [00:11<00:01, 2782.50it/s]Processing HH static:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 93215/96256 [00:11<00:01, 2632.21it/s]Processing HH static:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 93481/96256 [00:11<00:01, 2472.12it/s]Processing HH static:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 93732/96256 [00:11<00:01, 2411.63it/s]Processing HH static:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 94001/96256 [00:12<00:00, 2474.18it/s]Processing HH static:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 94251/96256 [00:12<00:00, 2419.73it/s]Processing HH static:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 94501/96256 [00:12<00:00, 2439.56it/s]Processing HH static:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 94782/96256 [00:12<00:00, 2544.40it/s]Processing HH static:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 95038/96256 [00:12<00:00, 2433.37it/s]Processing HH static:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 95358/96256 [00:12<00:00, 2642.56it/s]Processing HH static: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 95833/96256 [00:12<00:00, 3248.07it/s]Processing HH static: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 96162/96256 [00:12<00:00, 3208.74it/s]Processing HH static: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96256/96256 [00:12<00:00, 7529.33it/s]
Running evaluation after 0 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:   6%|‚ñã         | 1/16 [00:01<00:20,  1.35s/it]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:01<00:08,  1.57it/s]Computing eval metrics:  19%|‚ñà‚ñâ        | 3/16 [00:01<00:05,  2.51it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:01<00:03,  3.48it/s]Computing eval metrics:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:01<00:02,  4.39it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:01<00:01,  5.32it/s]Computing eval metrics:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:02<00:01,  6.02it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:02<00:01,  6.56it/s]Computing eval metrics:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:02<00:00,  7.14it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:02<00:00,  7.51it/s]Computing eval metrics:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:02<00:00,  7.66it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:02<00:00,  7.98it/s]Computing eval metrics:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:02<00:00,  8.14it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:02<00:00,  8.18it/s]Computing eval metrics:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [00:03<00:00,  8.27it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:03<00:00,  8.38it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:03<00:00,  5.10it/s]
eval after 0: {'rewards_eval/chosen': '0.0016929', 'rewards_eval/rejected': '-9.4888e-05', 'rewards_eval/accuracies': '0.55859', 'rewards_eval/margins': '0.0017878', 'logps_eval/rejected': '-125.99', 'logps_eval/chosen': '-147.78', 'loss/eval': '0.69229'}
train stats after 64 examples: {'rewards_train/chosen': '0.0014215', 'rewards_train/rejected': '0.00078263', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.00063891', 'logps_train/rejected': '-143.53', 'logps_train/chosen': '-144.76', 'loss/train': '0.69288', 'examples_per_second': '72.716', 'grad_norm': '21.148', 'counters/examples': 64, 'counters/updates': 1}
train stats after 128 examples: {'rewards_train/chosen': '-0.0012002', 'rewards_train/rejected': '-0.0013423', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.00014207', 'logps_train/rejected': '-139.89', 'logps_train/chosen': '-150.17', 'loss/train': '0.69311', 'examples_per_second': '52.14', 'grad_norm': '20.921', 'counters/examples': 128, 'counters/updates': 2}
train stats after 192 examples: {'rewards_train/chosen': '0.00037973', 'rewards_train/rejected': '0.0013546', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.00097491', 'logps_train/rejected': '-125.71', 'logps_train/chosen': '-145.08', 'loss/train': '0.69369', 'examples_per_second': '67.82', 'grad_norm': '20.976', 'counters/examples': 192, 'counters/updates': 3}
skipping logging after 256 examples to avoid logging too frequently
train stats after 320 examples: {'rewards_train/chosen': '0.0009676', 'rewards_train/rejected': '-0.00084501', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.0018126', 'logps_train/rejected': '-151.1', 'logps_train/chosen': '-148.16', 'loss/train': '0.6923', 'examples_per_second': '110.87', 'grad_norm': '22.007', 'counters/examples': 320, 'counters/updates': 5}
skipping logging after 384 examples to avoid logging too frequently
train stats after 448 examples: {'rewards_train/chosen': '-0.0040741', 'rewards_train/rejected': '-0.0018514', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.0022227', 'logps_train/rejected': '-124.44', 'logps_train/chosen': '-163.35', 'loss/train': '0.6943', 'examples_per_second': '114.28', 'grad_norm': '20.727', 'counters/examples': 448, 'counters/updates': 7}
skipping logging after 512 examples to avoid logging too frequently
train stats after 576 examples: {'rewards_train/chosen': '0.0033823', 'rewards_train/rejected': '-0.0017829', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.0051652', 'logps_train/rejected': '-127.53', 'logps_train/chosen': '-172.32', 'loss/train': '0.69063', 'examples_per_second': '115.26', 'grad_norm': '22.971', 'counters/examples': 576, 'counters/updates': 9}
skipping logging after 640 examples to avoid logging too frequently
train stats after 704 examples: {'rewards_train/chosen': '-0.00090856', 'rewards_train/rejected': '-0.0014038', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.00049526', 'logps_train/rejected': '-129.2', 'logps_train/chosen': '-141.74', 'loss/train': '0.69294', 'examples_per_second': '124.2', 'grad_norm': '19.917', 'counters/examples': 704, 'counters/updates': 11}
skipping logging after 768 examples to avoid logging too frequently
train stats after 832 examples: {'rewards_train/chosen': '-0.0017039', 'rewards_train/rejected': '-0.0015759', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.00012806', 'logps_train/rejected': '-124.61', 'logps_train/chosen': '-170.34', 'loss/train': '0.69325', 'examples_per_second': '111.79', 'grad_norm': '20.568', 'counters/examples': 832, 'counters/updates': 13}
skipping logging after 896 examples to avoid logging too frequently
train stats after 960 examples: {'rewards_train/chosen': '0.0013945', 'rewards_train/rejected': '-0.0037655', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.0051601', 'logps_train/rejected': '-136.85', 'logps_train/chosen': '-157.27', 'loss/train': '0.69062', 'examples_per_second': '114.82', 'grad_norm': '20.677', 'counters/examples': 960, 'counters/updates': 15}
skipping logging after 1024 examples to avoid logging too frequently
train stats after 1088 examples: {'rewards_train/chosen': '-0.0018697', 'rewards_train/rejected': '-0.0063039', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.0044342', 'logps_train/rejected': '-110.76', 'logps_train/chosen': '-158.76', 'loss/train': '0.69099', 'examples_per_second': '110.37', 'grad_norm': '19.967', 'counters/examples': 1088, 'counters/updates': 17}
skipping logging after 1152 examples to avoid logging too frequently
train stats after 1216 examples: {'rewards_train/chosen': '0.0019382', 'rewards_train/rejected': '-0.0077624', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.0097006', 'logps_train/rejected': '-150.62', 'logps_train/chosen': '-166.31', 'loss/train': '0.68836', 'examples_per_second': '111.68', 'grad_norm': '21.57', 'counters/examples': 1216, 'counters/updates': 19}
skipping logging after 1280 examples to avoid logging too frequently
train stats after 1344 examples: {'rewards_train/chosen': '-0.0036428', 'rewards_train/rejected': '-0.0089299', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.0052871', 'logps_train/rejected': '-136.12', 'logps_train/chosen': '-195.02', 'loss/train': '0.69061', 'examples_per_second': '111.56', 'grad_norm': '21.694', 'counters/examples': 1344, 'counters/updates': 21}
skipping logging after 1408 examples to avoid logging too frequently
train stats after 1472 examples: {'rewards_train/chosen': '-0.0029608', 'rewards_train/rejected': '-0.018799', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.015839', 'logps_train/rejected': '-144.51', 'logps_train/chosen': '-150.22', 'loss/train': '0.68534', 'examples_per_second': '111.2', 'grad_norm': '21.077', 'counters/examples': 1472, 'counters/updates': 23}
skipping logging after 1536 examples to avoid logging too frequently
train stats after 1600 examples: {'rewards_train/chosen': '-0.0038194', 'rewards_train/rejected': '-0.014926', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.011107', 'logps_train/rejected': '-157.54', 'logps_train/chosen': '-162.23', 'loss/train': '0.68779', 'examples_per_second': '109.92', 'grad_norm': '23.065', 'counters/examples': 1600, 'counters/updates': 25}
skipping logging after 1664 examples to avoid logging too frequently
train stats after 1728 examples: {'rewards_train/chosen': '-0.0079611', 'rewards_train/rejected': '-0.024023', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.016062', 'logps_train/rejected': '-122.58', 'logps_train/chosen': '-143.31', 'loss/train': '0.68549', 'examples_per_second': '124.85', 'grad_norm': '20.537', 'counters/examples': 1728, 'counters/updates': 27}
skipping logging after 1792 examples to avoid logging too frequently
train stats after 1856 examples: {'rewards_train/chosen': '-0.013799', 'rewards_train/rejected': '-0.025281', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.011482', 'logps_train/rejected': '-135.58', 'logps_train/chosen': '-148.72', 'loss/train': '0.68775', 'examples_per_second': '115.56', 'grad_norm': '20.8', 'counters/examples': 1856, 'counters/updates': 29}
skipping logging after 1920 examples to avoid logging too frequently
train stats after 1984 examples: {'rewards_train/chosen': '-0.0026306', 'rewards_train/rejected': '-0.032596', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.029966', 'logps_train/rejected': '-118.04', 'logps_train/chosen': '-140', 'loss/train': '0.67873', 'examples_per_second': '114.52', 'grad_norm': '19.839', 'counters/examples': 1984, 'counters/updates': 31}
skipping logging after 2048 examples to avoid logging too frequently
train stats after 2112 examples: {'rewards_train/chosen': '-0.010085', 'rewards_train/rejected': '-0.043833', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.033748', 'logps_train/rejected': '-131.19', 'logps_train/chosen': '-122.64', 'loss/train': '0.67711', 'examples_per_second': '114.22', 'grad_norm': '19.688', 'counters/examples': 2112, 'counters/updates': 33}
skipping logging after 2176 examples to avoid logging too frequently
train stats after 2240 examples: {'rewards_train/chosen': '0.0022676', 'rewards_train/rejected': '-0.030438', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.032705', 'logps_train/rejected': '-136.84', 'logps_train/chosen': '-153.97', 'loss/train': '0.67757', 'examples_per_second': '115.74', 'grad_norm': '20.798', 'counters/examples': 2240, 'counters/updates': 35}
skipping logging after 2304 examples to avoid logging too frequently
train stats after 2368 examples: {'rewards_train/chosen': '-0.015657', 'rewards_train/rejected': '-0.050858', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.035202', 'logps_train/rejected': '-118.82', 'logps_train/chosen': '-138.07', 'loss/train': '0.67652', 'examples_per_second': '115.66', 'grad_norm': '19.874', 'counters/examples': 2368, 'counters/updates': 37}
skipping logging after 2432 examples to avoid logging too frequently
train stats after 2496 examples: {'rewards_train/chosen': '-0.010034', 'rewards_train/rejected': '-0.056995', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.046961', 'logps_train/rejected': '-139.94', 'logps_train/chosen': '-141.96', 'loss/train': '0.67105', 'examples_per_second': '115.51', 'grad_norm': '20.682', 'counters/examples': 2496, 'counters/updates': 39}
skipping logging after 2560 examples to avoid logging too frequently
train stats after 2624 examples: {'rewards_train/chosen': '-0.010678', 'rewards_train/rejected': '-0.065246', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.054568', 'logps_train/rejected': '-124.44', 'logps_train/chosen': '-163.2', 'loss/train': '0.66746', 'examples_per_second': '114.86', 'grad_norm': '20.456', 'counters/examples': 2624, 'counters/updates': 41}
skipping logging after 2688 examples to avoid logging too frequently
train stats after 2752 examples: {'rewards_train/chosen': '-0.040083', 'rewards_train/rejected': '-0.066599', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.026516', 'logps_train/rejected': '-130.75', 'logps_train/chosen': '-154.99', 'loss/train': '0.68138', 'examples_per_second': '117.13', 'grad_norm': '20.755', 'counters/examples': 2752, 'counters/updates': 43}
skipping logging after 2816 examples to avoid logging too frequently
train stats after 2880 examples: {'rewards_train/chosen': '-0.023844', 'rewards_train/rejected': '-0.069328', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.045484', 'logps_train/rejected': '-137.1', 'logps_train/chosen': '-169.88', 'loss/train': '0.67248', 'examples_per_second': '115.06', 'grad_norm': '21.342', 'counters/examples': 2880, 'counters/updates': 45}
skipping logging after 2944 examples to avoid logging too frequently
train stats after 3008 examples: {'rewards_train/chosen': '-0.0061078', 'rewards_train/rejected': '-0.067809', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.061701', 'logps_train/rejected': '-129.83', 'logps_train/chosen': '-144.22', 'loss/train': '0.66441', 'examples_per_second': '119.88', 'grad_norm': '20.643', 'counters/examples': 3008, 'counters/updates': 47}
skipping logging after 3072 examples to avoid logging too frequently
train stats after 3136 examples: {'rewards_train/chosen': '-0.066677', 'rewards_train/rejected': '-0.11107', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.044391', 'logps_train/rejected': '-117.99', 'logps_train/chosen': '-137.08', 'loss/train': '0.67386', 'examples_per_second': '125.31', 'grad_norm': '19.961', 'counters/examples': 3136, 'counters/updates': 49}
skipping logging after 3200 examples to avoid logging too frequently
train stats after 3264 examples: {'rewards_train/chosen': '-0.014181', 'rewards_train/rejected': '-0.077907', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.063726', 'logps_train/rejected': '-140.66', 'logps_train/chosen': '-164.39', 'loss/train': '0.66618', 'examples_per_second': '111.21', 'grad_norm': '21.07', 'counters/examples': 3264, 'counters/updates': 51}
skipping logging after 3328 examples to avoid logging too frequently
train stats after 3392 examples: {'rewards_train/chosen': '-0.013512', 'rewards_train/rejected': '-0.13335', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.11984', 'logps_train/rejected': '-127.59', 'logps_train/chosen': '-148.21', 'loss/train': '0.64159', 'examples_per_second': '123.39', 'grad_norm': '19.17', 'counters/examples': 3392, 'counters/updates': 53}
skipping logging after 3456 examples to avoid logging too frequently
train stats after 3520 examples: {'rewards_train/chosen': '-0.015452', 'rewards_train/rejected': '-0.13527', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.11982', 'logps_train/rejected': '-149.55', 'logps_train/chosen': '-158.61', 'loss/train': '0.64119', 'examples_per_second': '111.25', 'grad_norm': '20.678', 'counters/examples': 3520, 'counters/updates': 55}
skipping logging after 3584 examples to avoid logging too frequently
train stats after 3648 examples: {'rewards_train/chosen': '-0.042077', 'rewards_train/rejected': '-0.096712', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.054635', 'logps_train/rejected': '-136.3', 'logps_train/chosen': '-144.53', 'loss/train': '0.6717', 'examples_per_second': '115.59', 'grad_norm': '21.71', 'counters/examples': 3648, 'counters/updates': 57}
skipping logging after 3712 examples to avoid logging too frequently
train stats after 3776 examples: {'rewards_train/chosen': '0.020701', 'rewards_train/rejected': '-0.10411', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.12481', 'logps_train/rejected': '-142.69', 'logps_train/chosen': '-160.44', 'loss/train': '0.63941', 'examples_per_second': '114.53', 'grad_norm': '21.21', 'counters/examples': 3776, 'counters/updates': 59}
skipping logging after 3840 examples to avoid logging too frequently
train stats after 3904 examples: {'rewards_train/chosen': '-0.042954', 'rewards_train/rejected': '-0.084219', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.041265', 'logps_train/rejected': '-127.09', 'logps_train/chosen': '-151.71', 'loss/train': '0.68029', 'examples_per_second': '115.82', 'grad_norm': '22.205', 'counters/examples': 3904, 'counters/updates': 61}
skipping logging after 3968 examples to avoid logging too frequently
train stats after 4032 examples: {'rewards_train/chosen': '-0.048416', 'rewards_train/rejected': '-0.14614', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.097728', 'logps_train/rejected': '-129.92', 'logps_train/chosen': '-138.63', 'loss/train': '0.65406', 'examples_per_second': '115.02', 'grad_norm': '20.157', 'counters/examples': 4032, 'counters/updates': 63}
skipping logging after 4096 examples to avoid logging too frequently
train stats after 4160 examples: {'rewards_train/chosen': '-0.019159', 'rewards_train/rejected': '-0.11537', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.09621', 'logps_train/rejected': '-134.1', 'logps_train/chosen': '-153.33', 'loss/train': '0.65461', 'examples_per_second': '115.15', 'grad_norm': '20.367', 'counters/examples': 4160, 'counters/updates': 65}
skipping logging after 4224 examples to avoid logging too frequently
train stats after 4288 examples: {'rewards_train/chosen': '-0.022556', 'rewards_train/rejected': '-0.14783', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12527', 'logps_train/rejected': '-139.12', 'logps_train/chosen': '-134.58', 'loss/train': '0.64103', 'examples_per_second': '110.32', 'grad_norm': '19.921', 'counters/examples': 4288, 'counters/updates': 67}
skipping logging after 4352 examples to avoid logging too frequently
train stats after 4416 examples: {'rewards_train/chosen': '-0.04034', 'rewards_train/rejected': '-0.12376', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.083416', 'logps_train/rejected': '-133.39', 'logps_train/chosen': '-145.48', 'loss/train': '0.66319', 'examples_per_second': '109.66', 'grad_norm': '20.871', 'counters/examples': 4416, 'counters/updates': 69}
skipping logging after 4480 examples to avoid logging too frequently
train stats after 4544 examples: {'rewards_train/chosen': '-0.059511', 'rewards_train/rejected': '-0.2159', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.15639', 'logps_train/rejected': '-129.54', 'logps_train/chosen': '-142.98', 'loss/train': '0.63064', 'examples_per_second': '111.63', 'grad_norm': '20.42', 'counters/examples': 4544, 'counters/updates': 71}
skipping logging after 4608 examples to avoid logging too frequently
train stats after 4672 examples: {'rewards_train/chosen': '-0.037752', 'rewards_train/rejected': '-0.12226', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.084506', 'logps_train/rejected': '-130.38', 'logps_train/chosen': '-137.84', 'loss/train': '0.66155', 'examples_per_second': '111.06', 'grad_norm': '19.073', 'counters/examples': 4672, 'counters/updates': 73}
skipping logging after 4736 examples to avoid logging too frequently
train stats after 4800 examples: {'rewards_train/chosen': '0.0038956', 'rewards_train/rejected': '-0.14445', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.14835', 'logps_train/rejected': '-116.52', 'logps_train/chosen': '-124.39', 'loss/train': '0.63486', 'examples_per_second': '116.66', 'grad_norm': '18.749', 'counters/examples': 4800, 'counters/updates': 75}
skipping logging after 4864 examples to avoid logging too frequently
train stats after 4928 examples: {'rewards_train/chosen': '-0.14887', 'rewards_train/rejected': '-0.27183', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.12296', 'logps_train/rejected': '-142.2', 'logps_train/chosen': '-147.78', 'loss/train': '0.65156', 'examples_per_second': '114.63', 'grad_norm': '20.966', 'counters/examples': 4928, 'counters/updates': 77}
skipping logging after 4992 examples to avoid logging too frequently
train stats after 5056 examples: {'rewards_train/chosen': '-0.10389', 'rewards_train/rejected': '-0.2806', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.17671', 'logps_train/rejected': '-149.95', 'logps_train/chosen': '-132.17', 'loss/train': '0.63115', 'examples_per_second': '115.35', 'grad_norm': '20.103', 'counters/examples': 5056, 'counters/updates': 79}
skipping logging after 5120 examples to avoid logging too frequently
train stats after 5184 examples: {'rewards_train/chosen': '-0.017527', 'rewards_train/rejected': '-0.16398', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.14645', 'logps_train/rejected': '-128.61', 'logps_train/chosen': '-165.85', 'loss/train': '0.63816', 'examples_per_second': '110.92', 'grad_norm': '21.247', 'counters/examples': 5184, 'counters/updates': 81}
skipping logging after 5248 examples to avoid logging too frequently
train stats after 5312 examples: {'rewards_train/chosen': '-0.085605', 'rewards_train/rejected': '-0.21083', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.12523', 'logps_train/rejected': '-134.17', 'logps_train/chosen': '-147.15', 'loss/train': '0.65481', 'examples_per_second': '113.02', 'grad_norm': '21.371', 'counters/examples': 5312, 'counters/updates': 83}
skipping logging after 5376 examples to avoid logging too frequently
train stats after 5440 examples: {'rewards_train/chosen': '-0.088738', 'rewards_train/rejected': '-0.24224', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.1535', 'logps_train/rejected': '-133.55', 'logps_train/chosen': '-131.17', 'loss/train': '0.64869', 'examples_per_second': '117.07', 'grad_norm': '20.737', 'counters/examples': 5440, 'counters/updates': 85}
skipping logging after 5504 examples to avoid logging too frequently
train stats after 5568 examples: {'rewards_train/chosen': '-0.12697', 'rewards_train/rejected': '-0.35744', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.23047', 'logps_train/rejected': '-116.04', 'logps_train/chosen': '-126.51', 'loss/train': '0.60852', 'examples_per_second': '115.23', 'grad_norm': '18.712', 'counters/examples': 5568, 'counters/updates': 87}
skipping logging after 5632 examples to avoid logging too frequently
train stats after 5696 examples: {'rewards_train/chosen': '-0.1455', 'rewards_train/rejected': '-0.34012', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.19462', 'logps_train/rejected': '-151.11', 'logps_train/chosen': '-158.8', 'loss/train': '0.63865', 'examples_per_second': '113.99', 'grad_norm': '22.433', 'counters/examples': 5696, 'counters/updates': 89}
skipping logging after 5760 examples to avoid logging too frequently
train stats after 5824 examples: {'rewards_train/chosen': '-0.056335', 'rewards_train/rejected': '-0.24945', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.19312', 'logps_train/rejected': '-150.17', 'logps_train/chosen': '-174.49', 'loss/train': '0.62799', 'examples_per_second': '115.76', 'grad_norm': '21.605', 'counters/examples': 5824, 'counters/updates': 91}
skipping logging after 5888 examples to avoid logging too frequently
train stats after 5952 examples: {'rewards_train/chosen': '-0.18247', 'rewards_train/rejected': '-0.30073', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.11826', 'logps_train/rejected': '-129.97', 'logps_train/chosen': '-136.81', 'loss/train': '0.65874', 'examples_per_second': '120.73', 'grad_norm': '20.521', 'counters/examples': 5952, 'counters/updates': 93}
skipping logging after 6016 examples to avoid logging too frequently
train stats after 6080 examples: {'rewards_train/chosen': '-0.22004', 'rewards_train/rejected': '-0.23244', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0124', 'logps_train/rejected': '-151.29', 'logps_train/chosen': '-163.99', 'loss/train': '0.71786', 'examples_per_second': '115.05', 'grad_norm': '25.413', 'counters/examples': 6080, 'counters/updates': 95}
skipping logging after 6144 examples to avoid logging too frequently
train stats after 6208 examples: {'rewards_train/chosen': '-0.19153', 'rewards_train/rejected': '-0.33297', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.14144', 'logps_train/rejected': '-138.48', 'logps_train/chosen': '-155.54', 'loss/train': '0.64756', 'examples_per_second': '120.49', 'grad_norm': '22.034', 'counters/examples': 6208, 'counters/updates': 97}
skipping logging after 6272 examples to avoid logging too frequently
train stats after 6336 examples: {'rewards_train/chosen': '-0.038822', 'rewards_train/rejected': '-0.24047', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.20165', 'logps_train/rejected': '-132.17', 'logps_train/chosen': '-157.81', 'loss/train': '0.62798', 'examples_per_second': '115.68', 'grad_norm': '22.85', 'counters/examples': 6336, 'counters/updates': 99}
skipping logging after 6400 examples to avoid logging too frequently
train stats after 6464 examples: {'rewards_train/chosen': '-0.18231', 'rewards_train/rejected': '-0.42503', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.24272', 'logps_train/rejected': '-128.69', 'logps_train/chosen': '-147.15', 'loss/train': '0.60843', 'examples_per_second': '115.88', 'grad_norm': '20.27', 'counters/examples': 6464, 'counters/updates': 101}
skipping logging after 6528 examples to avoid logging too frequently
train stats after 6592 examples: {'rewards_train/chosen': '-0.14647', 'rewards_train/rejected': '-0.25414', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10767', 'logps_train/rejected': '-160.92', 'logps_train/chosen': '-142.62', 'loss/train': '0.66918', 'examples_per_second': '115.59', 'grad_norm': '23.375', 'counters/examples': 6592, 'counters/updates': 103}
skipping logging after 6656 examples to avoid logging too frequently
train stats after 6720 examples: {'rewards_train/chosen': '-0.12339', 'rewards_train/rejected': '-0.31933', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.19594', 'logps_train/rejected': '-125.47', 'logps_train/chosen': '-138.87', 'loss/train': '0.62846', 'examples_per_second': '117.29', 'grad_norm': '20.719', 'counters/examples': 6720, 'counters/updates': 105}
skipping logging after 6784 examples to avoid logging too frequently
train stats after 6848 examples: {'rewards_train/chosen': '-0.17792', 'rewards_train/rejected': '-0.33304', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15511', 'logps_train/rejected': '-147.91', 'logps_train/chosen': '-157.7', 'loss/train': '0.65347', 'examples_per_second': '115.64', 'grad_norm': '23.141', 'counters/examples': 6848, 'counters/updates': 107}
skipping logging after 6912 examples to avoid logging too frequently
train stats after 6976 examples: {'rewards_train/chosen': '-0.26762', 'rewards_train/rejected': '-0.44493', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17731', 'logps_train/rejected': '-140.54', 'logps_train/chosen': '-176.29', 'loss/train': '0.65205', 'examples_per_second': '113', 'grad_norm': '23.79', 'counters/examples': 6976, 'counters/updates': 109}
skipping logging after 7040 examples to avoid logging too frequently
train stats after 7104 examples: {'rewards_train/chosen': '-0.22311', 'rewards_train/rejected': '-0.40444', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.18133', 'logps_train/rejected': '-118.03', 'logps_train/chosen': '-140.52', 'loss/train': '0.65232', 'examples_per_second': '113.72', 'grad_norm': '20.54', 'counters/examples': 7104, 'counters/updates': 111}
skipping logging after 7168 examples to avoid logging too frequently
train stats after 7232 examples: {'rewards_train/chosen': '-0.15997', 'rewards_train/rejected': '-0.45996', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.29999', 'logps_train/rejected': '-119.08', 'logps_train/chosen': '-174.17', 'loss/train': '0.58786', 'examples_per_second': '124.42', 'grad_norm': '20.305', 'counters/examples': 7232, 'counters/updates': 113}
skipping logging after 7296 examples to avoid logging too frequently
train stats after 7360 examples: {'rewards_train/chosen': '-0.21609', 'rewards_train/rejected': '-0.52846', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.31238', 'logps_train/rejected': '-122.95', 'logps_train/chosen': '-147.57', 'loss/train': '0.58833', 'examples_per_second': '119.69', 'grad_norm': '19.176', 'counters/examples': 7360, 'counters/updates': 115}
skipping logging after 7424 examples to avoid logging too frequently
train stats after 7488 examples: {'rewards_train/chosen': '-0.21798', 'rewards_train/rejected': '-0.32348', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10551', 'logps_train/rejected': '-133.39', 'logps_train/chosen': '-169.57', 'loss/train': '0.67984', 'examples_per_second': '111.18', 'grad_norm': '25.208', 'counters/examples': 7488, 'counters/updates': 117}
skipping logging after 7552 examples to avoid logging too frequently
train stats after 7616 examples: {'rewards_train/chosen': '-0.26137', 'rewards_train/rejected': '-0.36787', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1065', 'logps_train/rejected': '-132.33', 'logps_train/chosen': '-137.81', 'loss/train': '0.67795', 'examples_per_second': '115.47', 'grad_norm': '23.601', 'counters/examples': 7616, 'counters/updates': 119}
skipping logging after 7680 examples to avoid logging too frequently
train stats after 7744 examples: {'rewards_train/chosen': '-0.17752', 'rewards_train/rejected': '-0.47978', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.30226', 'logps_train/rejected': '-116.02', 'logps_train/chosen': '-164.24', 'loss/train': '0.59983', 'examples_per_second': '113.46', 'grad_norm': '20.184', 'counters/examples': 7744, 'counters/updates': 121}
skipping logging after 7808 examples to avoid logging too frequently
train stats after 7872 examples: {'rewards_train/chosen': '-0.26936', 'rewards_train/rejected': '-0.41921', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.14985', 'logps_train/rejected': '-145.16', 'logps_train/chosen': '-148.27', 'loss/train': '0.66964', 'examples_per_second': '115.6', 'grad_norm': '23.481', 'counters/examples': 7872, 'counters/updates': 123}
skipping logging after 7936 examples to avoid logging too frequently
train stats after 8000 examples: {'rewards_train/chosen': '-0.054346', 'rewards_train/rejected': '-0.28423', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.22988', 'logps_train/rejected': '-130.82', 'logps_train/chosen': '-146.83', 'loss/train': '0.6172', 'examples_per_second': '125.52', 'grad_norm': '20.667', 'counters/examples': 8000, 'counters/updates': 125}
skipping logging after 8064 examples to avoid logging too frequently
train stats after 8128 examples: {'rewards_train/chosen': '-0.20255', 'rewards_train/rejected': '-0.34257', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.14002', 'logps_train/rejected': '-153.75', 'logps_train/chosen': '-162.43', 'loss/train': '0.67316', 'examples_per_second': '115.54', 'grad_norm': '24.692', 'counters/examples': 8128, 'counters/updates': 127}
skipping logging after 8192 examples to avoid logging too frequently
train stats after 8256 examples: {'rewards_train/chosen': '0.025124', 'rewards_train/rejected': '-0.21376', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.23888', 'logps_train/rejected': '-145.79', 'logps_train/chosen': '-150.48', 'loss/train': '0.62638', 'examples_per_second': '112.29', 'grad_norm': '21.967', 'counters/examples': 8256, 'counters/updates': 129}
skipping logging after 8320 examples to avoid logging too frequently
train stats after 8384 examples: {'rewards_train/chosen': '-0.10614', 'rewards_train/rejected': '-0.42228', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.31614', 'logps_train/rejected': '-122.31', 'logps_train/chosen': '-150.51', 'loss/train': '0.59225', 'examples_per_second': '113.39', 'grad_norm': '20.145', 'counters/examples': 8384, 'counters/updates': 131}
skipping logging after 8448 examples to avoid logging too frequently
train stats after 8512 examples: {'rewards_train/chosen': '-0.12707', 'rewards_train/rejected': '-0.35785', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.23078', 'logps_train/rejected': '-126.84', 'logps_train/chosen': '-152.9', 'loss/train': '0.65535', 'examples_per_second': '115.62', 'grad_norm': '23.461', 'counters/examples': 8512, 'counters/updates': 133}
skipping logging after 8576 examples to avoid logging too frequently
train stats after 8640 examples: {'rewards_train/chosen': '-0.16411', 'rewards_train/rejected': '-0.42372', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.25961', 'logps_train/rejected': '-112.36', 'logps_train/chosen': '-135.7', 'loss/train': '0.61388', 'examples_per_second': '115.84', 'grad_norm': '20.249', 'counters/examples': 8640, 'counters/updates': 135}
skipping logging after 8704 examples to avoid logging too frequently
train stats after 8768 examples: {'rewards_train/chosen': '-0.055229', 'rewards_train/rejected': '-0.27589', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.22066', 'logps_train/rejected': '-128.45', 'logps_train/chosen': '-146.32', 'loss/train': '0.6194', 'examples_per_second': '113.43', 'grad_norm': '21.41', 'counters/examples': 8768, 'counters/updates': 137}
skipping logging after 8832 examples to avoid logging too frequently
train stats after 8896 examples: {'rewards_train/chosen': '-0.26548', 'rewards_train/rejected': '-0.46921', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.20373', 'logps_train/rejected': '-118.71', 'logps_train/chosen': '-151.47', 'loss/train': '0.62679', 'examples_per_second': '115.38', 'grad_norm': '20.856', 'counters/examples': 8896, 'counters/updates': 139}
skipping logging after 8960 examples to avoid logging too frequently
train stats after 9024 examples: {'rewards_train/chosen': '-0.24576', 'rewards_train/rejected': '-0.45647', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21071', 'logps_train/rejected': '-131.06', 'logps_train/chosen': '-156.61', 'loss/train': '0.63572', 'examples_per_second': '111.17', 'grad_norm': '20.936', 'counters/examples': 9024, 'counters/updates': 141}
skipping logging after 9088 examples to avoid logging too frequently
train stats after 9152 examples: {'rewards_train/chosen': '-0.21587', 'rewards_train/rejected': '-0.50079', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.28492', 'logps_train/rejected': '-123.41', 'logps_train/chosen': '-143.46', 'loss/train': '0.60885', 'examples_per_second': '115.25', 'grad_norm': '20.776', 'counters/examples': 9152, 'counters/updates': 143}
skipping logging after 9216 examples to avoid logging too frequently
train stats after 9280 examples: {'rewards_train/chosen': '-0.28756', 'rewards_train/rejected': '-0.54202', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.25446', 'logps_train/rejected': '-140.33', 'logps_train/chosen': '-173.07', 'loss/train': '0.61816', 'examples_per_second': '116.95', 'grad_norm': '23.417', 'counters/examples': 9280, 'counters/updates': 145}
skipping logging after 9344 examples to avoid logging too frequently
train stats after 9408 examples: {'rewards_train/chosen': '-0.11003', 'rewards_train/rejected': '-0.52096', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.41093', 'logps_train/rejected': '-125.1', 'logps_train/chosen': '-125.48', 'loss/train': '0.56348', 'examples_per_second': '115.18', 'grad_norm': '20.988', 'counters/examples': 9408, 'counters/updates': 147}
skipping logging after 9472 examples to avoid logging too frequently
train stats after 9536 examples: {'rewards_train/chosen': '-0.21863', 'rewards_train/rejected': '-0.27481', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.056185', 'logps_train/rejected': '-144.19', 'logps_train/chosen': '-161.16', 'loss/train': '0.71227', 'examples_per_second': '115.64', 'grad_norm': '24.644', 'counters/examples': 9536, 'counters/updates': 149}
skipping logging after 9600 examples to avoid logging too frequently
train stats after 9664 examples: {'rewards_train/chosen': '-0.24481', 'rewards_train/rejected': '-0.59739', 'rewards_train/accuracies': '0.78125', 'rewards_train/margins': '0.35258', 'logps_train/rejected': '-144.2', 'logps_train/chosen': '-189.99', 'loss/train': '0.58604', 'examples_per_second': '115.5', 'grad_norm': '23.748', 'counters/examples': 9664, 'counters/updates': 151}
skipping logging after 9728 examples to avoid logging too frequently
train stats after 9792 examples: {'rewards_train/chosen': '-0.40725', 'rewards_train/rejected': '-0.49754', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.090291', 'logps_train/rejected': '-179.26', 'logps_train/chosen': '-177.04', 'loss/train': '0.70534', 'examples_per_second': '112.86', 'grad_norm': '26.407', 'counters/examples': 9792, 'counters/updates': 153}
skipping logging after 9856 examples to avoid logging too frequently
train stats after 9920 examples: {'rewards_train/chosen': '-0.20105', 'rewards_train/rejected': '-0.61153', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.41049', 'logps_train/rejected': '-128.05', 'logps_train/chosen': '-122.36', 'loss/train': '0.56466', 'examples_per_second': '115.49', 'grad_norm': '19.758', 'counters/examples': 9920, 'counters/updates': 155}
skipping logging after 9984 examples to avoid logging too frequently
train stats after 10048 examples: {'rewards_train/chosen': '-0.29613', 'rewards_train/rejected': '-0.59726', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.30113', 'logps_train/rejected': '-122.5', 'logps_train/chosen': '-143.62', 'loss/train': '0.62048', 'examples_per_second': '111.54', 'grad_norm': '20.833', 'counters/examples': 10048, 'counters/updates': 157}
skipping logging after 10112 examples to avoid logging too frequently
train stats after 10176 examples: {'rewards_train/chosen': '-0.24016', 'rewards_train/rejected': '-0.44778', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.20762', 'logps_train/rejected': '-122.26', 'logps_train/chosen': '-172.64', 'loss/train': '0.6343', 'examples_per_second': '115.66', 'grad_norm': '22.191', 'counters/examples': 10176, 'counters/updates': 159}
skipping logging after 10240 examples to avoid logging too frequently
train stats after 10304 examples: {'rewards_train/chosen': '-0.28482', 'rewards_train/rejected': '-0.59319', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.30838', 'logps_train/rejected': '-144.7', 'logps_train/chosen': '-161.94', 'loss/train': '0.59475', 'examples_per_second': '115.13', 'grad_norm': '21.113', 'counters/examples': 10304, 'counters/updates': 161}
skipping logging after 10368 examples to avoid logging too frequently
train stats after 10432 examples: {'rewards_train/chosen': '-0.40365', 'rewards_train/rejected': '-0.62631', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.22266', 'logps_train/rejected': '-152.19', 'logps_train/chosen': '-190.22', 'loss/train': '0.65987', 'examples_per_second': '115.16', 'grad_norm': '24.905', 'counters/examples': 10432, 'counters/updates': 163}
skipping logging after 10496 examples to avoid logging too frequently
train stats after 10560 examples: {'rewards_train/chosen': '-0.61223', 'rewards_train/rejected': '-0.82986', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.21763', 'logps_train/rejected': '-139', 'logps_train/chosen': '-154.18', 'loss/train': '0.66432', 'examples_per_second': '116.16', 'grad_norm': '23.953', 'counters/examples': 10560, 'counters/updates': 165}
skipping logging after 10624 examples to avoid logging too frequently
train stats after 10688 examples: {'rewards_train/chosen': '-0.22715', 'rewards_train/rejected': '-0.56805', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.3409', 'logps_train/rejected': '-123.14', 'logps_train/chosen': '-139.8', 'loss/train': '0.59415', 'examples_per_second': '115.64', 'grad_norm': '20.851', 'counters/examples': 10688, 'counters/updates': 167}
skipping logging after 10752 examples to avoid logging too frequently
train stats after 10816 examples: {'rewards_train/chosen': '-0.27121', 'rewards_train/rejected': '-0.59859', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.32739', 'logps_train/rejected': '-181.95', 'logps_train/chosen': '-171.91', 'loss/train': '0.60985', 'examples_per_second': '115.63', 'grad_norm': '22.294', 'counters/examples': 10816, 'counters/updates': 169}
skipping logging after 10880 examples to avoid logging too frequently
train stats after 10944 examples: {'rewards_train/chosen': '-0.36464', 'rewards_train/rejected': '-0.71736', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.35273', 'logps_train/rejected': '-135.69', 'logps_train/chosen': '-158.61', 'loss/train': '0.60799', 'examples_per_second': '115.29', 'grad_norm': '21.874', 'counters/examples': 10944, 'counters/updates': 171}
skipping logging after 11008 examples to avoid logging too frequently
train stats after 11072 examples: {'rewards_train/chosen': '-0.5728', 'rewards_train/rejected': '-0.96178', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.38897', 'logps_train/rejected': '-144.17', 'logps_train/chosen': '-152.92', 'loss/train': '0.59321', 'examples_per_second': '115.42', 'grad_norm': '21.506', 'counters/examples': 11072, 'counters/updates': 173}
skipping logging after 11136 examples to avoid logging too frequently
train stats after 11200 examples: {'rewards_train/chosen': '-0.17583', 'rewards_train/rejected': '-0.46149', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.28565', 'logps_train/rejected': '-143.01', 'logps_train/chosen': '-151.63', 'loss/train': '0.61655', 'examples_per_second': '115.74', 'grad_norm': '21.229', 'counters/examples': 11200, 'counters/updates': 175}
skipping logging after 11264 examples to avoid logging too frequently
train stats after 11328 examples: {'rewards_train/chosen': '-0.26237', 'rewards_train/rejected': '-0.53715', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.27478', 'logps_train/rejected': '-133.94', 'logps_train/chosen': '-159.01', 'loss/train': '0.61662', 'examples_per_second': '112.13', 'grad_norm': '23.094', 'counters/examples': 11328, 'counters/updates': 177}
skipping logging after 11392 examples to avoid logging too frequently
train stats after 11456 examples: {'rewards_train/chosen': '-0.097725', 'rewards_train/rejected': '-0.43244', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.33471', 'logps_train/rejected': '-147.97', 'logps_train/chosen': '-147.94', 'loss/train': '0.57699', 'examples_per_second': '115.34', 'grad_norm': '20.594', 'counters/examples': 11456, 'counters/updates': 179}
skipping logging after 11520 examples to avoid logging too frequently
train stats after 11584 examples: {'rewards_train/chosen': '-0.16875', 'rewards_train/rejected': '-0.44636', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.27762', 'logps_train/rejected': '-116.88', 'logps_train/chosen': '-141.57', 'loss/train': '0.61422', 'examples_per_second': '115.66', 'grad_norm': '21.233', 'counters/examples': 11584, 'counters/updates': 181}
skipping logging after 11648 examples to avoid logging too frequently
train stats after 11712 examples: {'rewards_train/chosen': '-0.32767', 'rewards_train/rejected': '-0.48798', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16032', 'logps_train/rejected': '-135.51', 'logps_train/chosen': '-142.42', 'loss/train': '0.67524', 'examples_per_second': '115.41', 'grad_norm': '22.358', 'counters/examples': 11712, 'counters/updates': 183}
skipping logging after 11776 examples to avoid logging too frequently
train stats after 11840 examples: {'rewards_train/chosen': '-0.20047', 'rewards_train/rejected': '-0.61271', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.41224', 'logps_train/rejected': '-127.39', 'logps_train/chosen': '-143.42', 'loss/train': '0.56898', 'examples_per_second': '115.9', 'grad_norm': '20.665', 'counters/examples': 11840, 'counters/updates': 185}
skipping logging after 11904 examples to avoid logging too frequently
train stats after 11968 examples: {'rewards_train/chosen': '-0.23529', 'rewards_train/rejected': '-0.71461', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.47932', 'logps_train/rejected': '-149', 'logps_train/chosen': '-156.94', 'loss/train': '0.56289', 'examples_per_second': '115.36', 'grad_norm': '20.643', 'counters/examples': 11968, 'counters/updates': 187}
Running evaluation after 11968 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:   6%|‚ñã         | 1/16 [00:00<00:01,  9.04it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:01,  8.77it/s]Computing eval metrics:  19%|‚ñà‚ñâ        | 3/16 [00:00<00:01,  8.84it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:01,  8.82it/s]Computing eval metrics:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:00<00:01,  8.78it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:01,  8.95it/s]Computing eval metrics:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:00<00:01,  8.85it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00,  8.82it/s]Computing eval metrics:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:01<00:00,  8.86it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:01<00:00,  8.82it/s]Computing eval metrics:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:01<00:00,  8.82it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:01<00:00,  8.81it/s]Computing eval metrics:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:01<00:00,  8.84it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:01<00:00,  8.80it/s]Computing eval metrics:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [00:01<00:00,  8.78it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:01<00:00,  8.75it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:01<00:00,  8.81it/s]
eval after 11968: {'rewards_eval/chosen': '-0.32006', 'rewards_eval/rejected': '-0.63573', 'rewards_eval/accuracies': '0.63672', 'rewards_eval/margins': '0.31567', 'logps_eval/rejected': '-132.34', 'logps_eval/chosen': '-151', 'loss/eval': '0.63686'}
creating checkpoint to write to .cache/laura/pythia410m_dpo_seed0_2024-01-12_14-58-09_986894/step-11968...
writing checkpoint to .cache/laura/pythia410m_dpo_seed0_2024-01-12_14-58-09_986894/step-11968/policy.pt...
writing checkpoint to .cache/laura/pythia410m_dpo_seed0_2024-01-12_14-58-09_986894/step-11968/optimizer.pt...
writing checkpoint to .cache/laura/pythia410m_dpo_seed0_2024-01-12_14-58-09_986894/step-11968/scheduler.pt...
train stats after 12032 examples: {'rewards_train/chosen': '-0.20759', 'rewards_train/rejected': '-0.58217', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.37458', 'logps_train/rejected': '-119.24', 'logps_train/chosen': '-151.66', 'loss/train': '0.60478', 'examples_per_second': '111.54', 'grad_norm': '22.125', 'counters/examples': 12032, 'counters/updates': 188}
skipping logging after 12096 examples to avoid logging too frequently
train stats after 12160 examples: {'rewards_train/chosen': '-0.41941', 'rewards_train/rejected': '-0.79314', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.37373', 'logps_train/rejected': '-143.13', 'logps_train/chosen': '-163.68', 'loss/train': '0.60241', 'examples_per_second': '121.52', 'grad_norm': '21.94', 'counters/examples': 12160, 'counters/updates': 190}
skipping logging after 12224 examples to avoid logging too frequently
train stats after 12288 examples: {'rewards_train/chosen': '-0.49271', 'rewards_train/rejected': '-0.76907', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.27637', 'logps_train/rejected': '-143.34', 'logps_train/chosen': '-154.08', 'loss/train': '0.63406', 'examples_per_second': '116.22', 'grad_norm': '22.263', 'counters/examples': 12288, 'counters/updates': 192}
skipping logging after 12352 examples to avoid logging too frequently
train stats after 12416 examples: {'rewards_train/chosen': '-0.15985', 'rewards_train/rejected': '-0.37257', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21272', 'logps_train/rejected': '-125.01', 'logps_train/chosen': '-121.65', 'loss/train': '0.66025', 'examples_per_second': '115.49', 'grad_norm': '20.888', 'counters/examples': 12416, 'counters/updates': 194}
skipping logging after 12480 examples to avoid logging too frequently
train stats after 12544 examples: {'rewards_train/chosen': '-0.26274', 'rewards_train/rejected': '-0.52086', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.25812', 'logps_train/rejected': '-123', 'logps_train/chosen': '-162.78', 'loss/train': '0.63918', 'examples_per_second': '115.5', 'grad_norm': '23.519', 'counters/examples': 12544, 'counters/updates': 196}
skipping logging after 12608 examples to avoid logging too frequently
train stats after 12672 examples: {'rewards_train/chosen': '-0.086105', 'rewards_train/rejected': '-0.47848', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.39238', 'logps_train/rejected': '-144.27', 'logps_train/chosen': '-156.04', 'loss/train': '0.57416', 'examples_per_second': '111.49', 'grad_norm': '21.234', 'counters/examples': 12672, 'counters/updates': 198}
skipping logging after 12736 examples to avoid logging too frequently
train stats after 12800 examples: {'rewards_train/chosen': '-0.22213', 'rewards_train/rejected': '-0.64458', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.42245', 'logps_train/rejected': '-127.98', 'logps_train/chosen': '-145.58', 'loss/train': '0.57832', 'examples_per_second': '115.61', 'grad_norm': '21.057', 'counters/examples': 12800, 'counters/updates': 200}
skipping logging after 12864 examples to avoid logging too frequently
train stats after 12928 examples: {'rewards_train/chosen': '-0.29921', 'rewards_train/rejected': '-0.56804', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.26883', 'logps_train/rejected': '-167.56', 'logps_train/chosen': '-157.23', 'loss/train': '0.64769', 'examples_per_second': '115.61', 'grad_norm': '25.198', 'counters/examples': 12928, 'counters/updates': 202}
skipping logging after 12992 examples to avoid logging too frequently
train stats after 13056 examples: {'rewards_train/chosen': '-0.34219', 'rewards_train/rejected': '-0.74519', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.403', 'logps_train/rejected': '-121.22', 'logps_train/chosen': '-123.27', 'loss/train': '0.60254', 'examples_per_second': '116.24', 'grad_norm': '19.916', 'counters/examples': 13056, 'counters/updates': 204}
skipping logging after 13120 examples to avoid logging too frequently
train stats after 13184 examples: {'rewards_train/chosen': '-0.16187', 'rewards_train/rejected': '-0.50003', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.33816', 'logps_train/rejected': '-132.59', 'logps_train/chosen': '-149.79', 'loss/train': '0.59267', 'examples_per_second': '115.69', 'grad_norm': '21.345', 'counters/examples': 13184, 'counters/updates': 206}
skipping logging after 13248 examples to avoid logging too frequently
train stats after 13312 examples: {'rewards_train/chosen': '-0.20525', 'rewards_train/rejected': '-0.56019', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.35494', 'logps_train/rejected': '-132.67', 'logps_train/chosen': '-179.55', 'loss/train': '0.5836', 'examples_per_second': '115.78', 'grad_norm': '22.006', 'counters/examples': 13312, 'counters/updates': 208}
skipping logging after 13376 examples to avoid logging too frequently
train stats after 13440 examples: {'rewards_train/chosen': '-0.53704', 'rewards_train/rejected': '-0.73672', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19968', 'logps_train/rejected': '-144.44', 'logps_train/chosen': '-154.74', 'loss/train': '0.6741', 'examples_per_second': '115.65', 'grad_norm': '24.623', 'counters/examples': 13440, 'counters/updates': 210}
skipping logging after 13504 examples to avoid logging too frequently
train stats after 13568 examples: {'rewards_train/chosen': '-0.20901', 'rewards_train/rejected': '-0.73573', 'rewards_train/accuracies': '0.78125', 'rewards_train/margins': '0.52672', 'logps_train/rejected': '-150.3', 'logps_train/chosen': '-148.87', 'loss/train': '0.52061', 'examples_per_second': '115.41', 'grad_norm': '20.25', 'counters/examples': 13568, 'counters/updates': 212}
skipping logging after 13632 examples to avoid logging too frequently
train stats after 13696 examples: {'rewards_train/chosen': '-0.4003', 'rewards_train/rejected': '-0.54939', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14909', 'logps_train/rejected': '-151.67', 'logps_train/chosen': '-155.15', 'loss/train': '0.69555', 'examples_per_second': '120.33', 'grad_norm': '26.032', 'counters/examples': 13696, 'counters/updates': 214}
skipping logging after 13760 examples to avoid logging too frequently
train stats after 13824 examples: {'rewards_train/chosen': '-0.27699', 'rewards_train/rejected': '-0.51883', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.24184', 'logps_train/rejected': '-142.28', 'logps_train/chosen': '-153.13', 'loss/train': '0.65311', 'examples_per_second': '115.54', 'grad_norm': '23.508', 'counters/examples': 13824, 'counters/updates': 216}
skipping logging after 13888 examples to avoid logging too frequently
train stats after 13952 examples: {'rewards_train/chosen': '-0.04065', 'rewards_train/rejected': '-0.35124', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.31059', 'logps_train/rejected': '-128.91', 'logps_train/chosen': '-145.27', 'loss/train': '0.61023', 'examples_per_second': '125.47', 'grad_norm': '21.685', 'counters/examples': 13952, 'counters/updates': 218}
skipping logging after 14016 examples to avoid logging too frequently
train stats after 14080 examples: {'rewards_train/chosen': '-0.14755', 'rewards_train/rejected': '-0.38871', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.24116', 'logps_train/rejected': '-142.4', 'logps_train/chosen': '-128.72', 'loss/train': '0.65376', 'examples_per_second': '115.54', 'grad_norm': '23.127', 'counters/examples': 14080, 'counters/updates': 220}
skipping logging after 14144 examples to avoid logging too frequently
train stats after 14208 examples: {'rewards_train/chosen': '-0.15204', 'rewards_train/rejected': '-0.40292', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.25089', 'logps_train/rejected': '-128.15', 'logps_train/chosen': '-156.46', 'loss/train': '0.62236', 'examples_per_second': '124.9', 'grad_norm': '22.944', 'counters/examples': 14208, 'counters/updates': 222}
skipping logging after 14272 examples to avoid logging too frequently
train stats after 14336 examples: {'rewards_train/chosen': '0.0092499', 'rewards_train/rejected': '-0.34685', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.3561', 'logps_train/rejected': '-159.01', 'logps_train/chosen': '-149.22', 'loss/train': '0.57438', 'examples_per_second': '113.47', 'grad_norm': '22.697', 'counters/examples': 14336, 'counters/updates': 224}
skipping logging after 14400 examples to avoid logging too frequently
train stats after 14464 examples: {'rewards_train/chosen': '-0.12516', 'rewards_train/rejected': '-0.27896', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.1538', 'logps_train/rejected': '-151.13', 'logps_train/chosen': '-163.58', 'loss/train': '0.67066', 'examples_per_second': '117.29', 'grad_norm': '26.458', 'counters/examples': 14464, 'counters/updates': 226}
skipping logging after 14528 examples to avoid logging too frequently
train stats after 14592 examples: {'rewards_train/chosen': '-0.023824', 'rewards_train/rejected': '-0.29646', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.27263', 'logps_train/rejected': '-134.5', 'logps_train/chosen': '-141.46', 'loss/train': '0.62598', 'examples_per_second': '115.44', 'grad_norm': '22.855', 'counters/examples': 14592, 'counters/updates': 228}
skipping logging after 14656 examples to avoid logging too frequently
train stats after 14720 examples: {'rewards_train/chosen': '-0.10361', 'rewards_train/rejected': '-0.31193', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.20832', 'logps_train/rejected': '-149.07', 'logps_train/chosen': '-156.13', 'loss/train': '0.64554', 'examples_per_second': '117.48', 'grad_norm': '23.709', 'counters/examples': 14720, 'counters/updates': 230}
skipping logging after 14784 examples to avoid logging too frequently
train stats after 14848 examples: {'rewards_train/chosen': '-0.20053', 'rewards_train/rejected': '-0.50972', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.3092', 'logps_train/rejected': '-138.6', 'logps_train/chosen': '-143.09', 'loss/train': '0.6147', 'examples_per_second': '114.81', 'grad_norm': '22.129', 'counters/examples': 14848, 'counters/updates': 232}
skipping logging after 14912 examples to avoid logging too frequently
train stats after 14976 examples: {'rewards_train/chosen': '-0.18644', 'rewards_train/rejected': '-0.55458', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.36815', 'logps_train/rejected': '-141.09', 'logps_train/chosen': '-130.44', 'loss/train': '0.59705', 'examples_per_second': '115.76', 'grad_norm': '19.828', 'counters/examples': 14976, 'counters/updates': 234}
skipping logging after 15040 examples to avoid logging too frequently
train stats after 15104 examples: {'rewards_train/chosen': '-0.37122', 'rewards_train/rejected': '-0.60128', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.23006', 'logps_train/rejected': '-137.79', 'logps_train/chosen': '-149.93', 'loss/train': '0.6357', 'examples_per_second': '112.27', 'grad_norm': '23.635', 'counters/examples': 15104, 'counters/updates': 236}
skipping logging after 15168 examples to avoid logging too frequently
train stats after 15232 examples: {'rewards_train/chosen': '-0.35833', 'rewards_train/rejected': '-0.39804', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.03971', 'logps_train/rejected': '-130.52', 'logps_train/chosen': '-151.67', 'loss/train': '0.7296', 'examples_per_second': '115', 'grad_norm': '25.176', 'counters/examples': 15232, 'counters/updates': 238}
skipping logging after 15296 examples to avoid logging too frequently
train stats after 15360 examples: {'rewards_train/chosen': '-0.19784', 'rewards_train/rejected': '-0.54816', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.35032', 'logps_train/rejected': '-136.99', 'logps_train/chosen': '-164.04', 'loss/train': '0.59475', 'examples_per_second': '111.88', 'grad_norm': '22.38', 'counters/examples': 15360, 'counters/updates': 240}
skipping logging after 15424 examples to avoid logging too frequently
train stats after 15488 examples: {'rewards_train/chosen': '-0.2748', 'rewards_train/rejected': '-0.4327', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.1579', 'logps_train/rejected': '-109.1', 'logps_train/chosen': '-131.02', 'loss/train': '0.66959', 'examples_per_second': '114.81', 'grad_norm': '21.768', 'counters/examples': 15488, 'counters/updates': 242}
skipping logging after 15552 examples to avoid logging too frequently
train stats after 15616 examples: {'rewards_train/chosen': '-0.31038', 'rewards_train/rejected': '-0.65571', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.34533', 'logps_train/rejected': '-133.65', 'logps_train/chosen': '-157.75', 'loss/train': '0.61062', 'examples_per_second': '115.63', 'grad_norm': '21.739', 'counters/examples': 15616, 'counters/updates': 244}
skipping logging after 15680 examples to avoid logging too frequently
train stats after 15744 examples: {'rewards_train/chosen': '-0.22041', 'rewards_train/rejected': '-0.52803', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.30762', 'logps_train/rejected': '-141.57', 'logps_train/chosen': '-136.85', 'loss/train': '0.62326', 'examples_per_second': '117.22', 'grad_norm': '24.797', 'counters/examples': 15744, 'counters/updates': 246}
skipping logging after 15808 examples to avoid logging too frequently
train stats after 15872 examples: {'rewards_train/chosen': '-0.23737', 'rewards_train/rejected': '-0.50295', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.26559', 'logps_train/rejected': '-152.27', 'logps_train/chosen': '-140.68', 'loss/train': '0.62745', 'examples_per_second': '115.65', 'grad_norm': '22.818', 'counters/examples': 15872, 'counters/updates': 248}
skipping logging after 15936 examples to avoid logging too frequently
train stats after 16000 examples: {'rewards_train/chosen': '-0.16143', 'rewards_train/rejected': '-0.46189', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.30047', 'logps_train/rejected': '-145.83', 'logps_train/chosen': '-158.76', 'loss/train': '0.6132', 'examples_per_second': '115.2', 'grad_norm': '24.179', 'counters/examples': 16000, 'counters/updates': 250}
skipping logging after 16064 examples to avoid logging too frequently
train stats after 16128 examples: {'rewards_train/chosen': '-0.29856', 'rewards_train/rejected': '-0.57885', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.2803', 'logps_train/rejected': '-156.49', 'logps_train/chosen': '-168.36', 'loss/train': '0.65206', 'examples_per_second': '115.32', 'grad_norm': '24.223', 'counters/examples': 16128, 'counters/updates': 252}
skipping logging after 16192 examples to avoid logging too frequently
train stats after 16256 examples: {'rewards_train/chosen': '-0.40089', 'rewards_train/rejected': '-0.63429', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.2334', 'logps_train/rejected': '-140.89', 'logps_train/chosen': '-144.2', 'loss/train': '0.63668', 'examples_per_second': '117.69', 'grad_norm': '24.563', 'counters/examples': 16256, 'counters/updates': 254}
skipping logging after 16320 examples to avoid logging too frequently
train stats after 16384 examples: {'rewards_train/chosen': '-0.24116', 'rewards_train/rejected': '-0.48349', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.24233', 'logps_train/rejected': '-137.26', 'logps_train/chosen': '-155.19', 'loss/train': '0.62199', 'examples_per_second': '115.25', 'grad_norm': '24.349', 'counters/examples': 16384, 'counters/updates': 256}
skipping logging after 16448 examples to avoid logging too frequently
train stats after 16512 examples: {'rewards_train/chosen': '-0.59921', 'rewards_train/rejected': '-0.6922', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.092981', 'logps_train/rejected': '-110.92', 'logps_train/chosen': '-136.39', 'loss/train': '0.72741', 'examples_per_second': '115.55', 'grad_norm': '27.145', 'counters/examples': 16512, 'counters/updates': 258}
skipping logging after 16576 examples to avoid logging too frequently
train stats after 16640 examples: {'rewards_train/chosen': '-0.45282', 'rewards_train/rejected': '-0.76787', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.31505', 'logps_train/rejected': '-140.43', 'logps_train/chosen': '-151.44', 'loss/train': '0.60513', 'examples_per_second': '110.61', 'grad_norm': '22.121', 'counters/examples': 16640, 'counters/updates': 260}
skipping logging after 16704 examples to avoid logging too frequently
train stats after 16768 examples: {'rewards_train/chosen': '-0.44227', 'rewards_train/rejected': '-0.65217', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.2099', 'logps_train/rejected': '-139.47', 'logps_train/chosen': '-140.53', 'loss/train': '0.66391', 'examples_per_second': '115.18', 'grad_norm': '24.935', 'counters/examples': 16768, 'counters/updates': 262}
skipping logging after 16832 examples to avoid logging too frequently
train stats after 16896 examples: {'rewards_train/chosen': '-0.40661', 'rewards_train/rejected': '-0.77299', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.36638', 'logps_train/rejected': '-179.51', 'logps_train/chosen': '-162.44', 'loss/train': '0.59826', 'examples_per_second': '115.42', 'grad_norm': '24.64', 'counters/examples': 16896, 'counters/updates': 264}
skipping logging after 16960 examples to avoid logging too frequently
train stats after 17024 examples: {'rewards_train/chosen': '-0.61489', 'rewards_train/rejected': '-0.79898', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.18409', 'logps_train/rejected': '-180.29', 'logps_train/chosen': '-152.83', 'loss/train': '0.66049', 'examples_per_second': '114.99', 'grad_norm': '24.411', 'counters/examples': 17024, 'counters/updates': 266}
skipping logging after 17088 examples to avoid logging too frequently
train stats after 17152 examples: {'rewards_train/chosen': '-0.32915', 'rewards_train/rejected': '-0.59851', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.26936', 'logps_train/rejected': '-135.61', 'logps_train/chosen': '-153.7', 'loss/train': '0.6318', 'examples_per_second': '115.41', 'grad_norm': '23.258', 'counters/examples': 17152, 'counters/updates': 268}
skipping logging after 17216 examples to avoid logging too frequently
train stats after 17280 examples: {'rewards_train/chosen': '-0.48096', 'rewards_train/rejected': '-0.74175', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.2608', 'logps_train/rejected': '-143.91', 'logps_train/chosen': '-151.22', 'loss/train': '0.65476', 'examples_per_second': '115.78', 'grad_norm': '24.046', 'counters/examples': 17280, 'counters/updates': 270}
skipping logging after 17344 examples to avoid logging too frequently
train stats after 17408 examples: {'rewards_train/chosen': '-0.38667', 'rewards_train/rejected': '-0.70978', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.32311', 'logps_train/rejected': '-151.27', 'logps_train/chosen': '-164.57', 'loss/train': '0.6327', 'examples_per_second': '113.04', 'grad_norm': '23.215', 'counters/examples': 17408, 'counters/updates': 272}
skipping logging after 17472 examples to avoid logging too frequently
train stats after 17536 examples: {'rewards_train/chosen': '-0.55137', 'rewards_train/rejected': '-0.84226', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.2909', 'logps_train/rejected': '-134.52', 'logps_train/chosen': '-141.48', 'loss/train': '0.62665', 'examples_per_second': '121.33', 'grad_norm': '21.77', 'counters/examples': 17536, 'counters/updates': 274}
skipping logging after 17600 examples to avoid logging too frequently
train stats after 17664 examples: {'rewards_train/chosen': '-0.46409', 'rewards_train/rejected': '-1.0596', 'rewards_train/accuracies': '0.79688', 'rewards_train/margins': '0.59548', 'logps_train/rejected': '-149.53', 'logps_train/chosen': '-134.5', 'loss/train': '0.53272', 'examples_per_second': '110.71', 'grad_norm': '19.859', 'counters/examples': 17664, 'counters/updates': 276}
skipping logging after 17728 examples to avoid logging too frequently
train stats after 17792 examples: {'rewards_train/chosen': '-0.5722', 'rewards_train/rejected': '-0.82444', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.25224', 'logps_train/rejected': '-117.03', 'logps_train/chosen': '-114.51', 'loss/train': '0.66388', 'examples_per_second': '119.82', 'grad_norm': '22.691', 'counters/examples': 17792, 'counters/updates': 278}
skipping logging after 17856 examples to avoid logging too frequently
train stats after 17920 examples: {'rewards_train/chosen': '-0.34968', 'rewards_train/rejected': '-0.68492', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.33525', 'logps_train/rejected': '-137.05', 'logps_train/chosen': '-129.29', 'loss/train': '0.61502', 'examples_per_second': '131.19', 'grad_norm': '21.022', 'counters/examples': 17920, 'counters/updates': 280}
skipping logging after 17984 examples to avoid logging too frequently
train stats after 18048 examples: {'rewards_train/chosen': '-0.27654', 'rewards_train/rejected': '-0.64767', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.37113', 'logps_train/rejected': '-127.48', 'logps_train/chosen': '-152.3', 'loss/train': '0.60982', 'examples_per_second': '115.11', 'grad_norm': '22.198', 'counters/examples': 18048, 'counters/updates': 282}
skipping logging after 18112 examples to avoid logging too frequently
train stats after 18176 examples: {'rewards_train/chosen': '-0.35281', 'rewards_train/rejected': '-0.734', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.38119', 'logps_train/rejected': '-120.21', 'logps_train/chosen': '-151.28', 'loss/train': '0.60495', 'examples_per_second': '110.9', 'grad_norm': '21.803', 'counters/examples': 18176, 'counters/updates': 284}
skipping logging after 18240 examples to avoid logging too frequently
train stats after 18304 examples: {'rewards_train/chosen': '-0.39439', 'rewards_train/rejected': '-0.8877', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.49331', 'logps_train/rejected': '-155.79', 'logps_train/chosen': '-180.49', 'loss/train': '0.52952', 'examples_per_second': '115.02', 'grad_norm': '21.33', 'counters/examples': 18304, 'counters/updates': 286}
skipping logging after 18368 examples to avoid logging too frequently
train stats after 18432 examples: {'rewards_train/chosen': '-0.46469', 'rewards_train/rejected': '-0.65085', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.18616', 'logps_train/rejected': '-116.14', 'logps_train/chosen': '-144.17', 'loss/train': '0.71257', 'examples_per_second': '111.49', 'grad_norm': '28.118', 'counters/examples': 18432, 'counters/updates': 288}
skipping logging after 18496 examples to avoid logging too frequently
train stats after 18560 examples: {'rewards_train/chosen': '-0.30317', 'rewards_train/rejected': '-0.65847', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.3553', 'logps_train/rejected': '-134.58', 'logps_train/chosen': '-174.84', 'loss/train': '0.59479', 'examples_per_second': '115.68', 'grad_norm': '24.587', 'counters/examples': 18560, 'counters/updates': 290}
skipping logging after 18624 examples to avoid logging too frequently
train stats after 18688 examples: {'rewards_train/chosen': '-0.18802', 'rewards_train/rejected': '-0.43616', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.24814', 'logps_train/rejected': '-141.53', 'logps_train/chosen': '-144.54', 'loss/train': '0.64545', 'examples_per_second': '117.53', 'grad_norm': '21.88', 'counters/examples': 18688, 'counters/updates': 292}
skipping logging after 18752 examples to avoid logging too frequently
train stats after 18816 examples: {'rewards_train/chosen': '-0.47884', 'rewards_train/rejected': '-0.59655', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11771', 'logps_train/rejected': '-147.22', 'logps_train/chosen': '-154.99', 'loss/train': '0.70955', 'examples_per_second': '114.64', 'grad_norm': '25.863', 'counters/examples': 18816, 'counters/updates': 294}
skipping logging after 18880 examples to avoid logging too frequently
train stats after 18944 examples: {'rewards_train/chosen': '-0.5031', 'rewards_train/rejected': '-0.71583', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.21273', 'logps_train/rejected': '-134.61', 'logps_train/chosen': '-145.98', 'loss/train': '0.66525', 'examples_per_second': '114.89', 'grad_norm': '25.952', 'counters/examples': 18944, 'counters/updates': 296}
skipping logging after 19008 examples to avoid logging too frequently
train stats after 19072 examples: {'rewards_train/chosen': '-0.39566', 'rewards_train/rejected': '-0.62592', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.23027', 'logps_train/rejected': '-148.27', 'logps_train/chosen': '-156.57', 'loss/train': '0.65693', 'examples_per_second': '110.87', 'grad_norm': '23.579', 'counters/examples': 19072, 'counters/updates': 298}
skipping logging after 19136 examples to avoid logging too frequently
train stats after 19200 examples: {'rewards_train/chosen': '-0.3693', 'rewards_train/rejected': '-0.70953', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.34023', 'logps_train/rejected': '-147.97', 'logps_train/chosen': '-173.47', 'loss/train': '0.61186', 'examples_per_second': '110.32', 'grad_norm': '22.683', 'counters/examples': 19200, 'counters/updates': 300}
skipping logging after 19264 examples to avoid logging too frequently
train stats after 19328 examples: {'rewards_train/chosen': '-0.4037', 'rewards_train/rejected': '-0.50056', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.096865', 'logps_train/rejected': '-136.4', 'logps_train/chosen': '-167.49', 'loss/train': '0.70685', 'examples_per_second': '115.2', 'grad_norm': '26.303', 'counters/examples': 19328, 'counters/updates': 302}
skipping logging after 19392 examples to avoid logging too frequently
train stats after 19456 examples: {'rewards_train/chosen': '-0.21094', 'rewards_train/rejected': '-0.54563', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.33469', 'logps_train/rejected': '-142.78', 'logps_train/chosen': '-178.4', 'loss/train': '0.6055', 'examples_per_second': '111.91', 'grad_norm': '22.977', 'counters/examples': 19456, 'counters/updates': 304}
skipping logging after 19520 examples to avoid logging too frequently
train stats after 19584 examples: {'rewards_train/chosen': '-0.36687', 'rewards_train/rejected': '-0.67644', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.30957', 'logps_train/rejected': '-165.17', 'logps_train/chosen': '-167.72', 'loss/train': '0.58889', 'examples_per_second': '117.47', 'grad_norm': '22.644', 'counters/examples': 19584, 'counters/updates': 306}
skipping logging after 19648 examples to avoid logging too frequently
train stats after 19712 examples: {'rewards_train/chosen': '-0.32086', 'rewards_train/rejected': '-0.67809', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.35723', 'logps_train/rejected': '-143.91', 'logps_train/chosen': '-149.24', 'loss/train': '0.64103', 'examples_per_second': '115.29', 'grad_norm': '26.063', 'counters/examples': 19712, 'counters/updates': 308}
skipping logging after 19776 examples to avoid logging too frequently
train stats after 19840 examples: {'rewards_train/chosen': '-0.31192', 'rewards_train/rejected': '-0.60649', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.29457', 'logps_train/rejected': '-144.12', 'logps_train/chosen': '-160.85', 'loss/train': '0.62863', 'examples_per_second': '115.28', 'grad_norm': '22.94', 'counters/examples': 19840, 'counters/updates': 310}
skipping logging after 19904 examples to avoid logging too frequently
train stats after 19968 examples: {'rewards_train/chosen': '-0.19666', 'rewards_train/rejected': '-0.60827', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.4116', 'logps_train/rejected': '-119.99', 'logps_train/chosen': '-171.25', 'loss/train': '0.56753', 'examples_per_second': '119.45', 'grad_norm': '22.146', 'counters/examples': 19968, 'counters/updates': 312}
skipping logging after 20032 examples to avoid logging too frequently
train stats after 20096 examples: {'rewards_train/chosen': '-0.32904', 'rewards_train/rejected': '-0.62638', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.29734', 'logps_train/rejected': '-149.89', 'logps_train/chosen': '-165.66', 'loss/train': '0.63568', 'examples_per_second': '135.72', 'grad_norm': '25.174', 'counters/examples': 20096, 'counters/updates': 314}
skipping logging after 20160 examples to avoid logging too frequently
train stats after 20224 examples: {'rewards_train/chosen': '-0.20345', 'rewards_train/rejected': '-0.68931', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.48586', 'logps_train/rejected': '-149', 'logps_train/chosen': '-175.12', 'loss/train': '0.56638', 'examples_per_second': '115.6', 'grad_norm': '23.211', 'counters/examples': 20224, 'counters/updates': 316}
skipping logging after 20288 examples to avoid logging too frequently
train stats after 20352 examples: {'rewards_train/chosen': '-0.31148', 'rewards_train/rejected': '-0.79117', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.47969', 'logps_train/rejected': '-126.82', 'logps_train/chosen': '-147.2', 'loss/train': '0.54856', 'examples_per_second': '116.05', 'grad_norm': '20.321', 'counters/examples': 20352, 'counters/updates': 318}
skipping logging after 20416 examples to avoid logging too frequently
train stats after 20480 examples: {'rewards_train/chosen': '-0.35341', 'rewards_train/rejected': '-0.63235', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.27894', 'logps_train/rejected': '-179.74', 'logps_train/chosen': '-156.65', 'loss/train': '0.64434', 'examples_per_second': '115.73', 'grad_norm': '24.974', 'counters/examples': 20480, 'counters/updates': 320}
skipping logging after 20544 examples to avoid logging too frequently
train stats after 20608 examples: {'rewards_train/chosen': '-0.12572', 'rewards_train/rejected': '-0.57559', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.44986', 'logps_train/rejected': '-149.29', 'logps_train/chosen': '-190.71', 'loss/train': '0.56788', 'examples_per_second': '115.39', 'grad_norm': '25.27', 'counters/examples': 20608, 'counters/updates': 322}
skipping logging after 20672 examples to avoid logging too frequently
train stats after 20736 examples: {'rewards_train/chosen': '-0.27846', 'rewards_train/rejected': '-0.578', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.29954', 'logps_train/rejected': '-143.22', 'logps_train/chosen': '-186.21', 'loss/train': '0.62968', 'examples_per_second': '115.51', 'grad_norm': '24.704', 'counters/examples': 20736, 'counters/updates': 324}
skipping logging after 20800 examples to avoid logging too frequently
train stats after 20864 examples: {'rewards_train/chosen': '-0.40103', 'rewards_train/rejected': '-0.71598', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.31494', 'logps_train/rejected': '-127.44', 'logps_train/chosen': '-154.23', 'loss/train': '0.60608', 'examples_per_second': '110.81', 'grad_norm': '20.639', 'counters/examples': 20864, 'counters/updates': 326}
skipping logging after 20928 examples to avoid logging too frequently
train stats after 20992 examples: {'rewards_train/chosen': '-0.29225', 'rewards_train/rejected': '-0.70914', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.41689', 'logps_train/rejected': '-135.52', 'logps_train/chosen': '-163.3', 'loss/train': '0.56856', 'examples_per_second': '115.78', 'grad_norm': '22.03', 'counters/examples': 20992, 'counters/updates': 328}
skipping logging after 21056 examples to avoid logging too frequently
train stats after 21120 examples: {'rewards_train/chosen': '-0.5691', 'rewards_train/rejected': '-0.82269', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.25359', 'logps_train/rejected': '-149.67', 'logps_train/chosen': '-143.15', 'loss/train': '0.66792', 'examples_per_second': '115.59', 'grad_norm': '24.045', 'counters/examples': 21120, 'counters/updates': 330}
skipping logging after 21184 examples to avoid logging too frequently
train stats after 21248 examples: {'rewards_train/chosen': '-0.24131', 'rewards_train/rejected': '-0.47871', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.2374', 'logps_train/rejected': '-125.41', 'logps_train/chosen': '-129.93', 'loss/train': '0.63077', 'examples_per_second': '121.16', 'grad_norm': '21.279', 'counters/examples': 21248, 'counters/updates': 332}
skipping logging after 21312 examples to avoid logging too frequently
train stats after 21376 examples: {'rewards_train/chosen': '-0.19526', 'rewards_train/rejected': '-0.63368', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.43842', 'logps_train/rejected': '-161.04', 'logps_train/chosen': '-145.24', 'loss/train': '0.55366', 'examples_per_second': '118.11', 'grad_norm': '20.07', 'counters/examples': 21376, 'counters/updates': 334}
skipping logging after 21440 examples to avoid logging too frequently
train stats after 21504 examples: {'rewards_train/chosen': '-0.092351', 'rewards_train/rejected': '-0.61505', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.5227', 'logps_train/rejected': '-134.23', 'logps_train/chosen': '-162.86', 'loss/train': '0.54399', 'examples_per_second': '115.39', 'grad_norm': '23.66', 'counters/examples': 21504, 'counters/updates': 336}
skipping logging after 21568 examples to avoid logging too frequently
train stats after 21632 examples: {'rewards_train/chosen': '-0.18693', 'rewards_train/rejected': '-0.4991', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.31218', 'logps_train/rejected': '-123.65', 'logps_train/chosen': '-140.76', 'loss/train': '0.59251', 'examples_per_second': '115.65', 'grad_norm': '22.515', 'counters/examples': 21632, 'counters/updates': 338}
skipping logging after 21696 examples to avoid logging too frequently
train stats after 21760 examples: {'rewards_train/chosen': '-0.27271', 'rewards_train/rejected': '-0.62194', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.34923', 'logps_train/rejected': '-139.81', 'logps_train/chosen': '-178.25', 'loss/train': '0.62736', 'examples_per_second': '117.26', 'grad_norm': '23.919', 'counters/examples': 21760, 'counters/updates': 340}
skipping logging after 21824 examples to avoid logging too frequently
train stats after 21888 examples: {'rewards_train/chosen': '-0.33216', 'rewards_train/rejected': '-0.59381', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.26165', 'logps_train/rejected': '-150.59', 'logps_train/chosen': '-139.06', 'loss/train': '0.63109', 'examples_per_second': '118.27', 'grad_norm': '23.219', 'counters/examples': 21888, 'counters/updates': 342}
skipping logging after 21952 examples to avoid logging too frequently
train stats after 22016 examples: {'rewards_train/chosen': '-0.37617', 'rewards_train/rejected': '-0.71473', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.33856', 'logps_train/rejected': '-162.32', 'logps_train/chosen': '-143.04', 'loss/train': '0.61057', 'examples_per_second': '115.83', 'grad_norm': '22.953', 'counters/examples': 22016, 'counters/updates': 344}
skipping logging after 22080 examples to avoid logging too frequently
train stats after 22144 examples: {'rewards_train/chosen': '-0.20755', 'rewards_train/rejected': '-0.54867', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.34112', 'logps_train/rejected': '-116.68', 'logps_train/chosen': '-133.23', 'loss/train': '0.60208', 'examples_per_second': '112.97', 'grad_norm': '20.842', 'counters/examples': 22144, 'counters/updates': 346}
skipping logging after 22208 examples to avoid logging too frequently
train stats after 22272 examples: {'rewards_train/chosen': '-0.13717', 'rewards_train/rejected': '-0.50123', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.36406', 'logps_train/rejected': '-119.94', 'logps_train/chosen': '-136.87', 'loss/train': '0.57254', 'examples_per_second': '110.12', 'grad_norm': '20.17', 'counters/examples': 22272, 'counters/updates': 348}
skipping logging after 22336 examples to avoid logging too frequently
train stats after 22400 examples: {'rewards_train/chosen': '-0.26754', 'rewards_train/rejected': '-0.6887', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.42116', 'logps_train/rejected': '-125.62', 'logps_train/chosen': '-163.28', 'loss/train': '0.57816', 'examples_per_second': '115.37', 'grad_norm': '21.557', 'counters/examples': 22400, 'counters/updates': 350}
skipping logging after 22464 examples to avoid logging too frequently
train stats after 22528 examples: {'rewards_train/chosen': '-0.41538', 'rewards_train/rejected': '-0.68082', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.26544', 'logps_train/rejected': '-140.42', 'logps_train/chosen': '-165.47', 'loss/train': '0.63172', 'examples_per_second': '115.75', 'grad_norm': '22.016', 'counters/examples': 22528, 'counters/updates': 352}
skipping logging after 22592 examples to avoid logging too frequently
train stats after 22656 examples: {'rewards_train/chosen': '-0.32359', 'rewards_train/rejected': '-0.65073', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.32714', 'logps_train/rejected': '-134.31', 'logps_train/chosen': '-157.34', 'loss/train': '0.62511', 'examples_per_second': '115.54', 'grad_norm': '26.601', 'counters/examples': 22656, 'counters/updates': 354}
skipping logging after 22720 examples to avoid logging too frequently
train stats after 22784 examples: {'rewards_train/chosen': '-0.36113', 'rewards_train/rejected': '-0.76952', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.40839', 'logps_train/rejected': '-142.61', 'logps_train/chosen': '-148.31', 'loss/train': '0.56392', 'examples_per_second': '122.93', 'grad_norm': '20.846', 'counters/examples': 22784, 'counters/updates': 356}
skipping logging after 22848 examples to avoid logging too frequently
train stats after 22912 examples: {'rewards_train/chosen': '-0.26439', 'rewards_train/rejected': '-0.65334', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.38895', 'logps_train/rejected': '-141.09', 'logps_train/chosen': '-155.1', 'loss/train': '0.60779', 'examples_per_second': '136.9', 'grad_norm': '23.685', 'counters/examples': 22912, 'counters/updates': 358}
skipping logging after 22976 examples to avoid logging too frequently
train stats after 23040 examples: {'rewards_train/chosen': '-0.19525', 'rewards_train/rejected': '-0.58877', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.39351', 'logps_train/rejected': '-127.6', 'logps_train/chosen': '-134.25', 'loss/train': '0.57022', 'examples_per_second': '111.49', 'grad_norm': '20.614', 'counters/examples': 23040, 'counters/updates': 360}
skipping logging after 23104 examples to avoid logging too frequently
train stats after 23168 examples: {'rewards_train/chosen': '-0.22966', 'rewards_train/rejected': '-0.63131', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.40165', 'logps_train/rejected': '-143.78', 'logps_train/chosen': '-169.92', 'loss/train': '0.58514', 'examples_per_second': '114.93', 'grad_norm': '24.772', 'counters/examples': 23168, 'counters/updates': 362}
skipping logging after 23232 examples to avoid logging too frequently
train stats after 23296 examples: {'rewards_train/chosen': '-0.34383', 'rewards_train/rejected': '-0.63277', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.28894', 'logps_train/rejected': '-157', 'logps_train/chosen': '-167.41', 'loss/train': '0.65363', 'examples_per_second': '115.1', 'grad_norm': '25.459', 'counters/examples': 23296, 'counters/updates': 364}
skipping logging after 23360 examples to avoid logging too frequently
train stats after 23424 examples: {'rewards_train/chosen': '-0.28862', 'rewards_train/rejected': '-0.50625', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.21764', 'logps_train/rejected': '-131.04', 'logps_train/chosen': '-141.55', 'loss/train': '0.63557', 'examples_per_second': '115.49', 'grad_norm': '22.324', 'counters/examples': 23424, 'counters/updates': 366}
skipping logging after 23488 examples to avoid logging too frequently
train stats after 23552 examples: {'rewards_train/chosen': '-0.24299', 'rewards_train/rejected': '-0.78732', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.54433', 'logps_train/rejected': '-145.95', 'logps_train/chosen': '-138.64', 'loss/train': '0.57782', 'examples_per_second': '115.17', 'grad_norm': '22.479', 'counters/examples': 23552, 'counters/updates': 368}
skipping logging after 23616 examples to avoid logging too frequently
train stats after 23680 examples: {'rewards_train/chosen': '-0.45875', 'rewards_train/rejected': '-0.76255', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.30381', 'logps_train/rejected': '-123.19', 'logps_train/chosen': '-142.79', 'loss/train': '0.62785', 'examples_per_second': '110.78', 'grad_norm': '24.438', 'counters/examples': 23680, 'counters/updates': 370}
skipping logging after 23744 examples to avoid logging too frequently
train stats after 23808 examples: {'rewards_train/chosen': '-0.23127', 'rewards_train/rejected': '-0.52765', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.29638', 'logps_train/rejected': '-152.49', 'logps_train/chosen': '-150.01', 'loss/train': '0.62522', 'examples_per_second': '113.91', 'grad_norm': '24.063', 'counters/examples': 23808, 'counters/updates': 372}
skipping logging after 23872 examples to avoid logging too frequently
train stats after 23936 examples: {'rewards_train/chosen': '-0.41662', 'rewards_train/rejected': '-0.63874', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.22211', 'logps_train/rejected': '-127.83', 'logps_train/chosen': '-141.42', 'loss/train': '0.64786', 'examples_per_second': '115.79', 'grad_norm': '22.872', 'counters/examples': 23936, 'counters/updates': 374}
Running evaluation after 23936 train examples
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:   6%|‚ñã         | 1/16 [00:00<00:01,  8.82it/s]Computing eval metrics:  12%|‚ñà‚ñé        | 2/16 [00:00<00:01,  8.70it/s]Computing eval metrics:  19%|‚ñà‚ñâ        | 3/16 [00:00<00:01,  8.75it/s]Computing eval metrics:  25%|‚ñà‚ñà‚ñå       | 4/16 [00:00<00:01,  8.79it/s]Computing eval metrics:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [00:00<00:01,  8.76it/s]Computing eval metrics:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:01,  8.94it/s]Computing eval metrics:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 7/16 [00:00<00:01,  8.90it/s]Computing eval metrics:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:00<00:00,  8.87it/s]Computing eval metrics:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 9/16 [00:01<00:00,  8.90it/s]Computing eval metrics:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 10/16 [00:01<00:00,  8.86it/s]Computing eval metrics:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 11/16 [00:01<00:00,  8.87it/s]Computing eval metrics:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 12/16 [00:01<00:00,  8.90it/s]Computing eval metrics:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 13/16 [00:01<00:00,  8.92it/s]Computing eval metrics:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 14/16 [00:01<00:00,  8.87it/s]Computing eval metrics:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 15/16 [00:01<00:00,  8.90it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:01<00:00,  8.85it/s]Computing eval metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:01<00:00,  8.86it/s]
slurmstepd: error: *** REASON: burst_buffer/lua: Stage-out in progress ***
slurmstepd: error: *** JOB 52190 ON ip-10-0-222-166 CANCELLED AT 2024-01-12T15:05:15 ***
slurmstepd: error: *** REASON: burst_buffer/lua: Stage-out in progress ***
